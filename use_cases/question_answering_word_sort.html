<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" />

    <link rel="shortcut icon" href="../_static/LightRAG-logo-circle.png"/><!-- Generated with Sphinx 7.4.7 and Furo 2024.08.06 -->
        <title>Question Answer with LLM as Judge - Build and Optimize LM Workflows</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=f0068426" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/css/rtd_sphinx_search.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  --color-brand-primary: #FF6F00;
  --color-brand-content: #1E2A38;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #FF8F00;
  --color-brand-content: #CFD8DC;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #FF8F00;
  --color-brand-content: #CFD8DC;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Build and Optimize LM Workflows</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../_static/images/AdalFlow.svg" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="../_static/images/AdalFlow_black_bg.svg" alt="Dark Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Build and Optimize LM Workflows</span>
  
</a><div class="sidebar-github-section">
    <a href="https://github.com/SylphAI-Inc/AdalFlow" class="sidebar-github-link">
        <i class="fa-brands fa-github"></i>
        <span class="github-text">GitHub</span>
    </a>
</div><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Getting Started</a></li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../new_tutorials/index.html">Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Tutorials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../new_tutorials/core_concepts.html">Core Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../new_tutorials/generator.html">Generator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../new_tutorials/embedder.html">Embedder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/retriever.html">retriever</a></li>
<li class="toctree-l2"><a class="reference internal" href="../new_tutorials/tool.html">Tool Use</a></li>
<li class="toctree-l2"><a class="reference internal" href="../new_tutorials/agents_runner.html">Agent Runner</a></li>
<li class="toctree-l2"><a class="reference internal" href="../new_tutorials/streaming.html">Streaming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../new_tutorials/tracing.html">Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../new_tutorials/human_in_the_loop.html">Human in the Loop</a></li>
<li class="toctree-l2"><a class="reference internal" href="../new_tutorials/prompt.html">Prompt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../new_tutorials/parser.html">Parser and Structured Output</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../integrations/index.html">Integrations</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Integrations</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../integrations/integrations.html">All Providers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../integrations/openai.html">OpenAI Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../integrations/anthropic.html">Anthropic Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../integrations/ollama.html">Ollama Integration</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="index.html">Use Cases</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Use Cases</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="question_answering.html">Question Answering</a></li>
<li class="toctree-l2"><a class="reference internal" href="qa_computation_graph.html">Q&amp;A Computation Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="qa_text_grad_trace_graph.html">Q&amp;A Text Grad Trace Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="qa_demo_trace_graph.html">Q&amp;A Few Shot Demo Trace Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification.html">Classification Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="rag_opt.html">RAG optimization</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../contributor/index.html">Contributor Guide</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Contributor Guide</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../contributor/contribution.html">Contributing Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributor/contribute_to_code.html">Development Essentials</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorials/index.html">Developer Notes</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Developer Notes</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/lightrag_design_philosophy.html">Design Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/class_hierarchy.html">Class Hierarchy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/trace_graph.html">AdalFlow Trace Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/component.html">Component</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/base_data_class.html">DataClass</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/prompt.html">Prompt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/model_client.html">ModelClient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/generator.html">Generator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/generator.html#basic-generator-tutorial">Basic Generator Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/output_parsers.html">Parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/embedder.html">Embedder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/retriever.html">Retriever</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/text_splitter.html">Text Splitter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/db.html">Data (Database/Pipeline)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/rag_playbook.html">RAG Playbook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/rag_with_memory.html">RAG with Memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/tool_helper.html">Function calls</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/agent.html">ReAct Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../new_tutorials/agents_runner.html">Agents and Runner</a></li>
<li class="toctree-l2"><a class="reference internal" href="../new_tutorials/streaming.html">Streaming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../new_tutorials/tracing.html">Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../new_tutorials/human_in_the_loop.html">Human in the Loop</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/evaluation.html">LLM Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/datasets.html">Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/logging.html">Logger Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/logging.html#design">Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/logging.html#use-logger-in-projects">Use Logger in Projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/logging_tracing.html">Tracing</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../design/index.html">Blog</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Blog</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../design/ComponentTool.html">Use Class method as a better function tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/FunctionTool.html">Designing of AdalFlow FunctionTool</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/agent-streaming.html">Agent Streaming Architecture in OpenAI Agents SDK</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../apis/index.html">API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of API Reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../apis/core/index.html">Core</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Core</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../apis/core/core.base_data_class.html">base_data_class</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/core/core.component.html">component</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/core/core.container.html">container</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/core/core.default_prompt_template.html">default_prompt_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/core/core.embedder.html">embedder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/core/core.generator.html">generator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/core/core.model_client.html">model_client</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/core/core.prompt_builder.html">prompt_builder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/core/core.retriever.html">retriever</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/core/core.string_parser.html">string_parser</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/core/core.func_tool.html">func_tool</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/core/core.mcp_tool.html">mcp_tool</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/core/core.tool_manager.html">tool_manager</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/core/core.types.html">types</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/core/core.db.html">db</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/core/core.functional.html">functional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/core/core.tokenizer.html">tokenizer</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../apis/components/index.html">Components</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of Components</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../apis/components/components.model_client.html">model_client</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of model_client</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.model_client.anthropic_client.html">anthropic_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.model_client.azureai_client.html">azureai_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.model_client.bedrock_client.html">bedrock_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.model_client.chat_completion_to_response_converter.html">chat_completion_to_response_converter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.model_client.cohere_client.html">cohere_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.model_client.deepseek_client.html">deepseek_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.model_client.fireworks_client.html">fireworks_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.model_client.google_client.html">google_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.model_client.groq_client.html">groq_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.model_client.mistral_client.html">mistral_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.model_client.ollama_client.html">ollama_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.model_client.openai_client.html">openai_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.model_client.sambanova_client.html">sambanova_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.model_client.together_client.html">together_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.model_client.transformers_client.html">transformers_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.model_client.utils.html">utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.model_client.xai_client.html">xai_client</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../apis/components/components.retriever.html">retriever</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of retriever</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.retriever.bm25_retriever.html">bm25_retriever</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.retriever.faiss_retriever.html">faiss_retriever</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.retriever.lancedb_retriver.html">lancedb_retriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.retriever.llm_retriever.html">llm_retriever</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.retriever.postgres_retriever.html">postgres_retriever</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.retriever.qdrant_retriever.html">qdrant_retriever</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.retriever.reranker_retriever.html">reranker_retriever</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../apis/components/components.output_parsers.html">output_parsers</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of output_parsers</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.output_parsers.dataclass_parser.html">dataclass_parser</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.output_parsers.outputs.html">outputs</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../apis/components/components.agent.html">agent</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of agent</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.agent.agent.html">agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.agent.prompts.html">prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.agent.react.html">react</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.agent.runner.html">runner</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../apis/components/components.data_process.html">data_process</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of data_process</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.data_process.data_components.html">data_components</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.data_process.text_splitter.html">text_splitter</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../apis/components/components.memory.html">memory</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of memory</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../apis/components/components.memory.memory.html">memory</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../apis/datasets/index.html">Datasets</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of Datasets</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../apis/datasets/datasets.big_bench_hard.html">big_bench_hard</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/datasets/datasets.trec.html">trec</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/datasets/datasets.hotpot_qa.html">hotpot_qa</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/datasets/datasets.types.html">types</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../apis/eval/index.html">Evaluation</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of Evaluation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../apis/eval/eval.base.html">base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/eval/eval.answer_match_acc.html">answer_match_acc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/eval/eval.retriever_recall.html">retriever_recall</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/eval/eval.llm_as_judge.html">llm_as_judge</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/eval/eval.g_eval.html">g_eval</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../apis/optim/index.html">Optimization</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of Optimization</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../apis/optim/optim.parameter.html">parameter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/optim/optim.optimizer.html">optimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/optim/optim.grad_component.html">grad_component</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/optim/optim.loss_component.html">loss_component</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/optim/optim.types.html">types</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../apis/optim/optim.few_shot.html">few_shot</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of few_shot</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../apis/optim/optim.few_shot.bootstrap_optimizer.html">bootstrap_optimizer</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../apis/optim/optim.text_grad.html">text_grad</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of text_grad</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../apis/optim/optim.text_grad.backend_engine_prompt.html">backend_engine_prompt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/optim/optim.text_grad.llm_text_loss.html">llm_text_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/optim/optim.text_grad.ops.html">ops</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/optim/optim.text_grad.text_loss_with_eval_fn.html">text_loss_with_eval_fn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/optim/optim.text_grad.tgd_optimizer.html">tgd_optimizer</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../apis/optim/optim.trainer.html">trainer</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of trainer</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../apis/optim/optim.trainer.adal.html">adal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apis/optim/optim.trainer.trainer.html">trainer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../apis/tracing/index.html">Tracing</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of Tracing</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../apis/tracing/tracing.callback_manager.html">callback_manager</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/tracing/tracing.create.html">create</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/tracing/tracing.decorators.html">decorators</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/tracing/tracing.generator_call_logger.html">generator_call_logger</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/tracing/tracing.generator_state_logger.html">generator_state_logger</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/tracing/tracing.mlflow_integration.html">mlflow_integration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/tracing/tracing.processor_interface.html">processor_interface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/tracing/tracing.scope.html">scope</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/tracing/tracing.setup.html">setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/tracing/tracing.span_data.html">span_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/tracing/tracing.spans.html">spans</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/tracing/tracing.traces.html">traces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/tracing/tracing.util.html">util</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../apis/utils/index.html">Utils</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle navigation of Utils</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../apis/utils/utils.data.html">data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/utils/utils.setup_env.html">setup_env</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/utils/utils.logger.html">logger</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/utils/utils.file_io.html">file_io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/utils/utils.config.html">config</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/utils/utils.lazy_import.html">lazy_import</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/utils/utils.registry.html">registry</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/utils/utils.serialization.html">serialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apis/utils/utils.cache.html">cache</a></li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          

<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <div style="display: flex; justify-content: flex-start; align-items: center; margin-bottom: 20px;">
   <a href="https://colab.research.google.com/drive/1n3mHUWekTEYHiBdYBTw43TKlPN41A9za?usp=sharing" target="_blank" style="margin-right: 10px;">
      <img alt="Try Quickstart in Colab" src="https://colab.research.google.com/assets/colab-badge.svg" style="vertical-align: middle;">
   </a>
   <a href="https://github.com/SylphAI-Inc/AdalFlow/tree/main/use_cases/question_answering/bhh_object_count" target="_blank" style="display: flex; align-items: center;">
      <img src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" alt="GitHub" style="height: 20px; width: 20px; margin-right: 5px;">
      <span style="vertical-align: middle;"> Open Source Code</span>
   </a>
</div><section id="question-answer-with-llm-as-judge">
<h1>Question Answer with LLM as Judge<a class="headerlink" href="#question-answer-with-llm-as-judge" title="Link to this heading">¶</a></h1>
<p>AdalFlow provides token-efficient and high-performing prompt optimization within a unified framework.</p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading">¶</a></h2>
<p>In this tutorial, we will implement and optimize a question-answering task pipeline. Specifically, the task is to count the total number of objects.
Here is an example from the dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">question</span> <span class="o">=</span> <span class="s2">&quot;I have a flute, a piano, a trombone, four stoves, a violin, an accordion, a clarinet, a drum, two lamps, and a trumpet. How many musical instruments do I have?&quot;</span>
</pre></div>
</div>
<p>For optimization, we will demonstrate both the instruction/prompt optimization and few-shot In-context Learning(ICL).</p>
<p><strong>Instruction/prompt Optimization</strong></p>
<p>We especially want to see how the auto-training pipeline performs with both good and bad starting prompts.</p>
<p>With a low-performing starting prompt, our zero-shot optimizer states:</p>
<div class="table-wrapper colwidths-given docutils container" id="id4">
<table class="docutils align-default" id="id4">
<caption><span class="caption-text">Scores by Method and Split On Low-performing Starting Prompt (gpt-3.5-turbo)</span><a class="headerlink" href="#id4" title="Link to this table">¶</a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="head"><p>Train</p></th>
<th class="head"><p>Val</p></th>
<th class="head"><p>Test</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Start (manual prompt)</p></td>
<td><p>0.84 (50 samples)</p></td>
<td><p>0.66 (50 samples)</p></td>
<td><p>0.77 (100 samples)</p></td>
</tr>
<tr class="row-odd"><td><p>Optimized Zero-shot</p></td>
<td><p>N/A</p></td>
<td><p>0.9 (<strong>+36%</strong>)</p></td>
<td><p>0.9 (<strong>+25%</strong>)</p></td>
</tr>
</tbody>
</table>
</div>
<p>It converged within 5 steps, with each batch containing only 4 samples.</p>
<div class="table-wrapper colwidths-given docutils container" id="id5">
<table class="docutils align-default" id="id5">
<caption><span class="caption-text">Manual Prompt vs Optimized Prompt (gpt-3.5-turbo)</span><a class="headerlink" href="#id5" title="Link to this table">¶</a></caption>
<colgroup>
<col style="width: 50.0%" />
<col style="width: 50.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="head"><p>Prompt</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Manual</p></td>
<td><p>You will answer a reasoning question. The last line of your response should be of the following format: ‘Answer: $VALUE’ where VALUE is a numerical value.</p></td>
</tr>
<tr class="row-odd"><td><p>Optimized (zero-shot) (90% on val, 90% on test)</p></td>
<td><p>You will answer a reasoning question by performing detailed and careful counting of each item. Ensure no items, particularly those in plural form, are miscounted. The last line of your response should be formatted as follows: ‘Answer: $VALUE’ where VALUE is a numerical value.</p></td>
</tr>
</tbody>
</table>
</div>
<p>We will also demonstrate how to optimize an already high-performing task pipeline (~90% accuracy) to achieve even better results—a process that would be very challenging with manual prompt optimization.</p>
<div class="table-wrapper colwidths-given docutils container" id="id6">
<table class="docutils align-default" id="id6">
<caption><span class="caption-text">Scores by Method and Split On High-performing Starting Prompt (gpt-3.5-turbo)</span><a class="headerlink" href="#id6" title="Link to this table">¶</a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="head"><p>Train</p></th>
<th class="head"><p>Val</p></th>
<th class="head"><p>Test</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Start (manual prompt)</p></td>
<td><p>0.88 (50 samples)</p></td>
<td><p>0.90 (50 samples)</p></td>
<td><p>0.87 (100 samples)</p></td>
</tr>
<tr class="row-odd"><td><p>Optimized Zero-shot</p></td>
<td><p>N/A</p></td>
<td><p>0.98 (<strong>+8%</strong>)</p></td>
<td><p>0.91 (<strong>+4%</strong>)</p></td>
</tr>
</tbody>
</table>
</div>
<div class="table-wrapper colwidths-given docutils container" id="id7">
<table class="docutils align-default" id="id7">
<caption><span class="caption-text">Manual Prompt vs Optimized Prompt</span><a class="headerlink" href="#id7" title="Link to this table">¶</a></caption>
<colgroup>
<col style="width: 50.0%" />
<col style="width: 50.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="head"><p>Prompt</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Manual</p></td>
<td><p>You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: ‘Answer: $VALUE’ where VALUE is a numerical value.</p></td>
</tr>
<tr class="row-odd"><td><p>Optimized (zero-shot) (92% on val, 91% on test)</p></td>
<td><p>You will answer a reasoning question. Think step by step, and make sure to convert any numbers written in words into numerals. Double-check your calculations. The last line of your response should be of the following format: ‘Answer: $VALUE’ where VALUE is a numerical value.</p></td>
</tr>
<tr class="row-even"><td><p>Optimized (plus generated examples by itself) (98% on val, 91% on test)</p></td>
<td><p>You will answer a reasoning question. Think step by step and double-check each calculation you make. Pay close attention to any numerical quantities in the text, converting written numbers into their numerical equivalents. Additionally, re-verify your final answer before concluding. The last line of your response should be of the following format: ‘Answer: $VALUE’ where VALUE is a numerical value. Here are some examples: 1. I have a flute, a piano, a trombone, four stoves, a violin, an accordion, a clarinet, a drum, two lamps, and a trumpet. How many musical instruments do I have? Answer: 8</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Bootstrap Few-shot</strong></p>
<p>We achieved 94% accuracy on the test split with just one bootstrap shot, using only the demonstration of the teacher model’s response, surpassing the performance of all existing libraries.</p>
<div class="table-wrapper colwidths-given docutils container" id="id8">
<table class="docutils align-default" id="id8">
<caption><span class="caption-text">Optimized Scores comparison on the same prompt on test set (gpt-3.5-turbo)</span><a class="headerlink" href="#id8" title="Link to this table">¶</a></caption>
<colgroup>
<col style="width: 50.0%" />
<col style="width: 50.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="head"><p>Test</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Text-grad (start)</p></td>
<td><p>0.72</p></td>
</tr>
<tr class="row-odd"><td><p>Text-grad (optimized)</p></td>
<td><p>0.89</p></td>
</tr>
<tr class="row-even"><td><p>AdalFlow (start)</p></td>
<td><p>0.87</p></td>
</tr>
<tr class="row-odd"><td><p>AdalFlow(text-grad optimized)</p></td>
<td><p>0.91</p></td>
</tr>
<tr class="row-even"><td><p>AdalFlow (“Learn-to-reason” one-shot)</p></td>
<td><p><strong>0.94</strong></p></td>
</tr>
</tbody>
</table>
</div>
<p>Now, let’s get started on how to implement and achieve the results mentioned above together.</p>
</section>
<section id="build-the-task-pipeline">
<h2>Build the task pipeline<a class="headerlink" href="#build-the-task-pipeline" title="Link to this heading">¶</a></h2>
<p>As we can leverage the optimizer to automatically optimize our task pipeline, we offer a quick way to build it.
We’ll instruct the LLM to respond with a chain of thought and end the response with the format Answer: $VALUE. We will use the following code to process it:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">adalflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">adal</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>

<span class="nd">@adal</span><span class="o">.</span><span class="n">func_to_data_component</span>
<span class="k">def</span><span class="w"> </span><span class="nf">parse_integer_answer</span><span class="p">(</span><span class="n">answer</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A function that parses the last integer from a string using regular expressions.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Use regular expression to find all sequences of digits</span>
        <span class="n">numbers</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\d+&quot;</span><span class="p">,</span> <span class="n">answer</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">numbers</span><span class="p">:</span>
            <span class="c1"># Get the last number found</span>
            <span class="n">answer</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">numbers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">answer</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
        <span class="n">answer</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="k">return</span> <span class="n">answer</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">adal.func_to_data_component</span></code> is a decorator that converts a function to a component so that we can pass it to the generator as a output processor.</p>
<p>For the task, we will use a simple template taking three arguments: <code class="docutils literal notranslate"><span class="pre">system_prompt</span></code>, <code class="docutils literal notranslate"><span class="pre">few_shot_demos</span></code>, and <code class="docutils literal notranslate"><span class="pre">input_str</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">few_shot_template</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;&quot;&quot;&lt;START_OF_SYSTEM_PROMPT&gt;</span>
<span class="s2">{{system_prompt}}</span>
<span class="s2">{# Few shot demos #}</span>
<span class="s2">{</span><span class="si">% i</span><span class="s2">f few_shot_demos is not none %}</span>
<span class="s2">Here are some examples:</span>
<span class="s2">{{few_shot_demos}}</span>
<span class="s2">{</span><span class="si">% e</span><span class="s2">ndif %}</span>
<span class="s2">&lt;END_OF_SYSTEM_PROMPT&gt;</span>
<span class="s2">&lt;START_OF_USER&gt;</span>
<span class="s2">{{input_str}}</span>
<span class="s2">&lt;END_OF_USER&gt;</span>
<span class="s2">&quot;&quot;&quot;</span>
</pre></div>
</div>
<p>We will create two parameters for training the model: <code class="docutils literal notranslate"><span class="pre">system_prompt</span></code> and <code class="docutils literal notranslate"><span class="pre">few_shot_demos</span></code>.
We will initialize the <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> with a <code class="docutils literal notranslate"><span class="pre">role_desc</span></code> and <code class="docutils literal notranslate"><span class="pre">requires_opt</span></code> to inform the <code class="docutils literal notranslate"><span class="pre">backward_engine</span></code> (for feedback/textual gradients) and
the optimizer about the purpose of the parameter.
Additionally, we need to set the <code class="docutils literal notranslate"><span class="pre">param_type</span></code> to <code class="docutils literal notranslate"><span class="pre">ParameterType.PROMPT</span></code> and <code class="docutils literal notranslate"><span class="pre">ParameterType.DEMOS</span></code> so that our trainer can configure the appropriate optimizer to optimize these parameters.</p>
<p>Here is our task pipeline:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Union</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">adalflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">adal</span>


<span class="k">class</span><span class="w"> </span><span class="nc">ObjectCountTaskPipeline</span><span class="p">(</span><span class="n">adal</span><span class="o">.</span><span class="n">Component</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_client</span><span class="p">:</span> <span class="n">adal</span><span class="o">.</span><span class="n">ModelClient</span><span class="p">,</span> <span class="n">model_kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">system_prompt</span> <span class="o">=</span> <span class="n">adal</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">data</span><span class="o">=</span><span class="s2">&quot;You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: &#39;Answer: $VALUE&#39; where VALUE is a numerical value.&quot;</span><span class="p">,</span>
            <span class="n">role_desc</span><span class="o">=</span><span class="s2">&quot;To give task instruction to the language model in the system prompt&quot;</span><span class="p">,</span>
            <span class="n">requires_opt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">param_type</span><span class="o">=</span><span class="n">ParameterType</span><span class="o">.</span><span class="n">PROMPT</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">few_shot_demos</span> <span class="o">=</span> <span class="n">adal</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">role_desc</span><span class="o">=</span><span class="s2">&quot;To provide few shot demos to the language model&quot;</span><span class="p">,</span>
            <span class="n">requires_opt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">param_type</span><span class="o">=</span><span class="n">ParameterType</span><span class="o">.</span><span class="n">DEMOS</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">llm_counter</span> <span class="o">=</span> <span class="n">adal</span><span class="o">.</span><span class="n">Generator</span><span class="p">(</span>
            <span class="n">model_client</span><span class="o">=</span><span class="n">model_client</span><span class="p">,</span>
            <span class="n">model_kwargs</span><span class="o">=</span><span class="n">model_kwargs</span><span class="p">,</span>
            <span class="n">template</span><span class="o">=</span><span class="n">few_shot_template</span><span class="p">,</span>
            <span class="n">prompt_kwargs</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;system_prompt&quot;</span><span class="p">:</span> <span class="n">system_prompt</span><span class="p">,</span>
                <span class="s2">&quot;few_shot_demos&quot;</span><span class="p">:</span> <span class="n">few_shot_demos</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="n">output_processors</span><span class="o">=</span><span class="n">parse_integer_answer</span><span class="p">,</span>
            <span class="n">use_cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">question</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">adal</span><span class="o">.</span><span class="n">GeneratorOutput</span><span class="p">,</span> <span class="n">adal</span><span class="o">.</span><span class="n">Parameter</span><span class="p">]:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm_counter</span><span class="p">(</span><span class="n">prompt_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;input_str&quot;</span><span class="p">:</span> <span class="n">question</span><span class="p">},</span> <span class="nb">id</span><span class="o">=</span><span class="nb">id</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
<p>Here are a few points to keep in mind:</p>
<ol class="arabic simple">
<li><p>Our task pipeline operates in both evaluation and training modes. By default, it will be in evaluation mode and will output a <code class="docutils literal notranslate"><span class="pre">GeneratorOutput</span></code> object.
When in training mode, it will output a <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> object where the data attribute contains the raw output from <code class="docutils literal notranslate"><span class="pre">GeneratorOutput</span></code>.
The entire GeneratorOutput object will be saved in the <code class="docutils literal notranslate"><span class="pre">full_response</span></code> attribute, allowing it to be used later for evaluation.
To specify which input should be passed to the evaluation function, we will assign it to the <code class="docutils literal notranslate"><span class="pre">eval_input</span></code> attribute.</p></li>
<li><p>If we want to train using few-shot in-context learning, we need to assign an <code class="docutils literal notranslate"><span class="pre">id</span></code> to our LLM call. This <code class="docutils literal notranslate"><span class="pre">id</span></code> will be used to trace the few-shot examples automatically.</p></li>
</ol>
<p>Now, let’s pass a <code class="docutils literal notranslate"><span class="pre">gpt-3.5-turbo</span></code> model to our task pipeline and test both training and evaluation modes.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">adalflow.components.model_client.openai_client</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAIClient</span>

<span class="n">adal</span><span class="o">.</span><span class="n">setup_env</span><span class="p">()</span>

<span class="n">gpt_3_model</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;model_client&quot;</span><span class="p">:</span> <span class="n">OpenAIClient</span><span class="p">(),</span>
    <span class="s2">&quot;model_kwargs&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span>
        <span class="s2">&quot;max_tokens&quot;</span><span class="p">:</span> <span class="mi">2000</span><span class="p">,</span>
        <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s2">&quot;top_p&quot;</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">,</span>
        <span class="s2">&quot;frequency_penalty&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s2">&quot;presence_penalty&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s2">&quot;stop&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Here is the code to test the task pipeline:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">question</span> <span class="o">=</span> <span class="s2">&quot;I have a flute, a piano, a trombone, four stoves, a violin, an accordion, a clarinet, a drum, two lamps, and a trumpet. How many musical instruments do I have?&quot;</span>
<span class="n">task_pipeline</span> <span class="o">=</span> <span class="n">ObjectCountTaskPipeline</span><span class="p">(</span><span class="o">**</span><span class="n">gpt_3_model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">task_pipeline</span><span class="p">)</span>

<span class="n">answer</span> <span class="o">=</span> <span class="n">task_pipeline</span><span class="p">(</span><span class="n">question</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">answer</span><span class="p">)</span>

<span class="c1"># set it to train mode</span>
<span class="n">task_pipeline</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">answer</span> <span class="o">=</span> <span class="n">task_pipeline</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="s2">&quot;1&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">answer</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;full_response: </span><span class="si">{</span><span class="n">answer</span><span class="o">.</span><span class="n">full_response</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The answer for the eval mode:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">GeneratorOutput</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">usage</span><span class="o">=</span><span class="n">CompletionUsage</span><span class="p">(</span><span class="n">completion_tokens</span><span class="o">=</span><span class="mi">113</span><span class="p">,</span> <span class="n">prompt_tokens</span><span class="o">=</span><span class="mi">113</span><span class="p">,</span> <span class="n">total_tokens</span><span class="o">=</span><span class="mi">226</span><span class="p">),</span> <span class="n">raw_response</span><span class="o">=</span><span class="s1">&#39;To find the total number of musical instruments you have, you simply need to count the individual instruments you listed. </span><span class="se">\n\n</span><span class="s1">Counting the instruments:</span><span class="se">\n</span><span class="s1">1 flute</span><span class="se">\n</span><span class="s1">1 piano</span><span class="se">\n</span><span class="s1">1 trombone</span><span class="se">\n</span><span class="s1">1 violin</span><span class="se">\n</span><span class="s1">1 accordion</span><span class="se">\n</span><span class="s1">1 clarinet</span><span class="se">\n</span><span class="s1">1 drum</span><span class="se">\n</span><span class="s1">1 trumpet</span><span class="se">\n\n</span><span class="s1">Adding the number of stoves and lamps, which are not musical instruments:</span><span class="se">\n</span><span class="s1">4 stoves</span><span class="se">\n</span><span class="s1">2 lamps</span><span class="se">\n\n</span><span class="s1">Total number of musical instruments = 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 = 8</span><span class="se">\n\n</span><span class="s1">Answer: 8&#39;</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
<p>The answer for the train mode:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Parameter</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">Generator_output</span><span class="p">,</span> <span class="n">requires_opt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">param_type</span><span class="o">=</span><span class="n">generator_output</span> <span class="p">(</span><span class="n">The</span> <span class="n">output</span> <span class="n">of</span> <span class="n">the</span> <span class="n">generator</span><span class="o">.</span><span class="p">),</span> <span class="n">role_desc</span><span class="o">=</span><span class="n">Output</span> <span class="kn">from</span><span class="w"> </span><span class="p">(</span><span class="n">llm</span><span class="p">)</span> <span class="n">Generator</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">To</span> <span class="n">find</span> <span class="n">the</span> <span class="n">total</span> <span class="n">number</span> <span class="n">of</span> <span class="n">musical</span> <span class="n">instruments</span> <span class="n">you</span> <span class="n">have</span><span class="p">,</span> <span class="n">you</span> <span class="n">simply</span> <span class="n">need</span> <span class="n">to</span> <span class="n">count</span> <span class="n">the</span> <span class="n">individual</span> <span class="n">instruments</span> <span class="n">you</span> <span class="n">listed</span><span class="o">.</span>

<span class="n">Counting</span> <span class="n">the</span> <span class="n">instruments</span><span class="p">:</span>
<span class="mi">1</span> <span class="n">flute</span>
<span class="mi">1</span> <span class="n">piano</span>
<span class="mi">1</span> <span class="n">trombone</span>
<span class="mi">1</span> <span class="n">violin</span>
<span class="mi">1</span> <span class="n">accordion</span>
<span class="mi">1</span> <span class="n">clarinet</span>
<span class="mi">1</span> <span class="n">drum</span>
<span class="mi">1</span> <span class="n">trumpet</span>

<span class="n">Adding</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">stoves</span> <span class="ow">and</span> <span class="n">lamps</span><span class="p">,</span> <span class="n">which</span> <span class="n">are</span> <span class="ow">not</span> <span class="n">musical</span> <span class="n">instruments</span><span class="p">:</span>
<span class="mi">4</span> <span class="n">stoves</span>
<span class="mi">2</span> <span class="n">lamps</span>

<span class="n">Total</span> <span class="n">number</span> <span class="n">of</span> <span class="n">musical</span> <span class="n">instruments</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">=</span> <span class="mi">8</span>

<span class="n">Answer</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="n">predecessors</span><span class="o">=</span><span class="p">{</span><span class="n">Parameter</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">To_give_ta</span><span class="p">,</span> <span class="n">requires_opt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">param_type</span><span class="o">=</span><span class="n">prompt</span> <span class="p">(</span><span class="n">Instruction</span> <span class="n">to</span> <span class="n">the</span> <span class="n">language</span> <span class="n">model</span> <span class="n">on</span> <span class="n">task</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="ow">and</span> <span class="nb">format</span><span class="o">.</span><span class="p">),</span> <span class="n">role_desc</span><span class="o">=</span><span class="n">To</span> <span class="n">give</span> <span class="n">task</span> <span class="n">instruction</span> <span class="n">to</span> <span class="n">the</span> <span class="n">language</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">system</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">You</span> <span class="n">will</span> <span class="n">answer</span> <span class="n">a</span> <span class="n">reasoning</span> <span class="n">question</span><span class="o">.</span> <span class="n">Think</span> <span class="n">step</span> <span class="n">by</span> <span class="n">step</span><span class="o">.</span> <span class="n">The</span> <span class="n">last</span> <span class="n">line</span> <span class="n">of</span> <span class="n">your</span> <span class="n">response</span> <span class="n">should</span> <span class="n">be</span> <span class="n">of</span> <span class="n">the</span> <span class="n">following</span> <span class="nb">format</span><span class="p">:</span> <span class="s1">&#39;Answer: $VALUE&#39;</span> <span class="n">where</span> <span class="n">VALUE</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">numerical</span> <span class="n">value</span><span class="o">.</span><span class="p">,</span> <span class="n">predecessors</span><span class="o">=</span><span class="nb">set</span><span class="p">(),</span> <span class="n">gradients</span><span class="o">=</span><span class="nb">set</span><span class="p">(),</span>            <span class="n">raw_response</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">traces</span><span class="o">=</span><span class="p">{}),</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">To_provide</span><span class="p">,</span> <span class="n">requires_opt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">param_type</span><span class="o">=</span><span class="n">demos</span> <span class="p">(</span><span class="n">A</span> <span class="n">few</span> <span class="n">examples</span> <span class="n">to</span> <span class="n">guide</span> <span class="n">the</span> <span class="n">language</span> <span class="n">model</span><span class="o">.</span><span class="p">),</span> <span class="n">role_desc</span><span class="o">=</span><span class="n">To</span> <span class="n">provide</span> <span class="n">few</span> <span class="n">shot</span> <span class="n">demos</span> <span class="n">to</span> <span class="n">the</span> <span class="n">language</span> <span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">predecessors</span><span class="o">=</span><span class="nb">set</span><span class="p">(),</span> <span class="n">gradients</span><span class="o">=</span><span class="nb">set</span><span class="p">(),</span>            <span class="n">raw_response</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">traces</span><span class="o">=</span><span class="p">{})},</span> <span class="n">gradients</span><span class="o">=</span><span class="nb">set</span><span class="p">(),</span>            <span class="n">raw_response</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;prompt_kwargs&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;system_prompt&#39;</span><span class="p">:</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">To_give_ta</span><span class="p">,</span> <span class="n">requires_opt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">param_type</span><span class="o">=</span><span class="n">prompt</span> <span class="p">(</span><span class="n">Instruction</span> <span class="n">to</span> <span class="n">the</span> <span class="n">language</span> <span class="n">model</span> <span class="n">on</span> <span class="n">task</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="ow">and</span> <span class="nb">format</span><span class="o">.</span><span class="p">),</span> <span class="n">role_desc</span><span class="o">=</span><span class="n">To</span> <span class="n">give</span> <span class="n">task</span> <span class="n">instruction</span> <span class="n">to</span> <span class="n">the</span> <span class="n">language</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">system</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">You</span> <span class="n">will</span> <span class="n">answer</span> <span class="n">a</span> <span class="n">reasoning</span> <span class="n">question</span><span class="o">.</span> <span class="n">Think</span> <span class="n">step</span> <span class="n">by</span> <span class="n">step</span><span class="o">.</span> <span class="n">The</span> <span class="n">last</span> <span class="n">line</span> <span class="n">of</span> <span class="n">your</span> <span class="n">response</span> <span class="n">should</span> <span class="n">be</span> <span class="n">of</span> <span class="n">the</span> <span class="n">following</span> <span class="nb">format</span><span class="p">:</span> <span class="s1">&#39;Answer: $VALUE&#39;</span> <span class="n">where</span> <span class="n">VALUE</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">numerical</span> <span class="n">value</span><span class="o">.</span><span class="p">,</span> <span class="n">predecessors</span><span class="o">=</span><span class="nb">set</span><span class="p">(),</span> <span class="n">gradients</span><span class="o">=</span><span class="nb">set</span><span class="p">(),</span>            <span class="n">raw_response</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">traces</span><span class="o">=</span><span class="p">{}),</span> <span class="s1">&#39;few_shot_demos&#39;</span><span class="p">:</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">To_provide</span><span class="p">,</span> <span class="n">requires_opt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">param_type</span><span class="o">=</span><span class="n">demos</span> <span class="p">(</span><span class="n">A</span> <span class="n">few</span> <span class="n">examples</span> <span class="n">to</span> <span class="n">guide</span> <span class="n">the</span> <span class="n">language</span> <span class="n">model</span><span class="o">.</span><span class="p">),</span> <span class="n">role_desc</span><span class="o">=</span><span class="n">To</span> <span class="n">provide</span> <span class="n">few</span> <span class="n">shot</span> <span class="n">demos</span> <span class="n">to</span> <span class="n">the</span> <span class="n">language</span> <span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">predecessors</span><span class="o">=</span><span class="nb">set</span><span class="p">(),</span> <span class="n">gradients</span><span class="o">=</span><span class="nb">set</span><span class="p">(),</span>            <span class="n">raw_response</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">traces</span><span class="o">=</span><span class="p">{}),</span> <span class="s1">&#39;input_str&#39;</span><span class="p">:</span> <span class="s1">&#39;I have a flute, a piano, a trombone, four stoves, a violin, an accordion, a clarinet, a drum, two lamps, and a trumpet. How many musical instruments do I have?&#39;</span><span class="p">},</span> <span class="s1">&#39;model_kwargs&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;model&#39;</span><span class="p">:</span> <span class="s1">&#39;gpt-3.5-turbo&#39;</span><span class="p">,</span> <span class="s1">&#39;max_tokens&#39;</span><span class="p">:</span> <span class="mi">2000</span><span class="p">,</span> <span class="s1">&#39;temperature&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;top_p&#39;</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">,</span> <span class="s1">&#39;frequency_penalty&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;presence_penalty&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;stop&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">}},</span> <span class="n">traces</span><span class="o">=</span><span class="p">{})</span>
</pre></div>
</div>
<p>So far, we have completed the task pipeline and ensured it works in both evaluation and training modes. Of course, if the performance is already perfect, there may be no need for further training, but evaluation is still essential.</p>
<p>Our training pipeline can assist with both training and evaluation.</p>
</section>
<section id="evaluate-the-task-pipeline">
<h2>Evaluate the task pipeline<a class="headerlink" href="#evaluate-the-task-pipeline" title="Link to this heading">¶</a></h2>
<p>Before we start the training, we should prepare three datasets: train, validation, and test datasets. An initial evaluation is necessary to check two things:</p>
<ol class="arabic simple">
<li><p><strong>Overall Performance on Each Data Split:</strong> We need to assess the performance on each data split. If the accuracy does not meet the required standards, we must plan for further evaluation and adjustments.</p></li>
<li><p><strong>Performance Consistency Across Datasets:</strong> We need to ensure that each split (train, validation, and test) performs comparably. This consistency is crucial so that the train and validation sets can serve as reliable indicators of test performance.</p></li>
</ol>
<section id="datasets">
<h3>Datasets<a class="headerlink" href="#datasets" title="Link to this heading">¶</a></h3>
<p>We have prepared the dataset at <code class="docutils literal notranslate"><span class="pre">adalflow.datasets.big_bench_hard</span></code>.
We can load it with the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">adalflow.datasets.big_bench_hard</span><span class="w"> </span><span class="kn">import</span> <span class="n">BigBenchHard</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">adalflow.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">subset_dataset</span>

<span class="k">def</span><span class="w"> </span><span class="nf">load_datasets</span><span class="p">(</span><span class="n">max_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load the dataset&quot;&quot;&quot;</span>
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">BigBenchHard</span><span class="p">(</span><span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="n">val_data</span> <span class="o">=</span> <span class="n">BigBenchHard</span><span class="p">(</span><span class="n">split</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">)</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="n">BigBenchHard</span><span class="p">(</span><span class="n">split</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>

    <span class="c1"># Limit the number of samples</span>
    <span class="k">if</span> <span class="n">max_samples</span><span class="p">:</span>
        <span class="n">train_data</span> <span class="o">=</span> <span class="n">subset_dataset</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">max_samples</span><span class="p">)</span>
        <span class="n">val_data</span> <span class="o">=</span> <span class="n">subset_dataset</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">max_samples</span><span class="p">)</span>
        <span class="n">test_data</span> <span class="o">=</span> <span class="n">subset_dataset</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">max_samples</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">test_data</span>
</pre></div>
</div>
<p>We have 50, 50, 100 samples in the train, val, and test datasets, respectively. Here is one example of the loaded data sample:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Example</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s1">&#39;b0cffa3e-9dc8-4d8e-82e6-9dd7d34128df&#39;</span><span class="p">,</span> <span class="n">question</span><span class="o">=</span><span class="s1">&#39;I have a flute, a piano, a trombone, four stoves, a violin, an accordion, a clarinet, a drum, two lamps, and a trumpet. How many musical instruments do I have?&#39;</span><span class="p">,</span> <span class="n">answer</span><span class="o">=</span><span class="s1">&#39;8&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The data sample is already of type <code class="docutils literal notranslate"><span class="pre">DataClass</span></code> and each sample is assigned with an <code class="docutils literal notranslate"><span class="pre">id</span></code>, a <code class="docutils literal notranslate"><span class="pre">question</span></code>, and an <code class="docutils literal notranslate"><span class="pre">answer</span></code>.
To note that the answer is in <cite>str</cite> format.</p>
</section>
<section id="diagnose-the-task-pipeline">
<h3>Diagnose the task pipeline<a class="headerlink" href="#diagnose-the-task-pipeline" title="Link to this heading">¶</a></h3>
<p>To evaluate the task pipeline using the <a class="reference internal" href="../apis/optim/optim.trainer.trainer.html#optim.trainer.trainer.Trainer" title="optim.trainer.trainer.Trainer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">diagnose</span></code></a> method provided by our trainer,
we can take advantage of the <a class="reference internal" href="../apis/optim/optim.trainer.adal.html#optim.trainer.adal.AdalComponent" title="optim.trainer.adal.AdalComponent"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdalComponent</span></code></a> interface.
This interface class should be subclassed, allowing us to leverage its parallel processing capabilities, callback configuration, optimizer configuration, and built-in support for the teacher/backward engine. The AdalComponent works similarly to how PyTorch Lightning’s LightningModule interacts with its Trainer.</p>
<p>Here’s the minimum code required to get started on evaluating the task pipeline:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">adalflow.datasets.types</span><span class="w"> </span><span class="kn">import</span> <span class="n">Example</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">adalflow.eval.answer_match_acc</span><span class="w"> </span><span class="kn">import</span> <span class="n">AnswerMatchAcc</span>


<span class="k">class</span><span class="w"> </span><span class="nc">ObjectCountAdalComponent</span><span class="p">(</span><span class="n">adal</span><span class="o">.</span><span class="n">AdalComponent</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_client</span><span class="p">:</span> <span class="n">adal</span><span class="o">.</span><span class="n">ModelClient</span><span class="p">,</span> <span class="n">model_kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">):</span>
        <span class="n">task</span> <span class="o">=</span> <span class="n">ObjectCountTaskPipeline</span><span class="p">(</span><span class="n">model_client</span><span class="p">,</span> <span class="n">model_kwargs</span><span class="p">)</span>
        <span class="n">eval_fn</span> <span class="o">=</span> <span class="n">AnswerMatchAcc</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;exact_match&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">compute_single_item</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="n">task</span><span class="p">,</span> <span class="n">eval_fn</span><span class="o">=</span><span class="n">eval_fn</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">handle_one_task_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">:</span> <span class="n">Example</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">call</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="n">sample</span><span class="o">.</span><span class="n">question</span><span class="p">,</span> <span class="s2">&quot;id&quot;</span><span class="p">:</span> <span class="n">sample</span><span class="o">.</span><span class="n">id</span><span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate_one_sample</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">:</span> <span class="n">Example</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">:</span> <span class="n">adal</span><span class="o">.</span><span class="n">GeneratorOutput</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="n">y_label</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">y_pred</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>  <span class="c1"># if y_pred and y_pred.data: might introduce bug when the data is 0</span>
            <span class="n">y_label</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">data</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_fn</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y_label</span><span class="p">,</span> <span class="n">y_gt</span><span class="o">=</span><span class="n">sample</span><span class="o">.</span><span class="n">answer</span><span class="p">)</span>
</pre></div>
</div>
<p>Now, lets use the trainer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">diagnose</span><span class="p">(</span>
    <span class="n">model_client</span><span class="p">:</span> <span class="n">adal</span><span class="o">.</span><span class="n">ModelClient</span><span class="p">,</span>
    <span class="n">model_kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">use_cases.question_answering.bhh_object_count.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_datasets</span>

    <span class="n">trainset</span><span class="p">,</span> <span class="n">valset</span><span class="p">,</span> <span class="n">testset</span> <span class="o">=</span> <span class="n">load_datasets</span><span class="p">()</span>

    <span class="n">adal_component</span> <span class="o">=</span> <span class="n">ObjectCountAdalComponent</span><span class="p">(</span><span class="n">model_client</span><span class="p">,</span> <span class="n">model_kwargs</span><span class="p">)</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">adal</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">adaltask</span><span class="o">=</span><span class="n">adal_component</span><span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">diagnose</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">trainset</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">diagnose</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">valset</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">diagnose</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">testset</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>File structure:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>.adalflow/
├──<span class="w"> </span>ckpt/
│<span class="w">   </span>└──<span class="w"> </span>ObjectCountAdalComponent/
│<span class="w">       </span>├──<span class="w"> </span>diagnose_<span class="o">{</span>train,<span class="w"> </span>val,<span class="w"> </span>test<span class="o">}</span>/<span class="w">  </span><span class="c1"># Directory for training data diagnostics</span>
│<span class="w">       </span>│<span class="w">   </span>├──<span class="w"> </span>llm_counter_call.jsonl<span class="w">    </span><span class="c1"># Sorted by score from lowest to highest</span>
│<span class="w">       </span>│<span class="w">   </span>├──<span class="w"> </span>logger_metadata.jsonl
│<span class="w">       </span>│<span class="w">   </span>├──<span class="w"> </span>llm_counter_diagnose.json<span class="w"> </span><span class="c1"># Contains samples with score &lt; 0.5, sorted by score</span>
│<span class="w">       </span>│<span class="w">   </span>└──<span class="w"> </span>stats.json
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As we save all data in default at <cite>~/.adalflow</cite>, you can create a soft link to the current directory to access the data easily
in your code editor.</p>
</div>
<p>The <cite>llm_counter_call.jsonl</cite> file will contain 6 keys:</p>
<ol class="arabic simple">
<li><p>“prompt_kwargs”: the prompt_kwargs used in the call of <code class="docutils literal notranslate"><span class="pre">llm_counter</span></code>.</p></li>
<li><p>“model_kwargs”: the model_kwargs used in the call of <code class="docutils literal notranslate"><span class="pre">llm_counter</span></code>.</p></li>
<li><p>“input”: Everything that passed to the model_client (LLM).</p></li>
<li><p>“output”: GeneratorOutput object.</p></li>
<li><p>“score”: the performance score of the model on the dataset split.</p></li>
<li><p>“time_stamp”: the time stamp of the call.</p></li>
</ol>
<p>The items are ranked from the lowest to the highest score. The score is the performance score of the model on the dataset split.
If you have passed the <code class="docutils literal notranslate"><span class="pre">id</span></code> to the call, you will find it in the <code class="docutils literal notranslate"><span class="pre">output</span></code>.</p>
<p>In the <code class="docutils literal notranslate"><span class="pre">{}_diagnose.json</span></code> file, we save what can be used to manually diagnose the errors:
- “id”: the id of the sample.
- “score”: the performance score of the model on the dataset split.
- “prompt_kwargs”: the prompt_kwargs used in the call of <code class="docutils literal notranslate"><span class="pre">llm_counter</span></code>.
- “raw_response”: the raw_response of the model.
- “answer”: the answer of the sample.
- “dataset_item”: the dataset item where you can find sample to compare with.</p>
<p>Here is the stats:</p>
<div class="table-wrapper docutils container" id="id9">
<table class="docutils align-default" id="id9">
<caption><span class="caption-text">Scores by Split</span><a class="headerlink" href="#id9" title="Link to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Split</p></th>
<th class="head"><p>Train</p></th>
<th class="head"><p>Val</p></th>
<th class="head"><p>Test</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Score</p></td>
<td><p>0.88 (50)</p></td>
<td><p>0.90 (50)</p></td>
<td><p>0.87 (100)</p></td>
</tr>
</tbody>
</table>
</div>
<p>The model already performs quite well on the dataset.
Let’s see if we can optimize it further with either few-shot or zero-shot prompt optimization or even both.</p>
</section>
</section>
<section id="train-setup">
<h2>Train Setup<a class="headerlink" href="#train-setup" title="Link to this heading">¶</a></h2>
<section id="prepare-adalcomponent-for-training">
<h3>Prepare AdalComponent for training<a class="headerlink" href="#prepare-adalcomponent-for-training" title="Link to this heading">¶</a></h3>
<p>To be able to train, we will add a few attributes and define a few methods in our <code class="docutils literal notranslate"><span class="pre">ObjectCountAdalComponent</span></code> class.</p>
<p>First, <code class="docutils literal notranslate"><span class="pre">loss_fn</span></code> where we use <code class="docutils literal notranslate"><span class="pre">ada.EvalFnToTextLoss</span></code> to compute the loss(<code class="docutils literal notranslate"><span class="pre">Parameter</span></code>) where it takes the <code class="docutils literal notranslate"><span class="pre">eval_fn</span></code> and the <code class="docutils literal notranslate"><span class="pre">eval_fn_desc</span></code> at the initialization.
This loss function will pass whatever user set at <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> to the <code class="docutils literal notranslate"><span class="pre">eval_fn</span></code> and compute the loss and handle the <code class="docutils literal notranslate"><span class="pre">textual</span> <span class="pre">gradient</span></code> for the loss function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">ObjectCountAdalComponent</span><span class="p">(</span><span class="n">adal</span><span class="o">.</span><span class="n">AdalComponent</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_client</span><span class="p">:</span> <span class="n">adal</span><span class="o">.</span><span class="n">ModelClient</span><span class="p">,</span>
        <span class="n">model_kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">backward_engine_model_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">teacher_model_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">text_optimizer_model_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">task</span> <span class="o">=</span> <span class="n">ObjectCountTaskPipeline</span><span class="p">(</span><span class="n">model_client</span><span class="p">,</span> <span class="n">model_kwargs</span><span class="p">)</span>
        <span class="n">eval_fn</span> <span class="o">=</span> <span class="n">AnswerMatchAcc</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;exact_match&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">compute_single_item</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">adal</span><span class="o">.</span><span class="n">EvalFnToTextLoss</span><span class="p">(</span>
            <span class="n">eval_fn</span><span class="o">=</span><span class="n">eval_fn</span><span class="p">,</span>
            <span class="n">eval_fn_desc</span><span class="o">=</span><span class="s2">&quot;exact_match: 1 if str(y) == str(y_gt) else 0&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="n">task</span><span class="p">,</span> <span class="n">eval_fn</span><span class="o">=</span><span class="n">eval_fn</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">backward_engine_model_config</span> <span class="o">=</span> <span class="n">backward_engine_model_config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">teacher_model_config</span> <span class="o">=</span> <span class="n">teacher_model_config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_optimizer_model_config</span> <span class="o">=</span> <span class="n">text_optimizer_model_config</span>
</pre></div>
</div>
<p>Second, <code class="xref py py-meth docutils literal notranslate"><span class="pre">handle_one_loss_sample()</span></code> where we will return the loss function and the <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> to the loss function.
We need to convert the the ground truth into a <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> and set the <code class="docutils literal notranslate"><span class="pre">eval_input</span></code> that will be used as value to the <code class="docutils literal notranslate"><span class="pre">eval_fn</span></code>
when we evaluate the model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">handle_one_loss_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">:</span> <span class="n">Example</span><span class="p">,</span> <span class="n">pred</span><span class="p">:</span> <span class="n">adal</span><span class="o">.</span><span class="n">Parameter</span><span class="p">):</span>
    <span class="c1"># prepare gt parameter</span>
    <span class="n">y_gt</span> <span class="o">=</span> <span class="n">adal</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;y_gt&quot;</span><span class="p">,</span>
        <span class="n">data</span><span class="o">=</span><span class="n">sample</span><span class="o">.</span><span class="n">answer</span><span class="p">,</span>
        <span class="n">eval_input</span><span class="o">=</span><span class="n">sample</span><span class="o">.</span><span class="n">answer</span><span class="p">,</span>
        <span class="n">requires_opt</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># pred&#39;s full_response is the output of the task pipeline which is GeneratorOutput</span>
    <span class="n">pred</span><span class="o">.</span><span class="n">eval_input</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">full_response</span><span class="o">.</span><span class="n">data</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;kwargs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">pred</span><span class="p">,</span> <span class="s2">&quot;y_gt&quot;</span><span class="p">:</span> <span class="n">y_gt</span><span class="p">}}</span>
</pre></div>
</div>
<p>Third, if you intent to train <code class="docutils literal notranslate"><span class="pre">ParameterType.PROMPT</span></code>, we will need to set the <code class="docutils literal notranslate"><span class="pre">backward_engine</span></code> which is a subclass of <code class="docutils literal notranslate"><span class="pre">Generator</span></code> with its own <code class="docutils literal notranslate"><span class="pre">template</span></code>.
We provided a <code class="docutils literal notranslate"><span class="pre">configure_backward_engine_helper</span></code> method to smooth this setup; it requires only the <code class="docutils literal notranslate"><span class="pre">model_client</span></code> and the <code class="docutils literal notranslate"><span class="pre">model_kwargs</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">configure_backward_engine</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">configure_backward_engine_helper</span><span class="p">(</span>
        <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">backward_engine_model_config</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>If we also need to train the <code class="docutils literal notranslate"><span class="pre">ParameterType.DEMOS</span></code>, we will need to set the <code class="docutils literal notranslate"><span class="pre">teacher_generator</span></code> which is exactly the same setup as your <code class="docutils literal notranslate"><span class="pre">llm_counter</span></code> but
with your configured <code class="docutils literal notranslate"><span class="pre">model_client</span></code> and <code class="docutils literal notranslate"><span class="pre">model_kwargs</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">configure_teacher_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">configure_teacher_generator_helper</span><span class="p">(</span>
        <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">teacher_generator_model_config</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>Finally, we need to configure the optimizer. We will use both the <code class="docutils literal notranslate"><span class="pre">DemoOptimizer</span></code> (in default configured with <code class="docutils literal notranslate"><span class="pre">adal.optim.few_shot.few_shot_optimizer.BootstrapFewShot</span></code>) and the <code class="docutils literal notranslate"><span class="pre">PromptOptimizer</span></code> (in default configured with <code class="docutils literal notranslate"><span class="pre">adal.optim.text_grad.tgd_optimizer.TGDOptimizer</span></code>).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">to</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">configure_text_optimizer_helper</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">text_optimizer_model_config</span><span class="p">)</span>
    <span class="n">do</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">configure_demo_optimizer_helper</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">to</span>  <span class="o">+</span> <span class="n">do</span>
</pre></div>
</div>
</section>
<section id="use-the-trainer">
<h3>Use the trainer<a class="headerlink" href="#use-the-trainer" title="Link to this heading">¶</a></h3>
<p>Now, we can use the trainer to train the model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span>
    <span class="n">train_batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>  <span class="c1"># larger batch size is not that effective, probably because of llm&#39;s lost in the middle</span>
    <span class="n">raw_shots</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">bootstrap_shots</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">max_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;random&quot;</span><span class="p">,</span>
    <span class="n">debug</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">adal_component</span> <span class="o">=</span> <span class="n">ObjectCountAdalComponent</span><span class="p">(</span>
        <span class="o">**</span><span class="n">gpt_3_model</span><span class="p">,</span>
        <span class="n">teacher_model_config</span><span class="o">=</span><span class="n">gpt_4o_model</span><span class="p">,</span>
        <span class="n">text_optimizer_model_config</span><span class="o">=</span><span class="n">gpt_4o_model</span><span class="p">,</span>
        <span class="n">backward_engine_model_config</span><span class="o">=</span><span class="n">gpt_4o_model</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">adal_component</span><span class="p">)</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
        <span class="n">train_batch_size</span><span class="o">=</span><span class="n">train_batch_size</span><span class="p">,</span>
        <span class="n">strategy</span><span class="o">=</span><span class="n">strategy</span><span class="p">,</span>
        <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="n">adaltask</span><span class="o">=</span><span class="n">adal_component</span><span class="p">,</span>
        <span class="n">raw_shots</span><span class="o">=</span><span class="n">raw_shots</span><span class="p">,</span>
        <span class="n">bootstrap_shots</span><span class="o">=</span><span class="n">bootstrap_shots</span><span class="p">,</span>
        <span class="n">debug</span><span class="o">=</span><span class="n">debug</span><span class="p">,</span>
        <span class="n">weighted_sampling</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

    <span class="n">train_dataset</span><span class="p">,</span> <span class="n">val_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">load_datasets</span><span class="p">()</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
        <span class="n">val_dataset</span><span class="o">=</span><span class="n">val_dataset</span><span class="p">,</span>
        <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span>
        <span class="n">debug</span><span class="o">=</span><span class="n">debug</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</section>
<section id="train-in-debug-mode">
<h3>Train in Debug mode<a class="headerlink" href="#train-in-debug-mode" title="Link to this heading">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train</span><span class="p">(</span><span class="n">debug</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_steps</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;constrained&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Using the <code class="docutils literal notranslate"><span class="pre">debug</span></code> will show us two samples: one successful and one failed sample.
And it will not only check all necessary steps/methods to try its best to ensure you
have implemented all parts correctly before the training on the whole dataset which can be expensive.
Also, it is important to make sure the <code class="docutils literal notranslate"><span class="pre">backward_engine</span></code> is giving the right feedback and the <code class="docutils literal notranslate"><span class="pre">optimizer</span></code> is
following the instruction to make correct proposal.</p>
<p>Debug mode will turn on the log and set it to <code class="docutils literal notranslate"><span class="pre">DEBUG</span></code> level.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>.adalflow/
├──<span class="w"> </span>ckpt/
│<span class="w">   </span>└──<span class="w"> </span>ObjectCountAdalComponent/
│<span class="w">       </span>├──<span class="w"> </span>diagnose_<span class="o">{</span>train,<span class="w"> </span>val,<span class="w"> </span>test<span class="o">}</span>/<span class="w">  </span><span class="c1"># Directory for training data diagnostics</span>
│<span class="w">       </span>│<span class="w">   </span>├──<span class="w"> </span>llm_counter_call.jsonl<span class="w">    </span><span class="c1"># Sorted by score from lowest to highest</span>
│<span class="w">       </span>│<span class="w">   </span>├──<span class="w"> </span>logger_metadata.jsonl
│<span class="w">       </span>│<span class="w">   </span>├──<span class="w"> </span>llm_counter_diagnose.json<span class="w"> </span><span class="c1"># Contains samples with score &lt; 0.5, sorted by score</span>
│<span class="w">       </span>│<span class="w">   </span>└──<span class="w"> </span>stats.json
│<span class="w">       </span>├──<span class="w"> </span>debug_text_grads<span class="w">                          </span><span class="c1"># Directory for debug mode with text optimizer</span>
│<span class="w">       </span>│<span class="w">   </span>├──<span class="w"> </span>lib.log<span class="w">                    </span><span class="c1"># Log file</span>
│<span class="w">       </span>│<span class="w">   </span>├──<span class="w"> </span>trace_graph_sum.png<span class="w">       </span><span class="c1"># Trace graph with textual feedback and new proposed value</span>
│<span class="w">       </span>│<span class="w">   </span>├──<span class="w"> </span>trace_graph_sum_root.json<span class="w"> </span><span class="c1"># Json representation of the root loss node (sum of the success and fail loss)</span>
</pre></div>
</div>
<p>Here is how our trace_graph looks like: <a class="reference internal" href="../tutorials/trace_graph.html"><span class="doc">trace_graph</span></a>.</p>
</section>
</section>
<section id="train-with-text-gradient-descent">
<h2>Train with Text-Gradient Descent<a class="headerlink" href="#train-with-text-gradient-descent" title="Link to this heading">¶</a></h2>
<p>To train, we simply set the <code class="docutils literal notranslate"><span class="pre">debug</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<p>To do textual-gradient descent training for our task pipeline, we will go back to the task pipeline to set the <cite>requires_opt</cite> to <cite>False</cite> for the <cite>few_shot_demos</cite> parameter and
<cite>requires_opt=True</cite> for the <cite>system_prompt</cite> parameter.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">system_prompt</span> <span class="o">=</span> <span class="n">adal</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">data</span><span class="o">=</span><span class="s2">&quot;You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: &#39;Answer: $VALUE&#39; where VALUE is a numerical value.&quot;</span><span class="p">,</span>
            <span class="n">role_desc</span><span class="o">=</span><span class="s2">&quot;To give task instruction to the language model in the system prompt&quot;</span><span class="p">,</span>
            <span class="n">requires_opt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">param_type</span><span class="o">=</span><span class="n">ParameterType</span><span class="o">.</span><span class="n">PROMPT</span><span class="p">,</span>
        <span class="p">)</span>
<span class="n">few_shot_demos</span> <span class="o">=</span> <span class="n">adal</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">role_desc</span><span class="o">=</span><span class="s2">&quot;To provide few shot demos to the language model&quot;</span><span class="p">,</span>
    <span class="n">requires_opt</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">param_type</span><span class="o">=</span><span class="n">ParameterType</span><span class="o">.</span><span class="n">DEMOS</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>For the text optimizer, we have two training strategy: <code class="docutils literal notranslate"><span class="pre">random</span></code> and <code class="docutils literal notranslate"><span class="pre">constrained</span></code>.
The <code class="docutils literal notranslate"><span class="pre">random</span></code> strategy runs a batch of loss and backward propagation and then validate it on the <code class="docutils literal notranslate"><span class="pre">validation</span></code> and <code class="docutils literal notranslate"><span class="pre">test</span></code> dataset at each step.
This is a standard training strategy, and it is used by libraries like <code class="docutils literal notranslate"><span class="pre">Dspy</span></code> and <code class="docutils literal notranslate"><span class="pre">Text-grad</span></code>.
You can refer <a class="reference internal" href="../apis/optim/optim.trainer.html#optim.trainer.Trainer.fit" title="optim.trainer.Trainer.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">optim.trainer.Trainer.fit()</span></code></a> for more details.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">constrained</span></code> strategy is unique to AdalFlow library where it runs a moving batch capped at maximum 20 samples, and it subsample the correct and failed samples (each maximum at 4).
Before it runs the validations on the full <code class="docutils literal notranslate"><span class="pre">validation</span></code> and <code class="docutils literal notranslate"><span class="pre">test</span></code> dataset, it will run a validation on the moving sampled subset and the moving batch. It will try 5 proposals on the moving batch and only let a proposal that can beat the current subset and moving batch performance before it can be validated on the full dataset.
We find it often more effective than the <code class="docutils literal notranslate"><span class="pre">random</span></code> strategy.</p>
<p>Additionally, we estimate the maximum validataion score each validation can get. Once we know the maximum score is below our minimum requirement (the last highest validation score), we stop the evaluation to save time and cost.</p>
<p>After the training, we will all information saved in <code class="docutils literal notranslate"><span class="pre">.adalflow/ckpt/ObjectCountAdalComponent/</span></code>.
With file names like:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>.adalflow/
├──<span class="w"> </span>ckpt/
│<span class="w">   </span>└──<span class="w"> </span>ObjectCountAdalComponent/
│<span class="w">       </span>random_max_steps_8_bb908_run_1.json<span class="w"> </span><span class="c1"># The last training run for random strategy</span>
│<span class="w">       </span>constrained_max_steps_8_a1754_run_1.json<span class="w"> </span><span class="c1"># The last training run for constrained strategy</span>
</pre></div>
</div>
<p>Here is an example of how our ckpt file looks like: <a class="reference internal" href="../tutorials/ckpt_file.html"><span class="doc">ckpt_file</span></a>.
This file is a direct <cite>to_dict</cite>  (json) representation of <a class="reference internal" href="../apis/optim/optim.types.html#optim.types.TrainerResult" title="optim.types.TrainerResult"><code class="xref py py-class docutils literal notranslate"><span class="pre">TrainerResult</span></code></a>.</p>
</section>
<section id="train-with-few-shot-bootstrap">
<h2>Train with Few-shot Bootstrap<a class="headerlink" href="#train-with-few-shot-bootstrap" title="Link to this heading">¶</a></h2>
<p>As we have defined a <code class="docutils literal notranslate"><span class="pre">ParameterType.DEMOS</span></code> in our <code class="docutils literal notranslate"><span class="pre">ObjectCountAdalComponent</span></code>, we can train the model with few-shot bootstrap.
We will set <code class="docutils literal notranslate"><span class="pre">raw_shots=0</span></code> and <code class="docutils literal notranslate"><span class="pre">bootstrap_shots=1</span></code> in the <code class="docutils literal notranslate"><span class="pre">train</span></code> method.
In default, our demonstrations use the teacher’s direct raw response, with the purpose to teach the weaker model how to reason the answer.
We call this “Learn to reason” few-shot bootstrap.</p>
<p>Note: before we start the training, it will be worth to check if the teacher model is performing better so that the student can learn from the teacher.
We can achieve this using the diagnose method while setting the <cite>model_client</cite> and <cite>model_kwargs</cite> to the teacher model.
Additionally, ensure you set the <cite>split</cite> to <cite>train_teacher</cite> etc to ensure the previous diagnose on the student model is not overwritten.
Here is the teach model performance on the zero-shot prompt:</p>
<div class="table-wrapper colwidths-given docutils container" id="id10">
<table class="docutils align-default" id="id10">
<caption><span class="caption-text">Scores by teacher mode (gpt-4o) on the same high-performing starting prompt</span><a class="headerlink" href="#id10" title="Link to this table">¶</a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="head"><p>Train</p></th>
<th class="head"><p>Val</p></th>
<th class="head"><p>Test</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Start (manual prompt)</p></td>
<td><p>0.98 (50 samples)</p></td>
<td><p>1.0 (50 samples)</p></td>
<td><p>0.98 (100 samples)</p></td>
</tr>
</tbody>
</table>
</div>
<p>We will show how a single demonstration can help push the model performance to 92% on validation and 97% on test.</p>
<p>To do few-shot for our task pipeline, we will go back to the task pipeline to set the <cite>requires_opt</cite> to <cite>True</cite> for the <cite>few_shot_demos</cite> parameter and
turn off the <cite>requires_opt</cite> for the <cite>system_prompt</cite> parameter.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">system_prompt</span> <span class="o">=</span> <span class="n">adal</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">data</span><span class="o">=</span><span class="s2">&quot;You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: &#39;Answer: $VALUE&#39; where VALUE is a numerical value.&quot;</span><span class="p">,</span>
            <span class="n">role_desc</span><span class="o">=</span><span class="s2">&quot;To give task instruction to the language model in the system prompt&quot;</span><span class="p">,</span>
            <span class="n">requires_opt</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">param_type</span><span class="o">=</span><span class="n">ParameterType</span><span class="o">.</span><span class="n">PROMPT</span><span class="p">,</span>
        <span class="p">)</span>
<span class="n">few_shot_demos</span> <span class="o">=</span> <span class="n">adal</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">role_desc</span><span class="o">=</span><span class="s2">&quot;To provide few shot demos to the language model&quot;</span><span class="p">,</span>
    <span class="n">requires_opt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">param_type</span><span class="o">=</span><span class="n">ParameterType</span><span class="o">.</span><span class="n">DEMOS</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Here is our top performing few-shot example:</p>
<div class="table-wrapper colwidths-given docutils container" id="id11">
<table class="docutils align-default" id="id11">
<caption><span class="caption-text">Scores for One-shot Bootstrap</span><a class="headerlink" href="#id11" title="Link to this table">¶</a></caption>
<colgroup>
<col style="width: 10.0%" />
<col style="width: 40.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="head"><p>Prompt</p></th>
<th class="head"><p>Val</p></th>
<th class="head"><p>Test</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Start</p></td>
<td><p>None</p></td>
<td><p>0.90</p></td>
<td><p>0.87</p></td>
</tr>
<tr class="row-odd"><td><p>Optimized One-shot</p></td>
<td><p>“””Example: ‘To find the total number of objects you have, you need to count each individualn  item. In this case, you have:nn  1 microwavenn  1 lampnn  4 carsnn  1 stovenn  1 toasternn  1 bednnn  Adding these together:nn  1 + 1 + 4 + 1 + 1 + 1 = 9nnn  Therefore, you have 9 objects in total.nn  Answer: 9’””</p></td>
<td><p>0.96 (<strong>+6%</strong>, 4% &lt; teacher)</p></td>
<td><p>0.94 (<strong>+7%</strong>, 4% &lt; teacher)</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="benchmarking">
<h2>Benchmarking<a class="headerlink" href="#benchmarking" title="Link to this heading">¶</a></h2>
<p>We compared our performance with text-grad. Here are our stats:
The same prompt, text-grad gets 0.72 on the validation set. and it optimized it to 0.89.
But text-grad use more lengthy prompt, where it takes more than 80s to run a backpropagation on a batch size of 4.
Yet, we only take 12s.
Also AdalFlow has better converage rate in general.
We also leverage single message prompt, sending the whole template to the model’s system message, making this whole development process easy.</p>
<div class="table-wrapper colwidths-given docutils container" id="id12">
<table class="docutils align-default" id="id12">
<caption><span class="caption-text">Optimized Scores comparison on the same prompt on test set (gpt-3.5-turbo)</span><a class="headerlink" href="#id12" title="Link to this table">¶</a></caption>
<colgroup>
<col style="width: 50.0%" />
<col style="width: 50.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="head"><p>Test</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Text-grad (start)</p></td>
<td><p>0.72</p></td>
</tr>
<tr class="row-odd"><td><p>Text-grad (optimized)</p></td>
<td><p>0.89</p></td>
</tr>
<tr class="row-even"><td><p>AdalFlow (start)</p></td>
<td><p>0.87</p></td>
</tr>
<tr class="row-odd"><td><p>AdalFlow(text-grad optimized)</p></td>
<td><p>0.91</p></td>
</tr>
<tr class="row-even"><td><p>AdalFlow (“Learn-to-reason” one-shot)</p></td>
<td><p><strong>0.94</strong></p></td>
</tr>
</tbody>
</table>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In the start we use same prompt but we use a single template which achieves much better zero-shot performance than text-grad which sends the system prompt to system message and the input to user message.</p>
</div>
<div class="highlight admonition">
<p class="admonition-title">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id1" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Text-grad: <a class="reference external" href="https://arxiv.org/abs/2406.07496">https://arxiv.org/abs/2406.07496</a></p>
</aside>
<aside class="footnote brackets" id="id2" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>DsPy: <a class="reference external" href="https://arxiv.org/abs/2310.03714">https://arxiv.org/abs/2310.03714</a></p>
</aside>
<aside class="footnote brackets" id="id3" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>ORPO: <a class="reference external" href="https://arxiv.org/abs/2309.03409">https://arxiv.org/abs/2309.03409</a></p>
</aside>
</aside>
</div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, SylphAI, Inc
            </div>
            Made with 
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Question Answer with LLM as Judge</a><ul>
<li><a class="reference internal" href="#overview">Overview</a></li>
<li><a class="reference internal" href="#build-the-task-pipeline">Build the task pipeline</a></li>
<li><a class="reference internal" href="#evaluate-the-task-pipeline">Evaluate the task pipeline</a><ul>
<li><a class="reference internal" href="#datasets">Datasets</a></li>
<li><a class="reference internal" href="#diagnose-the-task-pipeline">Diagnose the task pipeline</a></li>
</ul>
</li>
<li><a class="reference internal" href="#train-setup">Train Setup</a><ul>
<li><a class="reference internal" href="#prepare-adalcomponent-for-training">Prepare AdalComponent for training</a></li>
<li><a class="reference internal" href="#use-the-trainer">Use the trainer</a></li>
<li><a class="reference internal" href="#train-in-debug-mode">Train in Debug mode</a></li>
</ul>
</li>
<li><a class="reference internal" href="#train-with-text-gradient-descent">Train with Text-Gradient Descent</a></li>
<li><a class="reference internal" href="#train-with-few-shot-bootstrap">Train with Few-shot Bootstrap</a></li>
<li><a class="reference internal" href="#benchmarking">Benchmarking</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../_static/js/rtd_search_config.js"></script>
    <script src="../_static/js/rtd_sphinx_search.min.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>