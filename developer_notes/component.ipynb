{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from lightrag.core import Component, Generator, DataClass\n",
    "from lightrag.components.model_client import OpenAIClient\n",
    "from lightrag.components.model_client import GroqAPIClient\n",
    "\n",
    "# a router and two generators\n",
    "# every single component might need a signature.\n",
    "# TODO: LLM for single choices\n",
    "class MyChatBot(Component):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            model_1_kwargs = {\n",
    "                \"model\": \"gpt-3.5-turbo\",\n",
    "            }\n",
    "            model_2_kwargs = {\n",
    "                 \"model\": \"llama3-8b-8192\"\n",
    "            }\n",
    "            template_doc = r\"\"\"<SYS> You are a doctor </SYS> User: {{input_str}}\"\"\"\n",
    "            template_law = r\"\"\"<SYS> You are a lawyer </SYS> User: {{input_str}}\"\"\"\n",
    "            self.doc = Generator(template=template_doc, model_client=OpenAIClient(), model_kwargs=model_1_kwargs)\n",
    "            self.lawyer = Generator(template=template_law, model_client=GroqAPIClient(), model_kwargs=model_2_kwargs)\n",
    "            self.router_choices = {\n",
    "                \"doctor\": self.create_generator_signature(self.doc),\n",
    "                \"lawyer\": self.create_generator_signature(self.lawyer),\n",
    "                \"other\": \"Choose me the question does not apply to other choices.\"\n",
    "            }\n",
    "            print(self.router_choices)\n",
    "            template_router = r\"\"\"<SYS> You are a router who will route a user question to the right generator.\n",
    "            Here are your choices in form of key: value pairs:\n",
    "             {% for key, value in choices.items() %}\n",
    "                {{ key }}: {{ value }}\n",
    "             {% endfor %}\n",
    "            Output the key of your choice.\n",
    "            </SYS> User question: {{input_str}}\n",
    "            You:\n",
    "            \"\"\"\n",
    "            self.router = Generator(template=template_router, model_client=OpenAIClient(), model_kwargs=model_1_kwargs)\n",
    "\n",
    "            # self.router = \n",
    "        def create_generator_signature(self, generator: Generator):\n",
    "            template = generator.template\n",
    "            pattern = r\"<SYS>(.*?)</SYS>\"\n",
    "\n",
    "            matches = re.findall(pattern, template)\n",
    "            # Print the contents found between <SYS> tags\n",
    "            for match in matches:\n",
    "                print(\"Content between <SYS> tags:\", match)\n",
    "                return match\n",
    "        \n",
    "        \n",
    "        def call(self, query: str):\n",
    "            choice = self.router(prompt_kwargs={\"input_str\": query, \"choices\": self.router_choices}).data\n",
    "            print(f\"Choice: {choice}\")\n",
    "            if choice == \"doctor\":\n",
    "                return self.doc(prompt_kwargs={\"input_str\": query}).data\n",
    "            elif choice == \"lawyer\":\n",
    "                return self.lawyer(prompt_kwargs={\"input_str\": query}).data\n",
    "            else:\n",
    "                return \"Choose me the question does not apply to other choices.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate the task component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content between <SYS> tags:  You are a doctor \n",
      "Content between <SYS> tags:  You are a lawyer \n",
      "{'doctor': ' You are a doctor ', 'lawyer': ' You are a lawyer ', 'other': 'Choose me the question does not apply to other choices.'}\n"
     ]
    }
   ],
   "source": [
    "task = MyChatBot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the structure of generator component and task component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  model_kwargs={'model': 'gpt-3.5-turbo'}, model_type=ModelType.LLM\n",
       "  (system_prompt): Prompt(template: <SYS> You are a doctor </SYS> User: {{input_str}}, prompt_variables: ['input_str'])\n",
       "  (model_client): OpenAIClient()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  model_kwargs={'model': 'llama3-8b-8192'}, model_type=ModelType.LLM\n",
       "  (system_prompt): Prompt(template: <SYS> You are a lawyer </SYS> User: {{input_str}}, prompt_variables: ['input_str'])\n",
       "  (model_client): GroqAPIClient()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.lawyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  model_kwargs={'model': 'gpt-3.5-turbo'}, model_type=ModelType.LLM\n",
       "  (system_prompt): Prompt(\n",
       "    template: <SYS> You are a router who will route a user question to the right generator.\n",
       "                Here are your choices in form of key: value pairs:\n",
       "                 {% for key, value in choices.items() %}\n",
       "                    {{ key }}: {{ value }}\n",
       "                 {% endfor %}\n",
       "                Output the key of your choice.\n",
       "                </SYS> User question: {{input_str}}\n",
       "                You:\n",
       "                , prompt_variables: ['input_str', 'choices']\n",
       "  )\n",
       "  (model_client): OpenAIClient()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyChatBot(\n",
       "  (doc): Generator(\n",
       "    model_kwargs={'model': 'gpt-3.5-turbo'}, model_type=ModelType.LLM\n",
       "    (system_prompt): Prompt(template: <SYS> You are a doctor </SYS> User: {{input_str}}, prompt_variables: ['input_str'])\n",
       "    (model_client): OpenAIClient()\n",
       "  )\n",
       "  (lawyer): Generator(\n",
       "    model_kwargs={'model': 'llama3-8b-8192'}, model_type=ModelType.LLM\n",
       "    (system_prompt): Prompt(template: <SYS> You are a lawyer </SYS> User: {{input_str}}, prompt_variables: ['input_str'])\n",
       "    (model_client): GroqAPIClient()\n",
       "  )\n",
       "  (router): Generator(\n",
       "    model_kwargs={'model': 'gpt-3.5-turbo'}, model_type=ModelType.LLM\n",
       "    (system_prompt): Prompt(\n",
       "      template: <SYS> You are a router who will route a user question to the right generator.\n",
       "                  Here are your choices in form of key: value pairs:\n",
       "                   {% for key, value in choices.items() %}\n",
       "                      {{ key }}: {{ value }}\n",
       "                   {% endfor %}\n",
       "                  Output the key of your choice.\n",
       "                  </SYS> User question: {{input_str}}\n",
       "                  You:\n",
       "                  , prompt_variables: ['input_str', 'choices']\n",
       "    )\n",
       "    (model_client): OpenAIClient()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightrag.utils import enable_library_logging\n",
    "enable_library_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-09 11:38:42 - INFO - [generator.py:194:call] - prompt_kwargs: {'input_str': 'I have a legal question', 'choices': {'doctor': ' You are a doctor ', 'lawyer': ' You are a lawyer ', 'other': 'Choose me the question does not apply to other choices.'}}\n",
      "2024-06-09 11:38:42 - INFO - [generator.py:195:call] - model_kwargs: {}\n",
      "2024-06-09 11:38:42 - INFO - [openai_client.py:122:call] - api_kwargs: {'model': 'gpt-3.5-turbo', 'messages': [{'role': 'system', 'content': '<SYS> You are a router who will route a user question to the right generator.\\n            Here are your choices in form of key: value pairs:\\n                doctor:  You are a doctor \\n                lawyer:  You are a lawyer \\n                other: Choose me the question does not apply to other choices.\\n            Output the key of your choice.\\n            </SYS> User question: I have a legal question\\n            You:'}]}\n",
      "2024-06-09 11:38:42 - INFO - [_client.py:1026:_send_single_request] - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-09 11:38:42 - INFO - [generator.py:203:call] - output: GeneratorOutput(data=None, error=None, raw_response='lawyer')\n",
      "Choice: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Choose me the question does not apply to other choices.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call \n",
    "\n",
    "task.call(\"I have a legal question\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-project-kernel",
   "language": "python",
   "name": "my-project-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
