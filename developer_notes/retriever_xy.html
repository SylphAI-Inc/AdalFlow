
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Retriever &#8212; LightRAG  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=292bc364" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=87e54e7c" />
    <link rel="stylesheet" type="text/css" href="../_static/css/rtd_sphinx_search.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../_static/js/rtd_search_config.js"></script>
    <script src="../_static/js/rtd_sphinx_search.min.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'developer_notes/retriever_xy';</script>
    <link rel="icon" href="../_static/LightRAG-logo-circle.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/LightRAG-logo-doc.jpeg" class="logo__image only-light" alt="LightRAG  documentation - Home"/>
    <script>document.write(`<img src="../_static/LightRAG-logo-doc.jpeg" class="logo__image only-dark" alt="LightRAG  documentation - Home"/>`);</script>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../get_started/index.html">
    Get Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="index.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../tutorials/index.html">
    Use Cases
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../apis/index.html">
    API Reference
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
        </div>
      
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/SylphAI-Inc/LightRAG" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discord.gg/ezzszrRZvT" title="Discord" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discord fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discord</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../get_started/index.html">
    Get Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="index.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../tutorials/index.html">
    Use Cases
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../apis/index.html">
    API Reference
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/SylphAI-Inc/LightRAG" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discord.gg/ezzszrRZvT" title="Discord" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discord fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discord</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page">Retriever</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="retriever">
<h1>Retriever<a class="headerlink" href="#retriever" title="Link to this heading">#</a></h1>
<p>In this tutorial, we will explain each component in <code class="docutils literal notranslate"><span class="pre">LightRAG's</span> <span class="pre">Retriever</span></code> and show you how to implement it in your LLM applications.</p>
<p>LLMs develop fast, but they have limitations.</p>
<p><strong>Content Window Limit:</strong> Although the trend is, LLM models’ content window keeps growing, there is still a context limit.</p>
<p><strong>Signal to Noise Ratio</strong> Meanwhile, LLMs perform better when the provided contents are relevant to the task.</p>
<p>To improve LLMs performances in production, Retrieval Augmented Generation (RAG), a system that augments LLMs by adding extra context from another source, becomes popular.
<strong>Retrieval</strong>, one of the most important components of RAG, is the process to fetch the extra relevant information to the model.
The common solution for Retrieval is to chunk the documents into smaller contexts, store these pieces in databases such as vectorstore, Graph DB and Relational DB depending on the use case, and create significant embedding representations for these chunks in order to retrieve.</p>
<p><code class="docutils literal notranslate"><span class="pre">LightRAG</span></code> aims to find the optimal way to pass the task-requiring data into LLMs.</p>
<section id="document-splitter">
<h2>1. Document Splitter<a class="headerlink" href="#document-splitter" title="Link to this heading">#</a></h2>
<p>The DocumentSplitter in LightRAG is designed to preprocess text by splitting long documents into smaller chunks.
This improves the performance of embedding models and ensures they operate within their maximum context length limits.</p>
<p><code class="docutils literal notranslate"><span class="pre">LightRAG's</span> <span class="pre">DocumentSplitter</span></code> splits a list of documents (<code class="xref py py-obj docutils literal notranslate"><span class="pre">core.base_data_class.Document</span></code>) into a list of shorter documents.
The document object to manage id, document content,optional meta data, document’s embedding vectors, etc.
Instead of maintaining the complex relationship between parent, child, previous, and next documents, <code class="docutils literal notranslate"><span class="pre">LightRAG</span></code> mainly manages the related documents with <code class="docutils literal notranslate"><span class="pre">parent_doc_id</span></code> (id of the Document where the chunk is from) and <code class="docutils literal notranslate"><span class="pre">order</span></code> (order of the chunked document in the original document).</p>
<p><strong>Key Arguments:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">split_by</span></code> is the unit by which the document should be split. We implemented a string split function inside to break the text into a <code class="docutils literal notranslate"><span class="pre">list</span></code>. The splitted <code class="docutils literal notranslate"><span class="pre">list</span></code> will get concatenated based on the specified <code class="docutils literal notranslate"><span class="pre">split_length</span></code> later.</p></li>
</ul>
<p>Check the following table for <code class="docutils literal notranslate"><span class="pre">split_by</span></code> options:</p>
<div class="pst-scrollable-table-container"><table class="table" id="id4">
<caption><span class="caption-text">Text Splitting Options</span><a class="headerlink" href="#id4" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 10.0%" />
<col style="width: 15.0%" />
<col style="width: 75.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Option</p></th>
<th class="head"><p>Split by</p></th>
<th class="head"><p>Example</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>page</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">\f</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Hello,</span> <span class="pre">world!\fNew</span> <span class="pre">page</span> <span class="pre">starts</span> <span class="pre">here.</span></code> to <code class="docutils literal notranslate"><span class="pre">['Hello,</span> <span class="pre">world!\x0c',</span> <span class="pre">'New</span> <span class="pre">page</span> <span class="pre">starts</span> <span class="pre">here.']</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><strong>passage</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">\n\n</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Hello,</span> <span class="pre">world!\n\nNew</span> <span class="pre">paragraph</span> <span class="pre">starts</span> <span class="pre">here</span></code> to <code class="docutils literal notranslate"><span class="pre">['Hello,</span> <span class="pre">world!\n\n',</span> <span class="pre">'New</span> <span class="pre">paragraph</span> <span class="pre">starts</span> <span class="pre">here.']</span></code></p></td>
</tr>
<tr class="row-even"><td><p><strong>sentence</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Hello,</span> <span class="pre">world.</span> <span class="pre">This</span> <span class="pre">is</span> <span class="pre">LightRAG.</span></code> to <code class="docutils literal notranslate"><span class="pre">['Hello,</span> <span class="pre">world.',</span> <span class="pre">'</span> <span class="pre">This</span> <span class="pre">is</span> <span class="pre">LightRAG.',</span> <span class="pre">'']</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><strong>word</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&lt;space&gt;</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Hello,</span> <span class="pre">world.</span> <span class="pre">This</span> <span class="pre">is</span> <span class="pre">LightRAG.</span></code> to <code class="docutils literal notranslate"><span class="pre">['Hello,</span> <span class="pre">',</span> <span class="pre">'world.</span> <span class="pre">',</span> <span class="pre">'This</span> <span class="pre">',</span> <span class="pre">'is</span> <span class="pre">',</span> <span class="pre">'LightRAG.']</span></code></p></td>
</tr>
</tbody>
</table>
</div>
<p>We will use <code class="docutils literal notranslate"><span class="pre">word</span></code> in our example.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">split_length</span></code> is the the maximum number of units in each split.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">split_overlap</span></code> is the number of units that each split should overlap. Including context at the borders prevents sudden meaning shift in text between sentences/context, especially in sentiment analysis. In <code class="docutils literal notranslate"><span class="pre">LightRAG</span></code> we use <code class="docutils literal notranslate"><span class="pre">windowed</span></code> function in <code class="docutils literal notranslate"><span class="pre">more-itertools</span></code> package to build a sliding window for the texts to keep the overlaps. The window step size = <code class="docutils literal notranslate"><span class="pre">split_length</span> <span class="pre">-</span> <span class="pre">split_overlap</span></code>.</p></li>
</ul>
<p>After splitting the long text into a list and using a sliding window to generate the text lists with specified overlap length, the text list will be concatenated into text pieces again.
Here is a quick example:</p>
<p><code class="docutils literal notranslate"><span class="pre">Review:</span> <span class="pre">The</span> <span class="pre">theater</span> <span class="pre">service</span> <span class="pre">is</span> <span class="pre">terrible.</span> <span class="pre">The</span> <span class="pre">movie</span> <span class="pre">is</span> <span class="pre">good.</span></code> Set <code class="docutils literal notranslate"><span class="pre">split_by:</span> <span class="pre">word</span></code>, <code class="docutils literal notranslate"><span class="pre">split_length:</span> <span class="pre">6</span></code>, <code class="docutils literal notranslate"><span class="pre">split_overlap:</span> <span class="pre">2</span></code>.</p>
<p>With our <code class="docutils literal notranslate"><span class="pre">DocumentSplitter</span></code> logic, the output will be: <code class="docutils literal notranslate"><span class="pre">Review:</span> <span class="pre">The</span> <span class="pre">theater</span> <span class="pre">service</span> <span class="pre">is</span> <span class="pre">terrible.</span></code>, <code class="docutils literal notranslate"><span class="pre">is</span> <span class="pre">terrible.</span> <span class="pre">The</span> <span class="pre">movie</span> <span class="pre">is</span> <span class="pre">good.</span></code>
It prevents the model of misunderstand the context. If we don’t have overlap, the second sentence will be <code class="docutils literal notranslate"><span class="pre">The</span> <span class="pre">movie</span> <span class="pre">is</span> <span class="pre">good.</span></code> and the embedding model might only consider this document is merely <code class="docutils literal notranslate"><span class="pre">Positive</span></code>.</p>
<p>Now let’s see the code example. First, import the components.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">core.document_splitter</span> <span class="kn">import</span> <span class="n">DocumentSplitter</span>
<span class="kn">from</span> <span class="nn">core.base_data_class</span> <span class="kn">import</span> <span class="n">Document</span>
</pre></div>
</div>
<p>Then, configure the splitter settings.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">text_splitter_settings</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;split_by&quot;</span><span class="p">:</span> <span class="s2">&quot;word&quot;</span><span class="p">,</span>
    <span class="s2">&quot;split_length&quot;</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span>
    <span class="s2">&quot;split_overlap&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="p">}</span>
</pre></div>
</div>
<p>Next, define the document splitter and set up the documents.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">text_splitter</span> <span class="o">=</span> <span class="n">DocumentSplitter</span><span class="p">(</span>
<span class="n">split_by</span><span class="o">=</span><span class="n">text_splitter_settings</span><span class="p">[</span><span class="s2">&quot;split_by&quot;</span><span class="p">],</span>
<span class="n">split_length</span><span class="o">=</span><span class="n">text_splitter_settings</span><span class="p">[</span><span class="s2">&quot;split_length&quot;</span><span class="p">],</span>
<span class="n">split_overlap</span><span class="o">=</span><span class="n">text_splitter_settings</span><span class="p">[</span><span class="s2">&quot;split_overlap&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">example1</span> <span class="o">=</span> <span class="n">Document</span><span class="p">(</span>
    <span class="n">text</span><span class="o">=</span><span class="s2">&quot;Review: I absolutely loved the friendly staff and the welcoming atmosphere! Sentiment: Positive&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">example2</span> <span class="o">=</span> <span class="n">Document</span><span class="p">(</span>
    <span class="n">text</span><span class="o">=</span><span class="s2">&quot;Review: It was an awful experience, the food was bland and overpriced. Sentiment: Negative&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">example3</span> <span class="o">=</span> <span class="n">Document</span><span class="p">(</span>
    <span class="n">text</span><span class="o">=</span><span class="s2">&quot;Review: What a fantastic movie! Had a great time and would watch it again! Sentiment: Positive&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">example4</span> <span class="o">=</span> <span class="n">Document</span><span class="p">(</span>
    <span class="n">text</span><span class="o">=</span><span class="s2">&quot;Review: The store is not clean and smells bad. Sentiment: Negative&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">documents</span> <span class="o">=</span> <span class="p">[</span><span class="n">example1</span><span class="p">,</span> <span class="n">example2</span><span class="p">,</span> <span class="n">example3</span><span class="p">,</span> <span class="n">example4</span><span class="p">]</span>
</pre></div>
</div>
<p>Now you can use the splitter to create document chunks.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">splitted_docs</span> <span class="o">=</span> <span class="p">(</span><span class="n">text_splitter</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">documents</span><span class="o">=</span><span class="n">documents</span><span class="p">))</span>

<span class="c1"># output:</span>
<span class="c1"># splitted_doc: [Document(id=15d838c4-abda-4c39-b81f-9cd745effb43, meta_data=None, text=Review: I absolutely loved the friendly staff and the welcoming atmosphere! Sentiment: Positive, estimated_num_tokens=17), Document(id=e4850140-8762-4972-9bae-1dfe96ccb65f, meta_data=None, text=Review: It was an awful experience, the food was bland and overpriced. Sentiment: Negative, estimated_num_tokens=21), Document(id=6bd772b9-88b4-4dfa-a595-922c0f8a4efb, meta_data=None, text=Review: What a fantastic movie! Had a great time and would watch it again! Sentiment: , estimated_num_tokens=21), Document(id=b0d98c1b-13ac-4c92-882e-2ed0196b0c81, meta_data=None, text=again! Sentiment: Positive, estimated_num_tokens=6), Document(id=fdc2429b-17e7-4c00-991f-f89e0955e3a3, meta_data=None, text=Review: The store is not clean and smells bad. Sentiment: Negative, estimated_num_tokens=15)]</span>
</pre></div>
</div>
</section>
<section id="embedder">
<h2>2. Embedder<a class="headerlink" href="#embedder" title="Link to this heading">#</a></h2>
<p>Now we have splitted long documents to shorter ones, the next part is to retrieve the relevant documents.
But how can we find “relevant” texts? A commonly applied approach in the NLP field is Embedding.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">Embedder</span></code> tutorial, please check <a class="reference external" href="./embedder.html">Embedder</a>.</p>
</section>
<section id="lightrag-retrievers">
<h2>3. LightRAG Retrievers<a class="headerlink" href="#lightrag-retrievers" title="Link to this heading">#</a></h2>
<p>Given a query, the retriever is responsible to fetch the relevant documents.
Now we have document splitter and embedder, we can check the retrievers now.
LightRAG provides <code class="docutils literal notranslate"><span class="pre">FAISSRetriever</span></code>, <code class="docutils literal notranslate"><span class="pre">BM25Retriever</span></code>, and <code class="docutils literal notranslate"><span class="pre">LLMRetriever</span></code>.
These retrievers are built on the basic <code class="xref py py-class docutils literal notranslate"><span class="pre">Retriever</span></code>, with default index building and retrieve phases.
All these retrievers return a list of <code class="docutils literal notranslate"><span class="pre">RetrieverOutput</span></code>, including indexes, scores, query and documents.</p>
<ol class="arabic simple">
<li><p>FAISSRetriever</p></li>
</ol>
<p>The <code class="docutils literal notranslate"><span class="pre">FAISSRetriever</span></code> uses in-memory Faiss index to retrieve the top k chunks(see <a class="reference external" href="https://github.com/facebookresearch/faiss">research</a>). It is particularly useful in applications involving large-scale vector.
The developers need to configure <code class="docutils literal notranslate"><span class="pre">top_k</span></code>, <code class="docutils literal notranslate"><span class="pre">dimensions</span></code> and <code class="docutils literal notranslate"><span class="pre">vectorizer</span></code> first.
<code class="docutils literal notranslate"><span class="pre">vectorizer</span></code> is basically an instance of the <code class="docutils literal notranslate"><span class="pre">Embedder</span></code>. The <code class="docutils literal notranslate"><span class="pre">FAISSRetriever</span></code> itself will initialize <code class="docutils literal notranslate"><span class="pre">faiss.IndexFlatIP</span></code> with the specified <code class="docutils literal notranslate"><span class="pre">dimensions</span></code> to do <cite>Exact Search for Inner Product</cite>.</p>
<p>LightRAG’s <code class="docutils literal notranslate"><span class="pre">FAISSRetriever</span></code> provides <code class="xref py py-func docutils literal notranslate"><span class="pre">build_index_from_documents</span></code> to create index from embeddings(<code class="docutils literal notranslate"><span class="pre">vector</span></code> field of each document).
It will create <code class="docutils literal notranslate"><span class="pre">xb</span></code> indexes(the same number with embeddings). After the indexes are added, the index state will be <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p>Then, developers can pass the queries to <code class="xref py py-func docutils literal notranslate"><span class="pre">retrieve</span></code>. This function embeds the queries, and performs inner product search for <a href="#id2"><span class="problematic" id="id3">``</span></a>xq``(the number of queries) queries and return k most close vectors.
We choose cosine similarity and convert it to range [0, 1] by adding 1 and dividing by 2 to simulate probability. This is how we calculate the score.
Then we attach the score to each retrieval output.</p>
<p>Then, to speed up the retrieval, it is a common practice to build indexes from the documents or chunks.
When the indexes are ready, we should pass the query to the retriever and get the top k documents closest to the query vector.</p>
<p>Here is an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightrag.core.embedder</span> <span class="kn">import</span> <span class="n">Embedder</span>
<span class="kn">from</span> <span class="nn">lightrag.components.model_client</span> <span class="kn">import</span> <span class="n">OpenAIClient</span>
<span class="kn">from</span> <span class="nn">lightrag.core.data_components</span> <span class="kn">import</span> <span class="n">ToEmbedderResponse</span><span class="p">,</span> <span class="n">ToEmbeddings</span>
<span class="kn">from</span> <span class="nn">lightrag.core.types</span> <span class="kn">import</span> <span class="n">Document</span>
<span class="kn">from</span> <span class="nn">lightrag.core.document_splitter</span> <span class="kn">import</span> <span class="n">DocumentSplitter</span>
<span class="kn">from</span> <span class="nn">lightrag.components.retriever</span> <span class="kn">import</span> <span class="n">FAISSRetriever</span>

<span class="kn">import</span> <span class="nn">dotenv</span>
<span class="n">dotenv</span><span class="o">.</span><span class="n">load_dotenv</span><span class="p">(</span><span class="n">dotenv_path</span><span class="o">=</span><span class="s2">&quot;.env&quot;</span><span class="p">,</span> <span class="n">override</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;KMP_DUPLICATE_LIB_OK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;True&quot;</span>

<span class="c1"># To use ``FAISSRetriever``, we need to prepare the embeddings</span>
<span class="c1"># for documents or chunks following the previous steps.</span>

<span class="c1"># configure the splitter setting</span>
<span class="n">text_splitter_settings</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;split_by&quot;</span><span class="p">:</span> <span class="s2">&quot;word&quot;</span><span class="p">,</span>
        <span class="s2">&quot;split_length&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
        <span class="s2">&quot;split_overlap&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
        <span class="p">}</span>

<span class="c1"># set up the document splitter</span>
<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">DocumentSplitter</span><span class="p">(</span>
    <span class="n">split_by</span><span class="o">=</span><span class="n">text_splitter_settings</span><span class="p">[</span><span class="s2">&quot;split_by&quot;</span><span class="p">],</span>
    <span class="n">split_length</span><span class="o">=</span><span class="n">text_splitter_settings</span><span class="p">[</span><span class="s2">&quot;split_length&quot;</span><span class="p">],</span>
    <span class="n">split_overlap</span><span class="o">=</span><span class="n">text_splitter_settings</span><span class="p">[</span><span class="s2">&quot;split_overlap&quot;</span><span class="p">],</span>
    <span class="p">)</span>

<span class="n">doc1</span> <span class="o">=</span> <span class="n">Document</span><span class="p">(</span>
    <span class="n">meta_data</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="s2">&quot;Luna&#39;s Profile&quot;</span><span class="p">},</span>
    <span class="n">text</span><span class="o">=</span><span class="s2">&quot;lots of more nonsense text.&quot;</span> <span class="o">*</span> <span class="mi">50</span>
    <span class="o">+</span> <span class="s2">&quot;Luna is a domestic shorthair.&quot;</span>
    <span class="o">+</span> <span class="s2">&quot;lots of nonsense text.&quot;</span> <span class="o">*</span> <span class="mi">100</span>
    <span class="o">+</span> <span class="s2">&quot;Luna loves to eat Tuna.&quot;</span>
    <span class="o">+</span> <span class="s2">&quot;lots of nonsense text.&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">,</span>
    <span class="nb">id</span><span class="o">=</span><span class="s2">&quot;doc1&quot;</span><span class="p">,</span>
    <span class="p">)</span>
<span class="n">doc2</span> <span class="o">=</span> <span class="n">Document</span><span class="p">(</span>
    <span class="n">meta_data</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="s2">&quot;Luna&#39;s Hobbies&quot;</span><span class="p">},</span>
    <span class="n">text</span><span class="o">=</span><span class="s2">&quot;lots of more nonsense text.&quot;</span> <span class="o">*</span> <span class="mi">50</span>
    <span class="o">+</span> <span class="s2">&quot;Luna loves to eat lickable treats.&quot;</span>
    <span class="o">+</span> <span class="s2">&quot;lots of more nonsense text.&quot;</span> <span class="o">*</span> <span class="mi">50</span>
    <span class="o">+</span> <span class="s2">&quot;Luna loves to play cat wand.&quot;</span>
    <span class="o">+</span> <span class="s2">&quot;lots of more nonsense text.&quot;</span> <span class="o">*</span> <span class="mi">50</span>
    <span class="o">+</span> <span class="s2">&quot;Luna likes to sleep all the afternoon&quot;</span><span class="p">,</span>
    <span class="nb">id</span><span class="o">=</span><span class="s2">&quot;doc2&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">documents</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc1</span><span class="p">,</span> <span class="n">doc2</span><span class="p">]</span>

<span class="c1"># split the documents</span>
<span class="n">splitted_docs</span> <span class="o">=</span> <span class="p">(</span><span class="n">text_splitter</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">documents</span><span class="o">=</span><span class="n">documents</span><span class="p">))</span>

<span class="c1"># configure the vectorizer(embedding) setting</span>
<span class="n">vectorizer_settings</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;model_kwargs&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;text-embedding-3-small&quot;</span><span class="p">,</span>
        <span class="s2">&quot;dimensions&quot;</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>
        <span class="s2">&quot;encoding_format&quot;</span><span class="p">:</span> <span class="s2">&quot;float&quot;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">100</span>
<span class="p">}</span>

<span class="c1"># set up the embedder using openai model</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">Embedder</span><span class="p">(</span>
        <span class="n">model_client</span><span class="o">=</span><span class="n">OpenAIClient</span><span class="p">,</span>
        <span class="n">model_kwargs</span><span class="o">=</span><span class="n">vectorizer_settings</span><span class="p">[</span><span class="s2">&quot;model_kwargs&quot;</span><span class="p">],</span> <span class="c1"># set up model arguments</span>
        <span class="n">output_processors</span><span class="o">=</span><span class="n">ToEmbedderResponse</span><span class="p">(),</span> <span class="c1"># convert the model output to EmbedderResponse</span>
    <span class="p">)</span>
<span class="c1"># Prepare embeddings for the documents</span>
<span class="n">embedder_response_processor</span> <span class="o">=</span> <span class="n">ToEmbeddings</span><span class="p">(</span>
    <span class="n">vectorizer</span><span class="o">=</span><span class="n">vectorizer</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">vectorizer_settings</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="c1"># Apply embedding transformation</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">embedder_response_processor</span><span class="p">(</span><span class="n">splitted_docs</span><span class="p">)</span>

<span class="c1"># Initialize the FAISS retriever with the embeddings</span>
<span class="n">faiss_retriever</span> <span class="o">=</span> <span class="n">FAISSRetriever</span><span class="p">(</span>
    <span class="n">top_k</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">dimensions</span><span class="o">=</span><span class="n">vectorizer_settings</span><span class="p">[</span><span class="s2">&quot;model_kwargs&quot;</span><span class="p">][</span><span class="s2">&quot;dimensions&quot;</span><span class="p">],</span>
    <span class="n">vectorizer</span><span class="o">=</span><span class="n">vectorizer</span>
<span class="p">)</span>

<span class="c1"># build indexes for the documents</span>
<span class="n">faiss_retriever</span><span class="o">.</span><span class="n">build_index_from_documents</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

<span class="c1"># set up queries</span>
<span class="n">queries</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;what does luna like to eat?&quot;</span><span class="p">]</span>

<span class="c1"># get the retrieved results</span>
<span class="n">faiss_query_result</span> <span class="o">=</span> <span class="n">faiss_retriever</span><span class="o">.</span><span class="n">retrieve</span><span class="p">(</span><span class="n">query_or_queries</span><span class="o">=</span><span class="n">queries</span><span class="p">)</span>

<span class="c1"># Continue with the rest of your original code</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;*&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Faiss Retrieval Results:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">faiss_query_result</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Query: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">query</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Document Indexes: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">doc_indexes</span><span class="si">}</span><span class="s2">, Scores: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">doc_scores</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># Fetch and print the document texts corresponding to the retrieved indexes</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">doc_indexes</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Document ID: </span><span class="si">{</span><span class="n">splitted_docs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">id</span><span class="si">}</span><span class="s2"> - Title: </span><span class="si">{</span><span class="n">splitted_docs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">meta_data</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Text: </span><span class="si">{</span><span class="n">splitted_docs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Print first 200 characters of the document text</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;*&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>

<span class="c1"># **************************************************</span>
<span class="c1"># Faiss Retrieval Results:</span>
<span class="c1"># Query: what does luna like to eat?</span>
<span class="c1"># Document Indexes: [8 2], Scores: [0.741 0.724]</span>
<span class="c1"># Document ID: e3f04c8b-68ae-4dde-844a-439037e58842 - Title: Luna&#39;s Hobbies</span>
<span class="c1"># Text: text. Luna loves to eat lickable treats.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more</span>
<span class="c1"># Document ID: f2d0f52a-4e69-4cc5-8f78-4499fa22525d - Title: Luna&#39;s Profile</span>
<span class="c1"># Text: text.Luna is a domestic shorthair.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots</span>
<span class="c1"># **************************************************</span>
</pre></div>
</div>
<ol class="arabic simple">
<li><p>BM25Retriever</p></li>
</ol>
<p>The <code class="docutils literal notranslate"><span class="pre">BM25Retriever</span></code> leverages the <a class="reference external" href="https://en.wikipedia.org/wiki/Okapi_BM25">Okapi BM25 algorithm(Best Matching 25 ranking)</a>, a widely-used ranking function in information retrieval that is particularly effective in contexts where document relevance to a query is crucial.</p>
<p>This retriever is initialized with parameters that fine-tune its behavior:</p>
<p><code class="docutils literal notranslate"><span class="pre">top_k</span></code>: Number of top documents to retrieve.
<code class="docutils literal notranslate"><span class="pre">k1</span></code>: Controls term frequency saturation.
<code class="docutils literal notranslate"><span class="pre">b`</span></code>: Part of the BM25 algorithm that controls the influence of document length on term frequency normalization. Larger b means lengthier documents have more impact on its effect. 0.5 &lt; b &lt; 0.8 is suggested to yields reasonably good results.
<code class="docutils literal notranslate"><span class="pre">alpha</span></code>: Sets a cutoff for the IDF scores, filtering out terms that are too common to be informative.
IDF refers to <a class="reference external" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">Inverse document frequency</a>. It measures how much information the word provides.
Lower the IDF score means the word is used a lot and less important in the document.
Please check <code class="xref py py-class docutils literal notranslate"><span class="pre">BM25Retriever</span></code> to see how we calculate the IDF score.
<code class="docutils literal notranslate"><span class="pre">split_function</span></code>: Tokenization is customizable via the <code class="docutils literal notranslate"><span class="pre">split_function</span></code>, which defaults to splitting text by tokens. Here’s an example using a custom tokenizer:
The following example shows how the token splitting works. This tokenizer converts text into a series of token IDs, which are numeric representations of the tokens.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightrag.core.tokenizer</span> <span class="kn">import</span> <span class="n">Tokenizer</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="k">def</span> <span class="nf">split_text_by_token_fn</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">:</span> <span class="n">Tokenizer</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;o200k_base&quot;</span><span class="p">)</span>
<span class="n">sentence</span> <span class="o">=</span>  <span class="s2">&quot;Hello world. This is LightRAG.&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">split_text_by_token_fn</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">sentence</span><span class="p">))</span>

<span class="c1"># [13225, 2375, 13, 1328, 382, 12936, 49, 2971, 13], these numbers represent token ids</span>
</pre></div>
</div>
<p>Tokenization can be customized through <code class="docutils literal notranslate"><span class="pre">split_function</span></code>.</p>
<p>Similar to <code class="docutils literal notranslate"><span class="pre">FAISSRetriever</span></code>, developers can build index from documents. In <code class="docutils literal notranslate"><span class="pre">BM25Retriever</span></code> allows direct documents inputs without need for preparing embeddings beforehand.
The <code class="docutils literal notranslate"><span class="pre">build_index_from_documents</span></code> first tokenizes the documents, then analyzes each to compute token frequencies necessary for IDF calculation.
And we filter the IDF based on the specified <code class="docutils literal notranslate"><span class="pre">alpha</span></code>.
The <code class="docutils literal notranslate"><span class="pre">t2d</span></code> represents the token and its frequency in documents.
For example, t2d={“apple”:{0:1}} means, the word apple appears once in the 0th document.
With the frequency we can calculate idf. The <code class="docutils literal notranslate"><span class="pre">idf</span></code> dictionary is to record the idf score for each token, such as {“apple”: 0.9}, it means in the corpus, the token apple has idf score=0.9.</p>
<p><code class="docutils literal notranslate"><span class="pre">load_index</span></code>, <code class="docutils literal notranslate"><span class="pre">save_index</span></code> and <code class="docutils literal notranslate"><span class="pre">reset_index</span></code> are supported.</p>
<p>When a query is received, each token of the query is first transformed into its corresponding token using the same <code class="docutils literal notranslate"><span class="pre">split_function</span></code> configured during initialization.</p>
<p>If a token from the query also appears in the documents of the corpus,
the retriever iterates over the documents containing the token,
applying the BM25 formula to calculate and accumulate scores based on the token’s frequency.
For instance, document 1 = “apple, apple, banana”, document 2 = “apple, orange”.
If the query is “apple, orange”, the score of document 1 be the accumulated score from 2 “apple”. The score of document 2 will be the accumulated score from “apple” and “orange”.
The document’s score increases for each occurrence of these tokens.
This cumulative scoring approach ensures that documents containing more query-related tokens are ranked higher.
Finally, the <code class="docutils literal notranslate"><span class="pre">k</span></code> documents with the highest cumulative scores are identified and returned in a <code class="docutils literal notranslate"><span class="pre">RetrieverOutput</span></code>,
which means most relevant to the query.</p>
<ol class="arabic simple">
<li><p>LLMRetriever</p></li>
</ol>
<p>Unlike <code class="docutils literal notranslate"><span class="pre">FAISSRetriever</span></code> and <code class="docutils literal notranslate"><span class="pre">BM25Retriever</span></code>, the <code class="docutils literal notranslate"><span class="pre">LLMRetriever</span></code> utilizes LLM models to perform retrieval.</p>
<p>This model-driven approach does not rely on traditional similarity/IDF scores but instead uses the model’s understanding of the content.</p>
<p>Besides <code class="docutils literal notranslate"><span class="pre">top_k</span></code>, developers need to configure the generator arguments to call LLMs, including:
<code class="docutils literal notranslate"><span class="pre">model_client</span></code>: Model provider such as OpenAIClient, or GroqAPIClient.
<code class="docutils literal notranslate"><span class="pre">model_kwargs</span></code>: Model related arguments such the <code class="docutils literal notranslate"><span class="pre">temperature</span></code>.
<code class="docutils literal notranslate"><span class="pre">template</span></code>: The prompt template used in the generator to guide the model’s focus during retrieval.
<code class="docutils literal notranslate"><span class="pre">preset_prompt_kwargs</span></code>: Includes preset arguments for prompt customization, such as <code class="docutils literal notranslate"><span class="pre">task_desc_str</span></code> for task descriptions and <code class="docutils literal notranslate"><span class="pre">input_str</span></code> for user queries.
<code class="docutils literal notranslate"><span class="pre">output_processors</span></code>: A component by default <code class="docutils literal notranslate"><span class="pre">ListParser</span></code> that processes the model’s output into a list of document indices. You should configure this parser based on how you instruct the model to output in the prompt.</p>
<p><strong>Index Building:</strong> When <code class="docutils literal notranslate"><span class="pre">build_info_from_documents</span></code> is called, the retriever configures a designed prompt that informs the model of the documents’ context. This enables the model to understand and organize the information before any query is processed.
<strong>Retrieve:</strong> Developers can submit queries as a list. The queries will be processed by using the configured model and template.
The retrieve phase will return the k most relevant <strong>document indices</strong> based on the context provided during indexing.
Developers should be aware of the flexibility of prompt instruction and <code class="docutils literal notranslate"><span class="pre">output_processors</span></code> setting and process the output indices.</p>
<p>Here is an example for <code class="docutils literal notranslate"><span class="pre">LLMRetriever</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightrag.components.model_client</span> <span class="kn">import</span> <span class="n">OpenAIClient</span>
<span class="kn">from</span> <span class="nn">lightrag.core.types</span> <span class="kn">import</span> <span class="n">Document</span>
<span class="kn">from</span> <span class="nn">lightrag.core.document_splitter</span> <span class="kn">import</span> <span class="n">DocumentSplitter</span>
<span class="kn">from</span> <span class="nn">lightrag.components.retriever</span> <span class="kn">import</span> <span class="n">LLMRetriever</span>
<span class="kn">from</span> <span class="nn">lightrag.core.string_parser</span> <span class="kn">import</span> <span class="n">ListParser</span>

<span class="kn">import</span> <span class="nn">dotenv</span>
<span class="n">dotenv</span><span class="o">.</span><span class="n">load_dotenv</span><span class="p">(</span><span class="n">dotenv_path</span><span class="o">=</span><span class="s2">&quot;.env&quot;</span><span class="p">,</span> <span class="n">override</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Document preparation and splitting</span>
<span class="n">splitter_settings</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;split_by&quot;</span><span class="p">:</span> <span class="s2">&quot;word&quot;</span><span class="p">,</span> <span class="s2">&quot;split_length&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span> <span class="s2">&quot;split_overlap&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">}</span>
<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">DocumentSplitter</span><span class="p">(</span><span class="o">**</span><span class="n">splitter_settings</span><span class="p">)</span>
<span class="n">documents</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">Document</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;doc1&quot;</span><span class="p">,</span> <span class="n">meta_data</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="s2">&quot;Luna&#39;s Profile&quot;</span><span class="p">},</span> <span class="n">text</span><span class="o">=</span>
            <span class="s2">&quot;lots of more nonsense text.&quot;</span> <span class="o">*</span> <span class="mi">50</span>
            <span class="o">+</span> <span class="s2">&quot;Luna is a domestic shorthair.&quot;</span>
            <span class="o">+</span> <span class="s2">&quot;lots of nonsense text.&quot;</span> <span class="o">*</span> <span class="mi">50</span>
            <span class="o">+</span> <span class="s2">&quot;Luna loves to eat Tuna.&quot;</span>
            <span class="o">+</span> <span class="s2">&quot;lots of nonsense text.&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">),</span>
    <span class="n">Document</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;doc2&quot;</span><span class="p">,</span> <span class="n">meta_data</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="s2">&quot;Luna&#39;s Hobbies&quot;</span><span class="p">},</span> <span class="n">text</span><span class="o">=</span>
            <span class="s2">&quot;lots of more nonsense text.&quot;</span> <span class="o">*</span> <span class="mi">50</span>
            <span class="o">+</span> <span class="s2">&quot;Luna loves to eat lickable treats.&quot;</span>
            <span class="o">+</span> <span class="s2">&quot;lots of more nonsense text.&quot;</span> <span class="o">*</span> <span class="mi">50</span>
            <span class="o">+</span> <span class="s2">&quot;Luna loves to play cat wand.&quot;</span>
            <span class="o">+</span> <span class="s2">&quot;lots of more nonsense text.&quot;</span> <span class="o">*</span> <span class="mi">50</span>
            <span class="o">+</span> <span class="s2">&quot;Luna likes to sleep all the afternoon&quot;</span><span class="p">),</span>
<span class="p">]</span>

<span class="c1"># split the documents</span>
<span class="n">splitted_docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>

<span class="c1"># configure the model</span>
<span class="n">gpt_model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span>
        <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="p">}</span>
<span class="c1"># set up the retriever</span>
<span class="n">llm_retriever</span> <span class="o">=</span> <span class="n">LLMRetriever</span><span class="p">(</span>
    <span class="n">top_k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">model_client</span><span class="o">=</span><span class="n">OpenAIClient</span><span class="p">(),</span>
    <span class="n">model_kwargs</span><span class="o">=</span><span class="n">gpt_model_kwargs</span><span class="p">,</span>
    <span class="n">output_processors</span> <span class="o">=</span> <span class="n">ListParser</span><span class="p">()</span>
<span class="p">)</span>

<span class="c1"># build indexes for the splitted documents</span>
<span class="n">llm_retriever</span><span class="o">.</span><span class="n">build_index_from_documents</span><span class="p">(</span><span class="n">documents</span><span class="o">=</span><span class="n">splitted_docs</span><span class="p">)</span>

<span class="c1"># set up queries</span>
<span class="n">queries</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;what does luna like to eat?&quot;</span><span class="p">,</span> <span class="s2">&quot;what does Luna look like?&quot;</span><span class="p">]</span>


<span class="c1"># get the retrieved list of GeneratorOutput, each contains list of indices</span>
<span class="n">llm_query_output</span> <span class="o">=</span> <span class="n">llm_retriever</span><span class="o">.</span><span class="n">retrieve</span><span class="p">(</span><span class="n">query_or_queries</span><span class="o">=</span><span class="n">queries</span><span class="p">)</span>
<span class="c1"># print(llm_query_indices)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;*&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
<span class="k">for</span> <span class="n">query</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">llm_query_output</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">data</span> <span class="c1"># get list of indices from generatoroutput</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Query: </span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span><span class="p">:</span>
        <span class="c1"># Retrieve the indices from the result</span>
        <span class="n">document_indices</span> <span class="o">=</span> <span class="n">result</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">document_indices</span><span class="p">:</span>
            <span class="c1"># Ensure the index is within the range of splitted_docs</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">splitted_docs</span><span class="p">):</span>
                <span class="n">doc</span> <span class="o">=</span> <span class="n">splitted_docs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Document ID: </span><span class="si">{</span><span class="n">doc</span><span class="o">.</span><span class="n">id</span><span class="si">}</span><span class="s2"> - Title: </span><span class="si">{</span><span class="n">doc</span><span class="o">.</span><span class="n">meta_data</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Text: </span><span class="si">{</span><span class="n">doc</span><span class="o">.</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Print the first 200 characters</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Index </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> out of range.&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No documents retrieved for this query.&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;*&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>

<span class="c1"># **************************************************</span>
<span class="c1"># Query: what does luna like to eat?</span>
<span class="c1"># Document ID: 557cc52b-a2b7-4780-bbc3-f1be8330c167 - Title: Luna&#39;s Profile</span>
<span class="c1"># Text: text.Luna is a domestic shorthair.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.Luna loves to eat Tuna.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense</span>
<span class="c1"># **************************************************</span>
<span class="c1"># Query: what does Luna look like?</span>
<span class="c1"># Document ID: 7de4b00a-e539-4df0-adc9-b4c312bed365 - Title: Luna&#39;s Profile</span>
<span class="c1"># Text: text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.lots of more nonsense text.Luna is a domestic shorthair.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense text.lots of nonsense</span>
<span class="c1"># **************************************************</span>
</pre></div>
</div>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#document-splitter">1. Document Splitter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embedder">2. Embedder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lightrag-retrievers">3. LightRAG Retrievers</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024, SylphAI, Inc.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>