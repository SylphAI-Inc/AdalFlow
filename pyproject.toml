[tool.poetry]
name = "lightrag"

packages = [
    { include = "core", from = "." },
    { include = "components", from = "." },
    { include = "prompts", from = "." },
    { include = "eval", from = "." },
]
version = "0.1.0"
description = "The 'PyTorch' library for LLM applications. RAG=Retriever-Agent-Generator."
authors = ["Li Yin <li.yin.gravity@gmail.com>"]
readme = "README.md"
license = "MIT"
classifiers = [
    "Topic :: Software Development :: Build Tools",
    "Topic :: Software Development :: Libraries :: Python Modules",
]

[tool.poetry.dependencies]
python = ">=3.11, <4.0"
python-dotenv = "^1.0.1"
backoff = "^2.2.1"
jinja2 = "^3.1.3"
# TODO: decide if we need people to install faiss, or openai, or groq separately
openai = "^1.12.0"
groq = "^0.5.0"       # should only be installed if groq client is used
faiss-cpu = "^1.8.0"
torchviz = "^0.0.2"
matplotlib = "^3.8.4"
ipykernel = "^6.29.4"


[tool.poetry.group.test.dependencies]
pytest = "^8.1.1"

[tool.poetry.group.typing.dependencies]
mypy = "^1"

[tool.poetry.group.doc.dependencies]
datasets = ">=2.14.6, <=2.19.1"
sphinx = "^7.3.7"
sphinx-rtd-theme = "^2.0.0"
pydata-sphinx-theme = "0.15.2"
sphinx-design = "^0.6.0"

[tool.poetry.group.dev.dependencies]
langchain = "^0.1.16"
llama-index = "^0.10.30"
pre-commit = "^3.7.0"
litellm = "^1.35.34"
haystack-ai = "^2.0.1"
torchvision = "^0.18.0"
torch = "^2.3.0"
langsmith = "^0.1.56"
langchain-openai = "^0.1.6"
pyvis = "^0.3.2"
llama-index-llms-ollama = "^0.1.3"
anthropic = "^0.26.0"
google-generativeai = "^0.5.4"
transformers = "^4.41.0"
torchmetrics = "^1.4.0.post0"
lightning = "^2.2.4"
dspy-ai = "^2.4.9"
jupyter = "^1.0.0"


[tool.ruff]
exclude = ["images"]


[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
