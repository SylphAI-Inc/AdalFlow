{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ó Welcome to AdalFlow!\n",
    "## The library to build & auto-optimize any LLM task pipelines\n",
    "\n",
    "Thanks for trying us out, we're here to provide you with the best LLM application development experience you can dream of üòä any questions or concerns you may have, [come talk to us on discord,](https://discord.gg/ezzszrRZvT) we're always here to help! ‚≠ê <i>Star us on <a href=\"https://github.com/SylphAI-Inc/AdalFlow\">Github</a> </i> ‚≠ê\n",
    "\n",
    "\n",
    "# Quick Links\n",
    "\n",
    "Github repo: https://github.com/SylphAI-Inc/AdalFlow\n",
    "\n",
    "Full Tutorials: https://adalflow.sylph.ai/index.html#.\n",
    "\n",
    "Deep dive on each API: check out the [developer notes](https://adalflow.sylph.ai/tutorials/index.html).\n",
    "\n",
    "Common use cases along with the auto-optimization:  check out [Use cases](https://adalflow.sylph.ai/use_cases/index.html).\n",
    "\n",
    "# Author\n",
    "\n",
    "This notebook was created by community contributor [Ajith](https://github.com/ajithvcoder).\n",
    "\n",
    "# Outline\n",
    "\n",
    "This is a quick introduction of what AdalFlow is capable of. We will cover:\n",
    "\n",
    "* How to use `DataClass` with `DataClassParser`.\n",
    "* How to do nested dataclass, we will test both one and two levels of nesting.\n",
    "\n",
    "**Next: Try our [auto-optimization](https://colab.research.google.com/drive/1n3mHUWekTEYHiBdYBTw43TKlPN41A9za?usp=sharing)**\n",
    "\n",
    "\n",
    "# Installation\n",
    "\n",
    "1. Use `pip` to install the `adalflow` Python package. We will need `openai` and `groq`from the extra packages.\n",
    "\n",
    "  ```bash\n",
    "  pip install adalflow[openai,groq]\n",
    "  ```\n",
    "2. Setup  `openai` and `groq` API key in the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ab_OmE6XTl4h"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "!pip install -U adalflow[openai,groq,datasets]\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall httpx anyio -y\n",
    "!pip install \"anyio>=3.1.0,<4.0\"\n",
    "!pip install httpx==0.24.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PbAIsBeeTQUk"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from adalflow.core import Component, Generator\n",
    "from adalflow.components.model_client import OpenAIClient\n",
    "from adalflow.components.model_client import GroqAPIClient\n",
    "from adalflow.utils import (\n",
    "    setup_env,\n",
    ")  # make sure you have a .env file with OPENAI_API_KEY and GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRymwpwHTQUm",
    "outputId": "6a992f52-1661-4002-ef74-ed26938c6baa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your OpenAI API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
      "API keys have been set.\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "# Prompt user to enter their API keys securely\n",
    "openai_api_key = getpass(\"Please enter your OpenAI API key: \")\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "print(\"API keys have been set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "czGDvnVUTQUm"
   },
   "outputs": [],
   "source": [
    "template_doc = r\"\"\"<SYS> You are a doctor </SYS> User: {{input_str}}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPs3gHqeTQUn"
   },
   "source": [
    "Let's turn on the library log to help with debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98QNsOcSTQUn",
    "outputId": "d63cba1b-6087-4b04-bb2b-0a9d9d4500a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RootLogger root (INFO)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from adalflow.utils import get_logger\n",
    "\n",
    "get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "b3ey1lozTQUo"
   },
   "outputs": [],
   "source": [
    "# Toy example\n",
    "\n",
    "\n",
    "class DocQA(Component):\n",
    "    def __init__(self):\n",
    "        super(DocQA, self).__init__()\n",
    "        self.doc = Generator(\n",
    "            template=template_doc,\n",
    "            model_client=OpenAIClient(),\n",
    "            model_kwargs={\"model\": \"gpt-3.5-turbo\"},\n",
    "        )\n",
    "\n",
    "    def call(self, query: str) -> str:\n",
    "        return self.doc(prompt_kwargs={\"input_str\": query}).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZAHSrbUTQUo",
    "outputId": "66e81fb3-17f9-4570-dbbd-681cad1afc65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-11 17:40:52 - prompt_builder - INFO - [prompt_builder.py:65:__init__] - Prompt has variables: ['input_str']\n",
      "2024-11-11 17:40:52 - generator - INFO - [generator.py:144:__init__] - Generator Generator initialized.\n"
     ]
    }
   ],
   "source": [
    "doc = DocQA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-y6l44PTQUp",
    "outputId": "e24aabd5-d758-4700-fa0d-46b66a88c412"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'DocQA', 'data': {'_components': {'_ordered_dict': True, 'data': [('doc', {'type': 'Generator', 'data': {'model_str': 'OpenAIClient_gpt-3_5-turbo', 'cache_path': PosixPath('/root/.adalflow/cache_OpenAIClient_gpt-3_5-turbo.db'), 'callbacks': {'on_success': [], 'on_failure': [], 'on_complete': []}, 'cache': <diskcache.core.Cache object at 0x7b8d4716abc0>, '_components': {'_ordered_dict': True, 'data': [('prompt', {'type': 'Prompt', 'data': {'_components': {'_ordered_dict': True, 'data': []}, '_parameters': {'_ordered_dict': True, 'data': []}, 'training': False, 'teacher_mode': False, 'tracing': False, 'name': 'Prompt', '_init_args': {'template': None, 'prompt_kwargs': {}}, 'template': '<SYS> You are a doctor </SYS> User: {{input_str}}', 'prompt_variables': ['input_str'], 'prompt_kwargs': {}}}), ('model_client', {'type': 'OpenAIClient', 'data': {'_components': {'_ordered_dict': True, 'data': []}, '_parameters': {'_ordered_dict': True, 'data': []}, 'training': False, 'teacher_mode': False, 'tracing': False, 'name': 'OpenAIClient', '_init_args': {'api_key': None, 'chat_completion_parser': None, 'input_type': 'text'}, '_api_key': None, 'chat_completion_parser': <function get_first_message_content at 0x7b8d6cd7a9e0>, '_input_type': 'text'}})]}, '_parameters': {'_ordered_dict': True, 'data': []}, 'training': False, 'teacher_mode': False, 'tracing': False, 'name': 'Generator', '_init_args': {'model_client': None, 'model_kwargs': {}, 'template': None, 'prompt_kwargs': {}, 'output_processors': None, 'name': None, 'cache_path': None, 'use_cache': False}, 'backward_engine': None, 'template': '<SYS> You are a doctor </SYS> User: {{input_str}}', 'prompt_kwargs': {}, 'model_kwargs': {'model': 'gpt-3.5-turbo'}, 'output_processors': None, 'mock_output': False, 'mock_output_data': 'mock data', 'data_map_func': <function Generator.set_data_map_func.<locals>.default_map_func at 0x7b8d471c97e0>, '_use_cache': False, '_kwargs': {'model_client': {'type': 'OpenAIClient', 'data': {'_components': {'_ordered_dict': True, 'data': []}, '_parameters': {'_ordered_dict': True, 'data': []}, 'training': False, 'teacher_mode': False, 'tracing': False, 'name': 'OpenAIClient', '_init_args': {'api_key': None, 'chat_completion_parser': None, 'input_type': 'text'}, '_api_key': None, 'chat_completion_parser': <function get_first_message_content at 0x7b8d6cd7a9e0>, '_input_type': 'text'}}, 'model_kwargs': {'model': 'gpt-3.5-turbo'}, 'template': '<SYS> You are a doctor </SYS> User: {{input_str}}', 'prompt_kwargs': {}, 'output_processors': None, 'name': None, 'cache_path': None, 'use_cache': False}, '_teacher': None}})]}, '_parameters': {'_ordered_dict': True, 'data': []}, 'training': False, 'teacher_mode': False, 'tracing': False, 'name': 'DocQA', '_init_args': {}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_components': OrderedDict([('doc',\n",
       "               Generator(\n",
       "                 model_kwargs={'model': 'gpt-3.5-turbo'}, trainable_prompt_kwargs=[]\n",
       "                 (prompt): Prompt(template: <SYS> You are a doctor </SYS> User: {{input_str}}, prompt_variables: ['input_str'])\n",
       "                 (model_client): OpenAIClient()\n",
       "               ))]),\n",
       " '_parameters': OrderedDict(),\n",
       " 'training': False,\n",
       " 'teacher_mode': False,\n",
       " 'tracing': False,\n",
       " 'name': 'DocQA',\n",
       " '_init_args': {}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# states\n",
    "states = doc.to_dict()\n",
    "print(states)\n",
    "doc.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_sH59_bTQUp"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P81kIS2qTQUp",
    "outputId": "d8e0e398-d704-4a85-8692-66a8c570b910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-11 17:40:58 - component - INFO - [component.py:350:_restore_value] - Restoring class using from_dict Generator, {'type': 'Generator', 'data': {'model_str': 'OpenAIClient_gpt-3_5-turbo', 'cache_path': PosixPath('/root/.adalflow/cache_OpenAIClient_gpt-3_5-turbo.db'), 'callbacks': {'on_success': [], 'on_failure': [], 'on_complete': []}, 'cache': <diskcache.core.Cache object at 0x7b8d4716abc0>, '_components': {'_ordered_dict': True, 'data': [('prompt', {'type': 'Prompt', 'data': {'_components': {'_ordered_dict': True, 'data': []}, '_parameters': {'_ordered_dict': True, 'data': []}, 'training': False, 'teacher_mode': False, 'tracing': False, 'name': 'Prompt', '_init_args': {'template': None, 'prompt_kwargs': {}}, 'template': '<SYS> You are a doctor </SYS> User: {{input_str}}', 'prompt_variables': ['input_str'], 'prompt_kwargs': {}}}), ('model_client', {'type': 'OpenAIClient', 'data': {'_components': {'_ordered_dict': True, 'data': []}, '_parameters': {'_ordered_dict': True, 'data': []}, 'training': False, 'teacher_mode': False, 'tracing': False, 'name': 'OpenAIClient', '_init_args': {'api_key': None, 'chat_completion_parser': None, 'input_type': 'text'}, '_api_key': None, 'chat_completion_parser': <function get_first_message_content at 0x7b8d6cd7a9e0>, '_input_type': 'text'}})]}, '_parameters': {'_ordered_dict': True, 'data': []}, 'training': False, 'teacher_mode': False, 'tracing': False, 'name': 'Generator', '_init_args': {'model_client': None, 'model_kwargs': {}, 'template': None, 'prompt_kwargs': {}, 'output_processors': None, 'name': None, 'cache_path': None, 'use_cache': False}, 'backward_engine': None, 'template': '<SYS> You are a doctor </SYS> User: {{input_str}}', 'prompt_kwargs': {}, 'model_kwargs': {'model': 'gpt-3.5-turbo'}, 'output_processors': None, 'mock_output': False, 'mock_output_data': 'mock data', 'data_map_func': <function Generator.set_data_map_func.<locals>.default_map_func at 0x7b8d471c97e0>, '_use_cache': False, '_kwargs': {'model_client': {'type': 'OpenAIClient', 'data': {'_components': {'_ordered_dict': True, 'data': []}, '_parameters': {'_ordered_dict': True, 'data': []}, 'training': False, 'teacher_mode': False, 'tracing': False, 'name': 'OpenAIClient', '_init_args': {'api_key': None, 'chat_completion_parser': None, 'input_type': 'text'}, '_api_key': None, 'chat_completion_parser': <function get_first_message_content at 0x7b8d6cd7a9e0>, '_input_type': 'text'}}, 'model_kwargs': {'model': 'gpt-3.5-turbo'}, 'template': '<SYS> You are a doctor </SYS> User: {{input_str}}', 'prompt_kwargs': {}, 'output_processors': None, 'name': None, 'cache_path': None, 'use_cache': False}, '_teacher': None}}\n",
      "2024-11-11 17:40:58 - component - INFO - [component.py:350:_restore_value] - Restoring class using from_dict Prompt, {'type': 'Prompt', 'data': {'_components': {'_ordered_dict': True, 'data': []}, '_parameters': {'_ordered_dict': True, 'data': []}, 'training': False, 'teacher_mode': False, 'tracing': False, 'name': 'Prompt', '_init_args': {'template': None, 'prompt_kwargs': {}}, 'template': '<SYS> You are a doctor </SYS> User: {{input_str}}', 'prompt_variables': ['input_str'], 'prompt_kwargs': {}}}\n",
      "2024-11-11 17:40:58 - component - INFO - [component.py:350:_restore_value] - Restoring class using from_dict OpenAIClient, {'type': 'OpenAIClient', 'data': {'_components': {'_ordered_dict': True, 'data': []}, '_parameters': {'_ordered_dict': True, 'data': []}, 'training': False, 'teacher_mode': False, 'tracing': False, 'name': 'OpenAIClient', '_init_args': {'api_key': None, 'chat_completion_parser': None, 'input_type': 'text'}, '_api_key': None, 'chat_completion_parser': <function get_first_message_content at 0x7b8d6cd7a9e0>, '_input_type': 'text'}}\n",
      "2024-11-11 17:40:58 - component - INFO - [component.py:350:_restore_value] - Restoring class using from_dict OpenAIClient, {'type': 'OpenAIClient', 'data': {'_components': {'_ordered_dict': True, 'data': []}, '_parameters': {'_ordered_dict': True, 'data': []}, 'training': False, 'teacher_mode': False, 'tracing': False, 'name': 'OpenAIClient', '_init_args': {'api_key': None, 'chat_completion_parser': None, 'input_type': 'text'}, '_api_key': None, 'chat_completion_parser': <function get_first_message_content at 0x7b8d6cd7a9e0>, '_input_type': 'text'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_components': OrderedDict([('doc',\n",
       "               Generator(\n",
       "                 model_kwargs={'model': 'gpt-3.5-turbo'}, trainable_prompt_kwargs=[]\n",
       "                 (prompt): Prompt(template: <SYS> You are a doctor </SYS> User: {{input_str}}, prompt_variables: ['input_str'])\n",
       "                 (model_client): OpenAIClient()\n",
       "               ))]),\n",
       " '_parameters': OrderedDict(),\n",
       " 'training': False,\n",
       " 'teacher_mode': False,\n",
       " 'tracing': False,\n",
       " 'name': 'DocQA',\n",
       " '_init_args': {}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restore the states\n",
    "doc2 = DocQA.from_dict(states)\n",
    "# print(doc2.call(\"What is the capital of France?\"))\n",
    "doc2.__dict__\n",
    "# doc2.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "198xYpLGTQUp",
    "outputId": "ffd33d12-6db0-45c2-dfb1-3d57460ad4c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'DocQA',\n",
       " 'data': {'_components': {'_ordered_dict': True,\n",
       "   'data': [('doc',\n",
       "     {'type': 'Generator',\n",
       "      'data': {'model_str': 'OpenAIClient_gpt-3_5-turbo',\n",
       "       'cache_path': PosixPath('/root/.adalflow/cache_OpenAIClient_gpt-3_5-turbo.db'),\n",
       "       'callbacks': {'on_success': [], 'on_failure': [], 'on_complete': []},\n",
       "       'cache': <diskcache.core.Cache at 0x7b8d4716abc0>,\n",
       "       '_components': {'_ordered_dict': True,\n",
       "        'data': [('prompt',\n",
       "          {'type': 'Prompt',\n",
       "           'data': {'_components': {'_ordered_dict': True, 'data': []},\n",
       "            '_parameters': {'_ordered_dict': True, 'data': []},\n",
       "            'training': False,\n",
       "            'teacher_mode': False,\n",
       "            'tracing': False,\n",
       "            'name': 'Prompt',\n",
       "            '_init_args': {'template': None, 'prompt_kwargs': {}},\n",
       "            'template': '<SYS> You are a doctor </SYS> User: {{input_str}}',\n",
       "            'prompt_variables': ['input_str'],\n",
       "            'prompt_kwargs': {}}}),\n",
       "         ('model_client',\n",
       "          {'type': 'OpenAIClient',\n",
       "           'data': {'_components': {'_ordered_dict': True, 'data': []},\n",
       "            '_parameters': {'_ordered_dict': True, 'data': []},\n",
       "            'training': False,\n",
       "            'teacher_mode': False,\n",
       "            'tracing': False,\n",
       "            'name': 'OpenAIClient',\n",
       "            '_init_args': {'api_key': None,\n",
       "             'chat_completion_parser': None,\n",
       "             'input_type': 'text'},\n",
       "            '_api_key': None,\n",
       "            'chat_completion_parser': <function adalflow.components.model_client.openai_client.get_first_message_content(completion: openai.types.chat.chat_completion.ChatCompletion) -> str>,\n",
       "            '_input_type': 'text'}})]},\n",
       "       '_parameters': {'_ordered_dict': True, 'data': []},\n",
       "       'training': False,\n",
       "       'teacher_mode': False,\n",
       "       'tracing': False,\n",
       "       'name': 'Generator',\n",
       "       '_init_args': {'model_client': None,\n",
       "        'model_kwargs': {},\n",
       "        'template': None,\n",
       "        'prompt_kwargs': {},\n",
       "        'output_processors': None,\n",
       "        'name': None,\n",
       "        'cache_path': None,\n",
       "        'use_cache': False},\n",
       "       'backward_engine': None,\n",
       "       'template': '<SYS> You are a doctor </SYS> User: {{input_str}}',\n",
       "       'prompt_kwargs': {},\n",
       "       'model_kwargs': {'model': 'gpt-3.5-turbo'},\n",
       "       'output_processors': None,\n",
       "       'mock_output': False,\n",
       "       'mock_output_data': 'mock data',\n",
       "       'data_map_func': <function adalflow.core.generator.Generator.set_data_map_func.<locals>.default_map_func(data: 'GeneratorOutputType') -> str>,\n",
       "       '_use_cache': False,\n",
       "       '_kwargs': {'model_client': {'type': 'OpenAIClient',\n",
       "         'data': {'_components': {'_ordered_dict': True, 'data': []},\n",
       "          '_parameters': {'_ordered_dict': True, 'data': []},\n",
       "          'training': False,\n",
       "          'teacher_mode': False,\n",
       "          'tracing': False,\n",
       "          'name': 'OpenAIClient',\n",
       "          '_init_args': {'api_key': None,\n",
       "           'chat_completion_parser': None,\n",
       "           'input_type': 'text'},\n",
       "          '_api_key': None,\n",
       "          'chat_completion_parser': <function adalflow.components.model_client.openai_client.get_first_message_content(completion: openai.types.chat.chat_completion.ChatCompletion) -> str>,\n",
       "          '_input_type': 'text'}},\n",
       "        'model_kwargs': {'model': 'gpt-3.5-turbo'},\n",
       "        'template': '<SYS> You are a doctor </SYS> User: {{input_str}}',\n",
       "        'prompt_kwargs': {},\n",
       "        'output_processors': None,\n",
       "        'name': None,\n",
       "        'cache_path': None,\n",
       "        'use_cache': False},\n",
       "       '_teacher': None}})]},\n",
       "  '_parameters': {'_ordered_dict': True, 'data': []},\n",
       "  'training': False,\n",
       "  'teacher_mode': False,\n",
       "  'tracing': False,\n",
       "  'name': 'DocQA',\n",
       "  '_init_args': {}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2.to_dict() == doc.to_dict()\n",
    "doc2.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ulb1OWxxTQUq",
    "outputId": "99972fcd-ed52-43b4-e461-a76c19bd9522"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-11 17:41:29 - openai_client - INFO - [openai_client.py:279:call] - api_kwargs: {'model': 'gpt-3.5-turbo', 'messages': [{'role': 'system', 'content': '<SYS> You are a doctor </SYS> User: What is the best treatment for headache?'}]}\n",
      "2024-11-11 17:41:30 - _client - INFO - [_client.py:1038:_send_single_request] - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 17:41:30 - generator - INFO - [generator.py:798:call] - output: GeneratorOutput(id=None, data='As a doctor, the best treatment for a headache depends on the underlying cause of the headache. In general, for tension headaches or migraines, over-the-counter pain medications such as acetaminophen, ibuprofen, or aspirin can help alleviate symptoms. It is also important to rest in a quiet, dark room and stay hydrated. If headaches are frequent or severe, it is important to consult with a healthcare provider for further evaluation and treatment options.', error=None, usage=CompletionUsage(completion_tokens=92, prompt_tokens=27, total_tokens=119), raw_response='As a doctor, the best treatment for a headache depends on the underlying cause of the headache. In general, for tension headaches or migraines, over-the-counter pain medications such as acetaminophen, ibuprofen, or aspirin can help alleviate symptoms. It is also important to rest in a quiet, dark room and stay hydrated. If headaches are frequent or severe, it is important to consult with a healthcare provider for further evaluation and treatment options.', metadata=None)\n",
      "As a doctor, the best treatment for a headache depends on the underlying cause of the headache. In general, for tension headaches or migraines, over-the-counter pain medications such as acetaminophen, ibuprofen, or aspirin can help alleviate symptoms. It is also important to rest in a quiet, dark room and stay hydrated. If headaches are frequent or severe, it is important to consult with a healthcare provider for further evaluation and treatment options.\n"
     ]
    }
   ],
   "source": [
    "print(doc(\"What is the best treatment for headache?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "POVal8CgTQUq",
    "outputId": "2fadb1d6-b858-4964-9045-8ea7454178e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-11 17:41:35 - openai_client - INFO - [openai_client.py:279:call] - api_kwargs: {'model': 'gpt-3.5-turbo', 'messages': [{'role': 'system', 'content': '<SYS> You are a doctor </SYS> User: What is the best treatment for headache?'}]}\n",
      "2024-11-11 17:41:36 - _client - INFO - [_client.py:1038:_send_single_request] - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 17:41:36 - generator - INFO - [generator.py:798:call] - output: GeneratorOutput(id=None, data='As a doctor, the best treatment for a headache will depend on the underlying cause of the headache. In general, over-the-counter pain medications such as acetaminophen, ibuprofen, or aspirin can help relieve mild to moderate headaches. It is also important to stay hydrated, get adequate rest, manage stress, and practice good posture. If the headache persists or is severe, it is important to see a healthcare provider for further evaluation and treatment.', error=None, usage=CompletionUsage(completion_tokens=92, prompt_tokens=27, total_tokens=119), raw_response='As a doctor, the best treatment for a headache will depend on the underlying cause of the headache. In general, over-the-counter pain medications such as acetaminophen, ibuprofen, or aspirin can help relieve mild to moderate headaches. It is also important to stay hydrated, get adequate rest, manage stress, and practice good posture. If the headache persists or is severe, it is important to see a healthcare provider for further evaluation and treatment.', metadata=None)\n",
      "As a doctor, the best treatment for a headache will depend on the underlying cause of the headache. In general, over-the-counter pain medications such as acetaminophen, ibuprofen, or aspirin can help relieve mild to moderate headaches. It is also important to stay hydrated, get adequate rest, manage stress, and practice good posture. If the headache persists or is severe, it is important to see a healthcare provider for further evaluation and treatment.\n"
     ]
    }
   ],
   "source": [
    "print(doc2(\"What is the best treatment for headache?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5gTO1-8TQUr"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jhgSpKrMTQUr",
    "outputId": "15615bf7-2b72-4ac7-d1fe-f436a7304734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', DocQA(\n",
      "  (doc): Generator(\n",
      "    model_kwargs={'model': 'gpt-3.5-turbo'}, trainable_prompt_kwargs=[]\n",
      "    (prompt): Prompt(template: <SYS> You are a doctor </SYS> User: {{input_str}}, prompt_variables: ['input_str'])\n",
      "    (model_client): OpenAIClient()\n",
      "  )\n",
      "))\n",
      "('doc', Generator(\n",
      "  model_kwargs={'model': 'gpt-3.5-turbo'}, trainable_prompt_kwargs=[]\n",
      "  (prompt): Prompt(template: <SYS> You are a doctor </SYS> User: {{input_str}}, prompt_variables: ['input_str'])\n",
      "  (model_client): OpenAIClient()\n",
      "))\n",
      "('doc.prompt', Prompt(template: <SYS> You are a doctor </SYS> User: {{input_str}}, prompt_variables: ['input_str']))\n",
      "('doc.model_client', OpenAIClient())\n"
     ]
    }
   ],
   "source": [
    "# list other subcomponents\n",
    "\n",
    "for subcomponent in doc.named_components():\n",
    "    print(subcomponent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjIHAY6bTQUr"
   },
   "source": [
    "Let's add a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "vxgjAUiFTQUr"
   },
   "outputs": [],
   "source": [
    "from adalflow.optim.parameter import Parameter\n",
    "\n",
    "doc.register_parameter(\"demo\", param=Parameter(data=\"demo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86C-h1e1TQUr",
    "outputId": "57cab4d0-eddf-433d-e364-5d7f07072fbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('demo', Parameter(name=param_313f196d-3c48-4eb3-8138-b7bd74298fbd, requires_opt=True, param_type=none (), role_desc=, data=demo, predecessors=set(), gradients=[],            raw_response=None, input_args=None, traces={}))\n"
     ]
    }
   ],
   "source": [
    "# list all parameters\n",
    "for param in doc.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_s2MPukiTQUr",
    "outputId": "b51c7d09-fb52-42d9-b2d5-4f44f5d22dc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'DocQA',\n",
       " 'data': {'_components': {'_ordered_dict': True,\n",
       "   'data': [('doc',\n",
       "     {'type': 'Generator',\n",
       "      'data': {'model_str': 'OpenAIClient_gpt-3_5-turbo',\n",
       "       'cache_path': PosixPath('/root/.adalflow/cache_OpenAIClient_gpt-3_5-turbo.db'),\n",
       "       'callbacks': {'on_success': [], 'on_failure': [], 'on_complete': []},\n",
       "       'cache': <diskcache.core.Cache at 0x7b8d4716abc0>,\n",
       "       '_components': {'_ordered_dict': True,\n",
       "        'data': [('prompt',\n",
       "          {'type': 'Prompt',\n",
       "           'data': {'_components': {'_ordered_dict': True, 'data': []},\n",
       "            '_parameters': {'_ordered_dict': True, 'data': []},\n",
       "            'training': False,\n",
       "            'teacher_mode': False,\n",
       "            'tracing': False,\n",
       "            'name': 'Prompt',\n",
       "            '_init_args': {'template': None, 'prompt_kwargs': {}},\n",
       "            'template': '<SYS> You are a doctor </SYS> User: {{input_str}}',\n",
       "            'prompt_variables': ['input_str'],\n",
       "            'prompt_kwargs': {}}}),\n",
       "         ('model_client',\n",
       "          {'type': 'OpenAIClient',\n",
       "           'data': {'_components': {'_ordered_dict': True, 'data': []},\n",
       "            '_parameters': {'_ordered_dict': True, 'data': []},\n",
       "            'training': False,\n",
       "            'teacher_mode': False,\n",
       "            'tracing': False,\n",
       "            'name': 'OpenAIClient',\n",
       "            '_init_args': {'api_key': None,\n",
       "             'chat_completion_parser': None,\n",
       "             'input_type': 'text'},\n",
       "            '_api_key': None,\n",
       "            'chat_completion_parser': <function adalflow.components.model_client.openai_client.get_first_message_content(completion: openai.types.chat.chat_completion.ChatCompletion) -> str>,\n",
       "            '_input_type': 'text'}})]},\n",
       "       '_parameters': {'_ordered_dict': True, 'data': []},\n",
       "       'training': False,\n",
       "       'teacher_mode': False,\n",
       "       'tracing': False,\n",
       "       'name': 'Generator',\n",
       "       '_init_args': {'model_client': None,\n",
       "        'model_kwargs': {},\n",
       "        'template': None,\n",
       "        'prompt_kwargs': {},\n",
       "        'output_processors': None,\n",
       "        'name': None,\n",
       "        'cache_path': None,\n",
       "        'use_cache': False},\n",
       "       'backward_engine': None,\n",
       "       'template': '<SYS> You are a doctor </SYS> User: {{input_str}}',\n",
       "       'prompt_kwargs': {},\n",
       "       'model_kwargs': {'model': 'gpt-3.5-turbo'},\n",
       "       'output_processors': None,\n",
       "       'mock_output': False,\n",
       "       'mock_output_data': 'mock data',\n",
       "       'data_map_func': <function adalflow.core.generator.Generator.set_data_map_func.<locals>.default_map_func(data: 'GeneratorOutputType') -> str>,\n",
       "       '_use_cache': False,\n",
       "       '_kwargs': {'model_client': {'type': 'OpenAIClient',\n",
       "         'data': {'_components': {'_ordered_dict': True, 'data': []},\n",
       "          '_parameters': {'_ordered_dict': True, 'data': []},\n",
       "          'training': False,\n",
       "          'teacher_mode': False,\n",
       "          'tracing': False,\n",
       "          'name': 'OpenAIClient',\n",
       "          '_init_args': {'api_key': None,\n",
       "           'chat_completion_parser': None,\n",
       "           'input_type': 'text'},\n",
       "          '_api_key': None,\n",
       "          'chat_completion_parser': <function adalflow.components.model_client.openai_client.get_first_message_content(completion: openai.types.chat.chat_completion.ChatCompletion) -> str>,\n",
       "          '_input_type': 'text'}},\n",
       "        'model_kwargs': {'model': 'gpt-3.5-turbo'},\n",
       "        'template': '<SYS> You are a doctor </SYS> User: {{input_str}}',\n",
       "        'prompt_kwargs': {},\n",
       "        'output_processors': None,\n",
       "        'name': None,\n",
       "        'cache_path': None,\n",
       "        'use_cache': False},\n",
       "       '_teacher': None}})]},\n",
       "  '_parameters': {'_ordered_dict': True,\n",
       "   'data': [('demo',\n",
       "     {'name': 'param_313f196d-3c48-4eb3-8138-b7bd74298fbd',\n",
       "      'role_desc': '',\n",
       "      'data': 'demo',\n",
       "      'requires_opt': True,\n",
       "      'param_type': 'none ()',\n",
       "      'predecessors': [],\n",
       "      'gradients': [],\n",
       "      'previous_data': None,\n",
       "      'gradients_context': [],\n",
       "      'grad_fn': 'None',\n",
       "      'gradient_prompt': 'None',\n",
       "      'raw_response': None,\n",
       "      'score': None,\n",
       "      'traces': {},\n",
       "      'input_args': None,\n",
       "      'demos': []})]},\n",
       "  'training': False,\n",
       "  'teacher_mode': False,\n",
       "  'tracing': False,\n",
       "  'name': 'DocQA',\n",
       "  '_init_args': {}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "mcIO1DuVTQUr"
   },
   "outputs": [],
   "source": [
    "from adalflow.utils.file_io import save_json\n",
    "\n",
    "save_json(doc.to_dict(), \"doc.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0vvO0nogTQUr",
    "outputId": "59131d9e-a996-4c8b-f32c-9a6a623d3db6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('demo',\n",
       "              Parameter(name=param_313f196d-3c48-4eb3-8138-b7bd74298fbd, requires_opt=True, param_type=none (), role_desc=, data=demo, predecessors=set(), gradients=[],            raw_response=None, input_args=None, traces={}))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "uroqi93tTQUs",
    "outputId": "8a3e4ecc-1368-475b-dc4d-2ff38821b8ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-11 17:42:18 - openai_client - INFO - [openai_client.py:279:call] - api_kwargs: {'model': 'gpt-3.5-turbo', 'messages': [{'role': 'system', 'content': '<SYS> You are a doctor </SYS> User: What is the best treatment for a cold?'}]}\n",
      "2024-11-11 17:42:19 - _client - INFO - [_client.py:1038:_send_single_request] - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 17:42:19 - generator - INFO - [generator.py:798:call] - output: GeneratorOutput(id=None, data='As a doctor, I recommend getting plenty of rest, staying hydrated, and taking over-the-counter medications like ibuprofen or acetaminophen to help relieve symptoms such as fever and congestion. Additionally, you can try using saline nasal sprays or lozenges to help soothe a sore throat. If your symptoms persist or worsen, it is best to consult with a healthcare provider for further evaluation and treatment.', error=None, usage=CompletionUsage(completion_tokens=85, prompt_tokens=28, total_tokens=113), raw_response='As a doctor, I recommend getting plenty of rest, staying hydrated, and taking over-the-counter medications like ibuprofen or acetaminophen to help relieve symptoms such as fever and congestion. Additionally, you can try using saline nasal sprays or lozenges to help soothe a sore throat. If your symptoms persist or worsen, it is best to consult with a healthcare provider for further evaluation and treatment.', metadata=None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'As a doctor, I recommend getting plenty of rest, staying hydrated, and taking over-the-counter medications like ibuprofen or acetaminophen to help relieve symptoms such as fever and congestion. Additionally, you can try using saline nasal sprays or lozenges to help soothe a sore throat. If your symptoms persist or worsen, it is best to consult with a healthcare provider for further evaluation and treatment.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.call(\"What is the best treatment for a cold?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mYSDr462TQUs",
    "outputId": "82414c82-8feb-4667-90ed-91c594cc6a73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<class 'adalflow.core.component.FunComponent'>\n"
     ]
    }
   ],
   "source": [
    "from adalflow.core.component import FunComponent\n",
    "\n",
    "\n",
    "def add_one(x):\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "fun_component = FunComponent(add_one)\n",
    "print(fun_component(1))\n",
    "print(type(fun_component))\n",
    "\n",
    "# output:\n",
    "# 2\n",
    "# <class 'core.component.FunComponent'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3MW1tpzRTQUs",
    "outputId": "351b8922-1423-434a-f470-ff435a1962d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<class 'adalflow.core.component.AddOneComponent'>\n"
     ]
    }
   ],
   "source": [
    "from adalflow.core.component import fun_to_component\n",
    "\n",
    "fun_component = fun_to_component(add_one)\n",
    "print(fun_component(1))\n",
    "print(type(fun_component))\n",
    "\n",
    "# output:\n",
    "# 2\n",
    "# <class 'adalflow.core.component.AddOneComponent'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dxAoGrnQTQUs",
    "outputId": "38c462a3-5abf-41f4-9231-746c8d0ffcb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<class 'adalflow.core.component.AddOneComponent'>\n"
     ]
    }
   ],
   "source": [
    "# use it as a decorator\n",
    "@fun_to_component\n",
    "def add_one(x):\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "print(add_one(1))\n",
    "print(type(add_one))\n",
    "\n",
    "# output:\n",
    "# 2\n",
    "# <class 'adalflow.core.component.AddOneComponent'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7BvJEP_mTQUs",
    "outputId": "066281b8-a650-4c48-c786-312022198015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-11 17:42:39 - openai_client - INFO - [openai_client.py:279:call] - api_kwargs: {'model': 'gpt-3.5-turbo', 'messages': [{'role': 'system', 'content': '<SYS> You are a doctor </SYS> User: What is the best treatment for headache?Please be concise and only list the top treatments.'}]}\n",
      "2024-11-11 17:42:40 - _client - INFO - [_client.py:1038:_send_single_request] - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 17:42:40 - generator - INFO - [generator.py:798:call] - output: GeneratorOutput(id=None, data='The top treatments for headache are rest, hydration, over-the-counter pain relievers such as ibuprofen or acetaminophen, and relaxation techniques such as deep breathing or meditation.', error=None, usage=CompletionUsage(completion_tokens=37, prompt_tokens=37, total_tokens=74), raw_response='The top treatments for headache are rest, hydration, over-the-counter pain relievers such as ibuprofen or acetaminophen, and relaxation techniques such as deep breathing or meditation.', metadata=None)\n",
      "The top treatments for headache are rest, hydration, over-the-counter pain relievers such as ibuprofen or acetaminophen, and relaxation techniques such as deep breathing or meditation.\n"
     ]
    }
   ],
   "source": [
    "from adalflow.core import Sequential\n",
    "\n",
    "\n",
    "@fun_to_component\n",
    "def enhance_query(query: str) -> str:\n",
    "    return query + \"Please be concise and only list the top treatments.\"\n",
    "\n",
    "\n",
    "seq = Sequential(enhance_query, doc)\n",
    "\n",
    "query = \"What is the best treatment for headache?\"\n",
    "print(seq(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aoZ2w8RUTQUt",
    "outputId": "115d0ccf-33d1-4464-a951-cf9f5476284b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): EnhanceQueryComponent(fun_name=enhance_query)\n",
       "  (1): DocQA(\n",
       "    (doc): Generator(\n",
       "      model_kwargs={'model': 'gpt-3.5-turbo'}, trainable_prompt_kwargs=[]\n",
       "      (prompt): Prompt(template: <SYS> You are a doctor </SYS> User: {{input_str}}, prompt_variables: ['input_str'])\n",
       "      (model_client): OpenAIClient()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-ffAlC6TQUt"
   },
   "source": [
    "# TODO: LLM for single choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issues and feedback\n",
    "\n",
    "If you encounter any issues, please report them here: [GitHub Issues](https://github.com/SylphAI-Inc/LightRAG/issues).\n",
    "\n",
    "For feedback, you can use either the [GitHub discussions](https://github.com/SylphAI-Inc/LightRAG/discussions) or [Discord](https://discord.gg/ezzszrRZvT)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
