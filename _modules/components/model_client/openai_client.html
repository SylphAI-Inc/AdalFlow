<!doctype html>
<html class="no-js" lang="en" data-content_root="../../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" />

    <link rel="shortcut icon" href="../../../_static/LightRAG-logo-circle.png"/><!-- Generated with Sphinx 7.4.7 and Furo 2024.08.06 -->
        <title>components.model_client.openai_client - Build and Optimize LM Workflows</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css?v=f0068426" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/rtd_sphinx_search.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  --color-brand-primary: #FF6F00;
  --color-brand-content: #1E2A38;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #FF8F00;
  --color-brand-content: #CFD8DC;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #FF8F00;
  --color-brand-content: #CFD8DC;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../index.html"><div class="brand">Build and Optimize LM Workflows</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../../../_static/images/AdalFlow.svg" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="../../../_static/images/AdalFlow_black_bg.svg" alt="Dark Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Build and Optimize LM Workflows</span>
  
</a><div class="sidebar-github-section">
    <a href="https://github.com/SylphAI-Inc/AdalFlow" class="sidebar-github-link">
        <i class="fa-brands fa-github"></i>
        <span class="github-text">GitHub</span>
    </a>
</div><form class="sidebar-search-container" method="get" action="../../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Getting Started</a></li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../new_tutorials/index.html">Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Tutorials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../new_tutorials/core_concepts.html">Core Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../new_tutorials/generator.html">Generator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../new_tutorials/embedder.html">Embedder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/retriever.html">retriever</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../new_tutorials/tool.html">Tool Use</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../new_tutorials/agents_runner.html">Agent Runner</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../new_tutorials/streaming.html">Streaming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../new_tutorials/tracing.html">Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../new_tutorials/human_in_the_loop.html">Human in the Loop</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../new_tutorials/prompt.html">Prompt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../new_tutorials/parser.html">Parser and Structured Output</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../integrations/index.html">Integrations</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Integrations</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../integrations/integrations.html">All Providers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../integrations/openai.html">OpenAI Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../integrations/anthropic.html">Anthropic Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../integrations/ollama.html">Ollama Integration</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../use_cases/index.html">Use Cases</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Use Cases</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../use_cases/question_answering.html">Question Answering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../use_cases/qa_computation_graph.html">Q&amp;A Computation Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../use_cases/qa_text_grad_trace_graph.html">Q&amp;A Text Grad Trace Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../use_cases/qa_demo_trace_graph.html">Q&amp;A Few Shot Demo Trace Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../use_cases/classification.html">Classification Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../use_cases/rag_opt.html">RAG optimization</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../contributor/index.html">Contributor Guide</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Contributor Guide</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../contributor/contribution.html">Contributing Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../contributor/contribute_to_code.html">Development Essentials</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../tutorials/index.html">Developer Notes</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Developer Notes</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/lightrag_design_philosophy.html">Design Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/class_hierarchy.html">Class Hierarchy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/trace_graph.html">AdalFlow Trace Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/component.html">Component</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/base_data_class.html">DataClass</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/prompt.html">Prompt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/model_client.html">ModelClient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/generator.html">Generator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/generator.html#basic-generator-tutorial">Basic Generator Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/output_parsers.html">Parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/embedder.html">Embedder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/retriever.html">Retriever</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/text_splitter.html">Text Splitter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/db.html">Data (Database/Pipeline)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/rag_playbook.html">RAG Playbook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/rag_with_memory.html">RAG with Memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/tool_helper.html">Function calls</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/agent.html">ReAct Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../new_tutorials/agents_runner.html">Agents and Runner</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../new_tutorials/streaming.html">Streaming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../new_tutorials/tracing.html">Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../new_tutorials/human_in_the_loop.html">Human in the Loop</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/evaluation.html">LLM Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/datasets.html">Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/logging.html">Logger Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/logging.html#design">Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/logging.html#use-logger-in-projects">Use Logger in Projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/logging_tracing.html">Tracing</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../design/index.html">Blog</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Blog</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../design/ComponentTool.html">Use Class method as a better function tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../design/FunctionTool.html">Designing of AdalFlow FunctionTool</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../design/agent-streaming.html">Agent Streaming Architecture in OpenAI Agents SDK</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../apis/index.html">API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of API Reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apis/core/index.html">Core</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Core</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/core/core.base_data_class.html">base_data_class</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/core/core.component.html">component</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/core/core.container.html">container</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/core/core.default_prompt_template.html">default_prompt_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/core/core.embedder.html">embedder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/core/core.generator.html">generator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/core/core.model_client.html">model_client</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/core/core.prompt_builder.html">prompt_builder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/core/core.retriever.html">retriever</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/core/core.string_parser.html">string_parser</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/core/core.func_tool.html">func_tool</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/core/core.mcp_tool.html">mcp_tool</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/core/core.tool_manager.html">tool_manager</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/core/core.types.html">types</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/core/core.db.html">db</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/core/core.functional.html">functional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/core/core.tokenizer.html">tokenizer</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apis/components/index.html">Components</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of Components</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../apis/components/components.model_client.html">model_client</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of model_client</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.model_client.anthropic_client.html">anthropic_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.model_client.azureai_client.html">azureai_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.model_client.bedrock_client.html">bedrock_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.model_client.chat_completion_to_response_converter.html">chat_completion_to_response_converter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.model_client.cohere_client.html">cohere_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.model_client.deepseek_client.html">deepseek_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.model_client.fireworks_client.html">fireworks_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.model_client.google_client.html">google_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.model_client.groq_client.html">groq_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.model_client.mistral_client.html">mistral_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.model_client.ollama_client.html">ollama_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.model_client.openai_client.html">openai_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.model_client.sambanova_client.html">sambanova_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.model_client.together_client.html">together_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.model_client.transformers_client.html">transformers_client</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.model_client.utils.html">utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.model_client.xai_client.html">xai_client</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../apis/components/components.retriever.html">retriever</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of retriever</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.retriever.bm25_retriever.html">bm25_retriever</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.retriever.faiss_retriever.html">faiss_retriever</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.retriever.lancedb_retriver.html">lancedb_retriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.retriever.llm_retriever.html">llm_retriever</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.retriever.postgres_retriever.html">postgres_retriever</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.retriever.qdrant_retriever.html">qdrant_retriever</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.retriever.reranker_retriever.html">reranker_retriever</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../apis/components/components.output_parsers.html">output_parsers</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of output_parsers</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.output_parsers.dataclass_parser.html">dataclass_parser</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.output_parsers.outputs.html">outputs</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../apis/components/components.agent.html">agent</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of agent</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.agent.agent.html">agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.agent.prompts.html">prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.agent.react.html">react</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.agent.runner.html">runner</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../apis/components/components.data_process.html">data_process</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of data_process</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.data_process.data_components.html">data_components</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.data_process.text_splitter.html">text_splitter</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../apis/components/components.memory.html">memory</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of memory</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/components/components.memory.memory.html">memory</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apis/datasets/index.html">Datasets</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of Datasets</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/datasets/datasets.big_bench_hard.html">big_bench_hard</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/datasets/datasets.trec.html">trec</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/datasets/datasets.hotpot_qa.html">hotpot_qa</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/datasets/datasets.types.html">types</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apis/eval/index.html">Evaluation</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of Evaluation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/eval/eval.base.html">base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/eval/eval.answer_match_acc.html">answer_match_acc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/eval/eval.retriever_recall.html">retriever_recall</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/eval/eval.llm_as_judge.html">llm_as_judge</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/eval/eval.g_eval.html">g_eval</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apis/optim/index.html">Optimization</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of Optimization</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/optim/optim.parameter.html">parameter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/optim/optim.optimizer.html">optimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/optim/optim.grad_component.html">grad_component</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/optim/optim.loss_component.html">loss_component</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/optim/optim.types.html">types</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../apis/optim/optim.few_shot.html">few_shot</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of few_shot</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/optim/optim.few_shot.bootstrap_optimizer.html">bootstrap_optimizer</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../apis/optim/optim.text_grad.html">text_grad</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of text_grad</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/optim/optim.text_grad.backend_engine_prompt.html">backend_engine_prompt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/optim/optim.text_grad.llm_text_loss.html">llm_text_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/optim/optim.text_grad.ops.html">ops</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/optim/optim.text_grad.text_loss_with_eval_fn.html">text_loss_with_eval_fn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/optim/optim.text_grad.tgd_optimizer.html">tgd_optimizer</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../apis/optim/optim.trainer.html">trainer</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of trainer</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/optim/optim.trainer.adal.html">adal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apis/optim/optim.trainer.trainer.html">trainer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apis/tracing/index.html">Tracing</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of Tracing</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/tracing/tracing.callback_manager.html">callback_manager</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/tracing/tracing.create.html">create</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/tracing/tracing.decorators.html">decorators</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/tracing/tracing.generator_call_logger.html">generator_call_logger</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/tracing/tracing.generator_state_logger.html">generator_state_logger</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/tracing/tracing.mlflow_integration.html">mlflow_integration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/tracing/tracing.processor_interface.html">processor_interface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/tracing/tracing.scope.html">scope</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/tracing/tracing.setup.html">setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/tracing/tracing.span_data.html">span_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/tracing/tracing.spans.html">spans</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/tracing/tracing.traces.html">traces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/tracing/tracing.util.html">util</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apis/utils/index.html">Utils</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle navigation of Utils</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/utils/utils.data.html">data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/utils/utils.setup_env.html">setup_env</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/utils/utils.logger.html">logger</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/utils/utils.file_io.html">file_io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/utils/utils.config.html">config</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/utils/utils.lazy_import.html">lazy_import</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/utils/utils.registry.html">registry</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/utils/utils.serialization.html">serialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apis/utils/utils.cache.html">cache</a></li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <h1>Source code for components.model_client.openai_client</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;OpenAI ModelClient integration.&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">base64</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">Sequence</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">TypeVar</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Generator</span> <span class="k">as</span> <span class="n">GeneratorType</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
    <span class="n">Literal</span><span class="p">,</span>
    <span class="n">Iterable</span><span class="p">,</span>
    <span class="n">AsyncIterable</span><span class="p">,</span>
    <span class="n">AsyncGenerator</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">backoff</span>

<span class="c1"># optional import</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">adalflow.utils.lazy_import</span><span class="w"> </span><span class="kn">import</span> <span class="n">safe_import</span><span class="p">,</span> <span class="n">OptionalPackages</span>


<span class="n">openai</span> <span class="o">=</span> <span class="n">safe_import</span><span class="p">(</span><span class="n">OptionalPackages</span><span class="o">.</span><span class="n">OPENAI</span><span class="o">.</span><span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">OptionalPackages</span><span class="o">.</span><span class="n">OPENAI</span><span class="o">.</span><span class="n">value</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">OpenAI</span><span class="p">,</span>
    <span class="n">AsyncOpenAI</span><span class="p">,</span>
<span class="p">)</span>  <span class="c1"># , Stream  # COMMENTED OUT - USING RESPONSE API ONLY</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">APITimeoutError</span><span class="p">,</span>
    <span class="n">InternalServerError</span><span class="p">,</span>
    <span class="n">RateLimitError</span><span class="p">,</span>
    <span class="n">UnprocessableEntityError</span><span class="p">,</span>
    <span class="n">BadRequestError</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">openai.types</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">Completion</span><span class="p">,</span>
    <span class="n">CreateEmbeddingResponse</span><span class="p">,</span>
    <span class="n">Image</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># from openai.types.chat import ChatCompletionChunk, ChatCompletion  # COMMENTED OUT - USING RESPONSE API ONLY</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">openai.types.responses</span><span class="w"> </span><span class="kn">import</span> <span class="n">Response</span><span class="p">,</span> <span class="n">ResponseUsage</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">adalflow.core.model_client</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelClient</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">adalflow.core.types</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">ModelType</span><span class="p">,</span>
    <span class="n">EmbedderOutput</span><span class="p">,</span>
    <span class="n">ResponseUsage</span> <span class="k">as</span> <span class="n">AdalFlowResponseUsage</span><span class="p">,</span>
    <span class="n">InputTokensDetails</span><span class="p">,</span>
    <span class="n">OutputTokensDetails</span><span class="p">,</span>
    <span class="n">GeneratorOutput</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">adalflow.components.model_client.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">parse_embedding_response</span><span class="p">,</span>
    <span class="n">format_content_for_response_api</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="ParsedResponseContent">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.ParsedResponseContent">[docs]</a>
<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ParsedResponseContent</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Structured container for parsed response content from OpenAI Response API.</span>

<span class="sd">    This dataclass provides a consistent interface for accessing different types</span>
<span class="sd">    of content that can be returned by the Response API, including text, images,</span>
<span class="sd">    tool calls, reasoning chains, and more.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        text: The main text content from the response</span>
<span class="sd">        images: List of image data (base64 or URLs) from image generation</span>
<span class="sd">        tool_calls: List of other tool call results</span>
<span class="sd">        reasoning: Reasoning chain from reasoning models</span>
<span class="sd">        code_outputs: Outputs from code interpreter</span>
<span class="sd">        raw_output: The original output array for advanced processing</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">text</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">images</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">tool_calls</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">reasoning</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">code_outputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">raw_output</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__bool__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if there&#39;s any content.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">any</span><span class="p">([</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">images</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tool_calls</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reasoning</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">code_outputs</span>
        <span class="p">])</span></div>



<span class="c1"># OLD CHAT COMPLETION PARSING FUNCTIONS (COMMENTED OUT)</span>
<span class="c1"># # completion parsing functions and you can combine them into one single chat completion parser</span>
<span class="c1"># def get_first_message_content(completion: ChatCompletion) -&gt; str:</span>
<span class="c1">#     r&quot;&quot;&quot;When we only need the content of the first message.</span>
<span class="c1">#     It is the default parser for chat completion.&quot;&quot;&quot;</span>
<span class="c1">#     log.debug(f&quot;raw completion: {completion}&quot;)</span>
<span class="c1">#     return completion.choices[0].message.content</span>


<div class="viewcode-block" id="get_response_output_text">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.get_response_output_text">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_response_output_text</span><span class="p">(</span><span class="n">response</span><span class="p">:</span> <span class="n">Response</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Used to extract the data field for the reasoning model&quot;&quot;&quot;</span>
    <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;raw response: </span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">output_text</span></div>



<div class="viewcode-block" id="parse_response_output">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.parse_response_output">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">parse_response_output</span><span class="p">(</span><span class="n">response</span><span class="p">:</span> <span class="n">Response</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ParsedResponseContent</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Parse response output that may include various types of content and tool calls.</span>

<span class="sd">    The output array can contain:</span>
<span class="sd">    - Output messages (with nested content items)</span>
<span class="sd">    - Tool calls (file search, function, web search, computer use, etc.)</span>
<span class="sd">    - Reasoning chains</span>
<span class="sd">    - Image generation calls</span>
<span class="sd">    - Code interpreter calls</span>
<span class="sd">    - And more...</span>

<span class="sd">    Returns:</span>
<span class="sd">        ParsedResponseContent: Structured content with typed access to all response data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;raw response from api: </span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">content</span> <span class="o">=</span> <span class="n">ParsedResponseContent</span><span class="p">()</span>

    <span class="c1"># Store raw output for advanced users</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="s1">&#39;output&#39;</span><span class="p">):</span>
        <span class="n">content</span><span class="o">.</span><span class="n">raw_output</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">output</span>

    <span class="c1"># First try to use output_text if available (SDK convenience property)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="s1">&#39;output_text&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">response</span><span class="o">.</span><span class="n">output_text</span><span class="p">:</span>
        <span class="n">content</span><span class="o">.</span><span class="n">text</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">output_text</span>
    <span class="c1"># Parse the output array manually if no output_text</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="s1">&#39;output&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">response</span><span class="o">.</span><span class="n">output</span><span class="p">:</span>
        <span class="n">parsed</span> <span class="o">=</span> <span class="n">_parse_output_array</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
        <span class="n">content</span><span class="o">.</span><span class="n">text</span> <span class="o">=</span> <span class="n">content</span><span class="o">.</span><span class="n">text</span> <span class="ow">or</span> <span class="n">parsed</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">)</span>
        <span class="n">content</span><span class="o">.</span><span class="n">images</span> <span class="o">=</span> <span class="n">parsed</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;images&quot;</span><span class="p">,</span> <span class="p">[])</span>
        <span class="n">content</span><span class="o">.</span><span class="n">tool_calls</span> <span class="o">=</span> <span class="n">parsed</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;tool_calls&quot;</span><span class="p">)</span>
        <span class="n">content</span><span class="o">.</span><span class="n">reasoning</span> <span class="o">=</span> <span class="n">parsed</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;reasoning&quot;</span><span class="p">)</span>
        <span class="n">content</span><span class="o">.</span><span class="n">code_outputs</span> <span class="o">=</span> <span class="n">parsed</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;code_outputs&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">content</span></div>




<span class="k">def</span><span class="w"> </span><span class="nf">_parse_message</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Parse a message item from the output array.</span>

<span class="sd">    Args:</span>
<span class="sd">        item: A message item with type=&quot;message&quot; and content array</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict with parsed text and images from the message</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>

    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="c1"># now pick the longer response </span>
        <span class="n">text_parts</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">content_item</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">content</span><span class="p">:</span>
            <span class="n">content_type</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">content_item</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">content_type</span> <span class="o">==</span> <span class="s2">&quot;output_text&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">content_item</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">):</span>
                    <span class="n">text_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">content_item</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">text_parts</span><span class="p">:</span>
            <span class="n">result</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">text_parts</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="nb">len</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">text_parts</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">text_parts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_parse_reasoning</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Parse a reasoning item from the output array.</span>

<span class="sd">    Args:</span>
<span class="sd">        item: A reasoning item with type=&quot;reasoning&quot; and summary array</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict with extracted reasoning text and full structure</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;reasoning&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>

    <span class="c1"># Extract text from reasoning summary if available</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="s1">&#39;summary&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">summary</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">summary_texts</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">summary_item</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">summary</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">summary_item</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">summary_item</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;summary_text&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">summary_item</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">):</span>
                    <span class="n">summary_texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">summary_item</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">summary_texts</span><span class="p">:</span>
            <span class="c1"># Store reasoning text separately for later combination</span>
            <span class="n">result</span><span class="p">[</span><span class="s2">&quot;reasoning&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">summary_texts</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_parse_image</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Parse an image generation call item from the output array.</span>

<span class="sd">    Args:</span>
<span class="sd">        item: An image generation item with type=&quot;image_generation_call&quot; and result field</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict with extracted image data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;images&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>

    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="s1">&#39;result&#39;</span><span class="p">):</span>
        <span class="c1"># The result contains the base64 image data or URL</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;images&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">result</span>

    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_parse_tool_call</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Parse a tool call item from the output array.</span>

<span class="sd">    Args:</span>
<span class="sd">        item: A tool call item (various types ending in _call or containing tool_call)</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict with tool call information</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">item_type</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">item_type</span> <span class="o">==</span> <span class="s2">&quot;image_generation_call&quot;</span><span class="p">:</span>
        <span class="c1"># Handle image generation - extract the result which contains the image data</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="s1">&#39;result&#39;</span><span class="p">):</span>
            <span class="c1"># The result contains the base64 image data or URL</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;images&quot;</span><span class="p">:</span> <span class="n">item</span><span class="o">.</span><span class="n">result</span><span class="p">}</span>
    <span class="k">elif</span> <span class="n">item_type</span> <span class="o">==</span> <span class="s2">&quot;code_interpreter_tool_call&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;code_outputs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">_serialize_item</span><span class="p">(</span><span class="n">item</span><span class="p">)]}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Generic tool call</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;tool_calls&quot;</span><span class="p">:</span> <span class="p">[{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="n">item_type</span><span class="p">,</span>
                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">_serialize_item</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
            <span class="p">}]</span>
        <span class="p">}</span>

    <span class="k">return</span> <span class="p">{}</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_parse_output_array</span><span class="p">(</span><span class="n">output_array</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Parse the entire output array, processing all elements.</span>

<span class="sd">    The output array typically contains:</span>
<span class="sd">    1. Reasoning (optional) - thinking/reasoning before the response</span>
<span class="sd">    2. Message - the actual response with content</span>
<span class="sd">    3. Tool calls (optional) - any tool invocations</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict with keys: text, images, tool_calls, reasoning, code_outputs</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;images&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;tool_calls&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;reasoning&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;code_outputs&quot;</span><span class="p">:</span> <span class="kc">None</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">output_array</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="c1"># Process all items in the array</span>
    <span class="n">all_images</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_tool_calls</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_code_outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_reasoning</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">text</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">output_array</span><span class="p">:</span>
        <span class="n">item_type</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">item_type</span> <span class="o">==</span> <span class="s2">&quot;reasoning&quot;</span><span class="p">:</span>
            <span class="c1"># Parse reasoning item</span>
            <span class="n">parsed</span> <span class="o">=</span> <span class="n">_parse_reasoning</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">parsed</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;reasoning&quot;</span><span class="p">):</span>
                <span class="n">all_reasoning</span> <span class="o">=</span> <span class="n">parsed</span><span class="p">[</span><span class="s2">&quot;reasoning&quot;</span><span class="p">]</span>

        <span class="k">elif</span> <span class="n">item_type</span> <span class="o">==</span> <span class="s2">&quot;message&quot;</span><span class="p">:</span>
            <span class="c1"># Parse message item</span>
            <span class="n">parsed</span> <span class="o">=</span> <span class="n">_parse_message</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">parsed</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">):</span>
                <span class="n">text</span> <span class="o">=</span> <span class="n">parsed</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span>

        <span class="k">elif</span> <span class="n">item_type</span> <span class="o">==</span> <span class="s2">&quot;image_generation_call&quot;</span><span class="p">:</span>
            <span class="c1"># Parse image generation call separately</span>
            <span class="n">parsed</span> <span class="o">=</span> <span class="n">_parse_image</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">parsed</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;images&quot;</span><span class="p">):</span>
                <span class="n">all_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parsed</span><span class="p">[</span><span class="s2">&quot;images&quot;</span><span class="p">])</span>

        <span class="k">elif</span> <span class="n">item_type</span> <span class="ow">and</span> <span class="p">(</span><span class="s1">&#39;call&#39;</span> <span class="ow">in</span> <span class="n">item_type</span> <span class="ow">or</span> <span class="s1">&#39;tool&#39;</span> <span class="ow">in</span> <span class="n">item_type</span><span class="p">):</span>
            <span class="c1"># Parse other tool calls</span>
            <span class="n">parsed</span> <span class="o">=</span> <span class="n">_parse_tool_call</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">parsed</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;tool_calls&quot;</span><span class="p">):</span>
                <span class="n">all_tool_calls</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">parsed</span><span class="p">[</span><span class="s2">&quot;tool_calls&quot;</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">parsed</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;code_outputs&quot;</span><span class="p">):</span>
                <span class="n">all_code_outputs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">parsed</span><span class="p">[</span><span class="s2">&quot;code_outputs&quot;</span><span class="p">])</span>


    <span class="n">result</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">text</span> <span class="k">if</span> <span class="n">text</span> <span class="k">else</span> <span class="kc">None</span> <span class="c1"># TODO: they can potentially send multiple complete text messages, we might need to save all of them and only return the first that can convert to outpu parser</span>

    <span class="c1"># Set other fields if they have content</span>
    <span class="n">result</span><span class="p">[</span><span class="s2">&quot;images&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_images</span>
    <span class="k">if</span> <span class="n">all_tool_calls</span><span class="p">:</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;tool_calls&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_tool_calls</span>
    <span class="k">if</span> <span class="n">all_reasoning</span><span class="p">:</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;reasoning&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_reasoning</span>
    <span class="k">if</span> <span class="n">all_code_outputs</span><span class="p">:</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;code_outputs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_code_outputs</span>

    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_serialize_item</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Convert an output item to a serializable dict.&quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">attr</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
                <span class="n">result</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="c1"># def _get_chat_completion_usage(completion: ChatCompletion) -&gt; OpenAICompletionUsage:</span>
<span class="c1">#     return completion.usage</span>


<span class="c1"># A simple heuristic to estimate token count for estimating number of tokens in a Streaming response</span>
<div class="viewcode-block" id="estimate_token_count">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.estimate_token_count">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">estimate_token_count</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimate the token count of a given text.</span>

<span class="sd">    Args:</span>
<span class="sd">        text (str): The text to estimate token count for.</span>

<span class="sd">    Returns:</span>
<span class="sd">        int: Estimated token count.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Split the text into tokens using spaces as a simple heuristic</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

    <span class="c1"># Return the number of tokens</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span></div>



<span class="c1"># OLD CHAT COMPLETION STREAMING FUNCTIONS (COMMENTED OUT)</span>
<span class="c1"># def parse_stream_chat_completion(completion: ChatCompletionChunk) -&gt; str:</span>
<span class="c1">#     r&quot;&quot;&quot;Parse the completion chunks of the chat completion API.&quot;&quot;&quot;</span>
<span class="c1">#     output = completion.choices[0].delta.content</span>
<span class="c1">#     if hasattr(completion, &quot;citations&quot;):</span>
<span class="c1">#         citations = completion.citations</span>
<span class="c1">#         return output, citations</span>
<span class="c1">#     return output</span>


<span class="c1"># def handle_streaming_chat_completion(generator: Stream[ChatCompletionChunk]):</span>
<span class="c1">#     r&quot;&quot;&quot;Handle the streaming completion.&quot;&quot;&quot;</span>
<span class="c1">#     for completion in generator:</span>
<span class="c1">#         log.debug(f&quot;Raw chunk completion: {completion}&quot;)</span>
<span class="c1">#         parsed_content = parse_stream_chat_completion(completion)</span>
<span class="c1">#         yield parsed_content</span>


<div class="viewcode-block" id="handle_streaming_response">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.handle_streaming_response">[docs]</a>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">handle_streaming_response</span><span class="p">(</span>
    <span class="n">stream</span><span class="p">:</span> <span class="n">AsyncIterable</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AsyncGenerator</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Async generator that processes a stream of SSE events from client.responses.create(..., stream=True).</span>

<span class="sd">    Args:</span>
<span class="sd">        stream: An async iterable of SSE events from the OpenAI API</span>

<span class="sd">    Yields:</span>
<span class="sd">        str: Non-empty text fragments parsed from the stream events</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">async</span> <span class="k">for</span> <span class="n">event</span> <span class="ow">in</span> <span class="n">stream</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">event</span></div>



<div class="viewcode-block" id="handle_streaming_response_sync">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.handle_streaming_response_sync">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">handle_streaming_response_sync</span><span class="p">(</span><span class="n">stream</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GeneratorType</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Synchronous version: Iterate over an SSE stream from client.responses.create(..., stream=True),</span>
<span class="sd">    logging each raw event and yielding non-empty text fragments.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># already compatible as this is the OpenAI client</span>
    <span class="k">for</span> <span class="n">event</span> <span class="ow">in</span> <span class="n">stream</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">event</span></div>





<div class="viewcode-block" id="OpenAIClient">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.OpenAIClient">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">OpenAIClient</span><span class="p">(</span><span class="n">ModelClient</span><span class="p">):</span>
    <span class="vm">__doc__</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;&quot;&quot;A component wrapper for the OpenAI API client.</span>

<span class="s2">    Support both embedding and response API, including multimodal capabilities.</span>


<span class="s2">    Users (1) simplify use ``Embedder`` and ``Generator`` components by passing OpenAIClient() as the model_client.</span>
<span class="s2">    (2) can use this as an example to create their own API client or extend this class(copying and modifing the code) in their own project.</span>

<span class="s2">    Note:</span>
<span class="s2">        We suggest users not to use `response_format` to enforce output data type or `tools` and `tool_choice`  in your model_kwargs when calling the API.</span>
<span class="s2">        We do not know how OpenAI is doing the formating or what prompt they have added.</span>
<span class="s2">        Instead</span>
<span class="s2">        - use :ref:`OutputParser&lt;components-output_parsers&gt;` for response parsing and formating.</span>

<span class="s2">        For multimodal inputs, provide images in model_kwargs[&quot;images&quot;] as a path, URL, or list of them.</span>
<span class="s2">        The model must support vision capabilities (e.g., gpt-4o, gpt-4o-mini, o1, o1-mini).</span>

<span class="s2">        For image generation, use model_type=ModelType.IMAGE_GENERATION and provide:</span>
<span class="s2">        - model: &quot;dall-e-3&quot; or &quot;dall-e-2&quot;</span>
<span class="s2">        - prompt: Text description of the image to generate</span>
<span class="s2">        - size: &quot;1024x1024&quot;, &quot;1024x1792&quot;, or &quot;1792x1024&quot; for DALL-E 3; &quot;256x256&quot;, &quot;512x512&quot;, or &quot;1024x1024&quot; for DALL-E 2</span>
<span class="s2">        - quality: &quot;standard&quot; or &quot;hd&quot; (DALL-E 3 only)</span>
<span class="s2">        - n: Number of images to generate (1 for DALL-E 3, 1-10 for DALL-E 2)</span>
<span class="s2">        - response_format: &quot;url&quot; or &quot;b64_json&quot;</span>

<span class="s2">    Examples:</span>
<span class="s2">        Basic text generation::</span>

<span class="s2">            from adalflow.components.model_client import OpenAIClient</span>
<span class="s2">            from adalflow.core import Generator</span>

<span class="s2">            # Initialize client (uses OPENAI_API_KEY env var by default)</span>
<span class="s2">            client = OpenAIClient()</span>

<span class="s2">            # Create a generator for text</span>
<span class="s2">            generator = Generator(</span>
<span class="s2">                model_client=client,</span>
<span class="s2">                model_kwargs={&quot;model&quot;: &quot;gpt-4o-mini&quot;}</span>
<span class="s2">            )</span>

<span class="s2">            # Generate response</span>
<span class="s2">            response = generator(prompt_kwargs={&quot;input_str&quot;: &quot;What is machine learning?&quot;})</span>
<span class="s2">            print(response.data)</span>

<span class="s2">        Multimodal with URL image::</span>

<span class="s2">            # Vision model with image from URL</span>
<span class="s2">            generator = Generator(</span>
<span class="s2">                model_client=OpenAIClient(),</span>
<span class="s2">                model_kwargs={</span>
<span class="s2">                    &quot;model&quot;: &quot;gpt-4o&quot;,</span>
<span class="s2">                    &quot;images&quot;: &quot;https://example.com/chart.jpg&quot;</span>
<span class="s2">                }</span>
<span class="s2">            )</span>

<span class="s2">            response = generator(</span>
<span class="s2">                prompt_kwargs={&quot;input_str&quot;: &quot;Analyze this chart and explain the trends&quot;}</span>
<span class="s2">            )</span>

<span class="s2">        Multimodal with local images::</span>

<span class="s2">            # Multiple local images</span>
<span class="s2">            generator = Generator(</span>
<span class="s2">                model_client=OpenAIClient(),</span>
<span class="s2">                model_kwargs={</span>
<span class="s2">                    &quot;model&quot;: &quot;gpt-4o&quot;,</span>
<span class="s2">                    &quot;images&quot;: [</span>
<span class="s2">                        &quot;/path/to/image1.jpg&quot;,</span>
<span class="s2">                        &quot;/path/to/image2.png&quot;</span>
<span class="s2">                    ]</span>
<span class="s2">                }</span>
<span class="s2">            )</span>

<span class="s2">            response = generator(</span>
<span class="s2">                prompt_kwargs={&quot;input_str&quot;: &quot;Compare these two images&quot;}</span>
<span class="s2">            )</span>

<span class="s2">        Pre-formatted images with custom encoding::</span>

<span class="s2">            import base64</span>
<span class="s2">            from adalflow.core.functional import encode_image</span>

<span class="s2">            # Option 1: Using the encode_image helper</span>
<span class="s2">            base64_img = encode_image(&quot;/path/to/image.jpg&quot;)</span>

<span class="s2">            # Option 2: Manual base64 encoding</span>
<span class="s2">            with open(&quot;/path/to/image.png&quot;, &quot;rb&quot;) as f:</span>
<span class="s2">                base64_img = base64.b64encode(f.read()).decode(&#39;utf-8&#39;)</span>

<span class="s2">            # Use pre-formatted image data</span>
<span class="s2">            generator = Generator(</span>
<span class="s2">                model_client=OpenAIClient(),</span>
<span class="s2">                model_kwargs={</span>
<span class="s2">                    &quot;model&quot;: &quot;gpt-4o&quot;,</span>
<span class="s2">                    &quot;images&quot;: [</span>
<span class="s2">                        # Pre-formatted as base64 data URI</span>
<span class="s2">                        f&quot;data:image/png;base64,</span><span class="si">{base64_img}</span><span class="s2">&quot;,</span>
<span class="s2">                        # Or as a dict with type and image_url</span>
<span class="s2">                        {</span>
<span class="s2">                            &quot;type&quot;: &quot;input_image&quot;,</span>
<span class="s2">                            &quot;image_url&quot;: f&quot;data:image/jpeg;base64,</span><span class="si">{base64_img}</span><span class="s2">&quot;</span>
<span class="s2">                        },</span>
<span class="s2">                        # Mix with regular URLs</span>
<span class="s2">                        &quot;https://example.com/chart.jpg&quot;</span>
<span class="s2">                    ]</span>
<span class="s2">                }</span>
<span class="s2">            )</span>

<span class="s2">            response = generator(</span>
<span class="s2">                prompt_kwargs={&quot;input_str&quot;: &quot;Analyze these images&quot;}</span>
<span class="s2">            )</span>

<span class="s2">        Reasoning models (O1, O3)::</span>

<span class="s2">            from adalflow.core.types import ModelType</span>

<span class="s2">            # O3 reasoning model with effort configuration</span>
<span class="s2">            generator = Generator(</span>
<span class="s2">                model_client=OpenAIClient(),</span>
<span class="s2">                model_type=ModelType.LLM_REASONING,</span>
<span class="s2">                model_kwargs={</span>
<span class="s2">                    &quot;model&quot;: &quot;o3&quot;,</span>
<span class="s2">                    &quot;reasoning&quot;: {</span>
<span class="s2">                        &quot;effort&quot;: &quot;medium&quot;,  # low, medium, high</span>
<span class="s2">                        &quot;summary&quot;: &quot;auto&quot;    # detailed, auto, none</span>
<span class="s2">                    }</span>
<span class="s2">                }</span>
<span class="s2">            )</span>

<span class="s2">            response = generator(</span>
<span class="s2">                prompt_kwargs={&quot;input_str&quot;: &quot;Solve this complex problem: ...&quot;}</span>
<span class="s2">            )</span>

<span class="s2">        Image generation with DALL-E (legacy method)::</span>

<span class="s2">            from adalflow.core.types import ModelType</span>

<span class="s2">            # Generate an image using ModelType.IMAGE_GENERATION</span>
<span class="s2">            generator = Generator(</span>
<span class="s2">                model_client=OpenAIClient(),</span>
<span class="s2">                model_type=ModelType.IMAGE_GENERATION,</span>
<span class="s2">                model_kwargs={</span>
<span class="s2">                    &quot;model&quot;: &quot;dall-e-3&quot;,</span>
<span class="s2">                    &quot;size&quot;: &quot;1024x1792&quot;,</span>
<span class="s2">                    &quot;quality&quot;: &quot;hd&quot;,</span>
<span class="s2">                    &quot;n&quot;: 1</span>
<span class="s2">                }</span>
<span class="s2">            )</span>

<span class="s2">            response = generator(</span>
<span class="s2">                prompt_kwargs={&quot;input_str&quot;: &quot;A futuristic city with flying cars at sunset&quot;}</span>
<span class="s2">            )</span>
<span class="s2">            # response.data contains the image URL or base64 data</span>

<span class="s2">        Image generation via tools (new API)::</span>

<span class="s2">            import base64</span>

<span class="s2">            # Generate images using the new tools API</span>
<span class="s2">            generator = Generator(</span>
<span class="s2">                model_client=OpenAIClient(),</span>
<span class="s2">                model_kwargs={</span>
<span class="s2">                    &quot;model&quot;: &quot;gpt-4o-mini&quot;,  # or any model that supports tools</span>
<span class="s2">                    &quot;tools&quot;: [{&quot;type&quot;: &quot;image_generation&quot;}]</span>
<span class="s2">                }</span>
<span class="s2">            )</span>

<span class="s2">            # Generate an image</span>
<span class="s2">            response = generator(</span>
<span class="s2">                prompt_kwargs={</span>
<span class="s2">                    &quot;input_str&quot;: &quot;Generate an image of a gray tabby cat hugging an otter with an orange scarf&quot;</span>
<span class="s2">                }</span>
<span class="s2">            )</span>

<span class="s2">            # Access the generated image(s)</span>
<span class="s2">            if isinstance(response.data, list):</span>
<span class="s2">                # Multiple images</span>
<span class="s2">                for i, img_base64 in enumerate(response.data):</span>
<span class="s2">                    with open(f&quot;generated_</span><span class="si">{i}</span><span class="s2">.png&quot;, &quot;wb&quot;) as f:</span>
<span class="s2">                        f.write(base64.b64decode(img_base64))</span>
<span class="s2">            elif isinstance(response.data, str):</span>
<span class="s2">                # Single image</span>
<span class="s2">                with open(&quot;generated.png&quot;, &quot;wb&quot;) as f:</span>
<span class="s2">                    f.write(base64.b64decode(response.data))</span>
<span class="s2">            elif isinstance(response.data, dict) and &quot;images&quot; in response.data:</span>
<span class="s2">                # Mixed response with text and images</span>
<span class="s2">                print(&quot;Text:&quot;, response.data[&quot;text&quot;])</span>
<span class="s2">                for i, img_base64 in enumerate(response.data[&quot;images&quot;]):</span>
<span class="s2">                    with open(f&quot;generated_</span><span class="si">{i}</span><span class="s2">.png&quot;, &quot;wb&quot;) as f:</span>
<span class="s2">                        f.write(base64.b64decode(img_base64))</span>

<span class="s2">        Embeddings::</span>

<span class="s2">            from adalflow.core import Embedder</span>

<span class="s2">            # Create embedder</span>
<span class="s2">            embedder = Embedder(</span>
<span class="s2">                model_client=OpenAIClient(),</span>
<span class="s2">                model_kwargs={&quot;model&quot;: &quot;text-embedding-3-small&quot;}</span>
<span class="s2">            )</span>

<span class="s2">            # Generate embeddings</span>
<span class="s2">            embeddings = embedder(input=[&quot;Hello world&quot;, &quot;Machine learning&quot;])</span>
<span class="s2">            print(embeddings.data)  # List of embedding vectors</span>

<span class="s2">        Streaming responses::</span>

<span class="s2">            from adalflow.components.model_client.utils import extract_text_from_response_stream</span>

<span class="s2">            # Enable streaming</span>
<span class="s2">            generator = Generator(</span>
<span class="s2">                model_client=OpenAIClient(),</span>
<span class="s2">                model_kwargs={</span>
<span class="s2">                    &quot;model&quot;: &quot;gpt-4o&quot;,</span>
<span class="s2">                    &quot;stream&quot;: True</span>
<span class="s2">                }</span>
<span class="s2">            )</span>

<span class="s2">            # Stream the response</span>
<span class="s2">            response = generator(prompt_kwargs={&quot;input_str&quot;: &quot;Tell me a story&quot;})</span>

<span class="s2">            # Extract text from Response API streaming events</span>
<span class="s2">            for event in response.raw_response:</span>
<span class="s2">                text = extract_text_from_response_stream(event)</span>
<span class="s2">                if text:</span>
<span class="s2">                    print(text, end=&quot;&quot;)</span>

<span class="s2">        Custom API endpoint::</span>

<span class="s2">            # Use with third-party providers or local models</span>
<span class="s2">            client = OpenAIClient(</span>
<span class="s2">                base_url=&quot;https://api.custom-provider.com/v1/&quot;,</span>
<span class="s2">                api_key=&quot;your-api-key&quot;,</span>
<span class="s2">                headers={&quot;X-Custom-Header&quot;: &quot;value&quot;}</span>
<span class="s2">            )</span>

<span class="s2">    Args:</span>
<span class="s2">        api_key (Optional[str], optional): OpenAI API key. Defaults to `None`.</span>
<span class="s2">        non_streaming_chat_completion_parser (Callable[[Completion], Any], optional): Legacy parser for chat completions.</span>
<span class="s2">            Defaults to `None` (deprecated).</span>
<span class="s2">        streaming_chat_completion_parser (Callable[[Completion], Any], optional): Legacy parser for streaming chat completions.</span>
<span class="s2">            Defaults to `None` (deprecated).</span>
<span class="s2">        non_streaming_response_parser (Callable[[Response], Any], optional): The parser for non-streaming responses.</span>
<span class="s2">            Defaults to `get_response_output_text`.</span>
<span class="s2">        streaming_response_parser (Callable[[Response], Any], optional): The parser for streaming responses.</span>
<span class="s2">            Defaults to `handle_streaming_response`.</span>
<span class="s2">        input_type (Literal[&quot;text&quot;, &quot;messages&quot;]): Input type for the client. Defaults to &quot;text&quot;.</span>
<span class="s2">        base_url (str): The API base URL to use when initializing the client.</span>
<span class="s2">            Defaults to `&quot;https://api.openai.com/v1/&quot;`, but can be customized for third-party API providers or self-hosted models.</span>
<span class="s2">        env_api_key_name (str): The environment variable name for the API key. Defaults to `&quot;OPENAI_API_KEY&quot;`.</span>
<span class="s2">        organization (Optional[str], optional): OpenAI organization key. Defaults to None.</span>
<span class="s2">        headers (Optional[Dict[str, str]], optional): Additional headers to include in API requests. Defaults to None.</span>

<span class="s2">    References:</span>
<span class="s2">        - OpenAI API Overview: https://platform.openai.com/docs/introduction, https://platform.openai.com/docs/guides/images-vision?api-mode=responses</span>
<span class="s2">        - Embeddings Guide: https://platform.openai.com/docs/guides/embeddings</span>
<span class="s2">        - Chat Completion Models: https://platform.openai.com/docs/guides/text-generation</span>
<span class="s2">        - Response api: https://platform.openai.com/docs/api-reference/responses/create, Analyze images and use them as input and/or generate images as output</span>
<span class="s2">        - Vision Models: https://platform.openai.com/docs/guides/vision</span>
<span class="s2">        - Image Generation: https://platform.openai.com/docs/guides/images</span>
<span class="s2">        - reasoning: https://platform.openai.com/docs/guides/reasoning</span>

<span class="s2">    Note:</span>
<span class="s2">        - Ensure each OpenAIClient instance is used by one generator only.</span>
<span class="s2">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">api_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="c1"># OLD CHAT COMPLETION PARSER PARAMS (kept for backward compatibility)</span>
        <span class="n">non_streaming_chat_completion_parser</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Callable</span><span class="p">[[</span><span class="n">Completion</span><span class="p">],</span> <span class="n">Any</span><span class="p">]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># non-streaming parser - deprecated but accepted</span>
        <span class="n">streaming_chat_completion_parser</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Callable</span><span class="p">[[</span><span class="n">Completion</span><span class="p">],</span> <span class="n">Any</span><span class="p">]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># streaming parser - deprecated but accepted</span>
        <span class="c1"># Response API parsers (used for reasoning models)</span>
        <span class="n">non_streaming_response_parser</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Response</span><span class="p">],</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">streaming_response_parser</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Response</span><span class="p">],</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_type</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;messages&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span>
        <span class="n">base_url</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;https://api.openai.com/v1/&quot;</span><span class="p">,</span>
        <span class="n">env_api_key_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">,</span>
        <span class="n">organization</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">headers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;It is recommended to set the OPENAI_API_KEY environment variable instead of passing it as an argument.</span>

<span class="sd">        Args:</span>
<span class="sd">            api_key (Optional[str], optional): OpenAI API key. Defaults to None.</span>
<span class="sd">            non_streaming_chat_completion_parser (Optional[Callable[[Completion], Any]], optional): DEPRECATED - Legacy parser for chat completions. Ignored, kept for backward compatibility. Defaults to None.</span>
<span class="sd">            streaming_chat_completion_parser (Optional[Callable[[Completion], Any]], optional): DEPRECATED - Legacy parser for streaming chat completions. Ignored, kept for backward compatibility. Defaults to None.</span>
<span class="sd">            non_streaming_response_parser (Optional[Callable[[Response], Any]], optional): Parser for non-streaming responses. Defaults to None.</span>
<span class="sd">            streaming_response_parser (Optional[Callable[[Response], Any]], optional): Parser for streaming responses. Defaults to None.</span>
<span class="sd">            input_type (Literal[&quot;text&quot;, &quot;messages&quot;]): Input type for the client. Defaults to &quot;text&quot;.</span>
<span class="sd">            base_url (str): The API base URL to use when initializing the client.</span>
<span class="sd">            env_api_key_name (str): The environment variable name for the API key. Defaults to `&quot;OPENAI_API_KEY&quot;`.</span>
<span class="sd">            organization (Optional[str], optional): OpenAI organization key. Defaults to None.</span>
<span class="sd">            headers (Optional[Dict[str, str]], optional): Additional headers to include in API requests. Defaults to None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Log deprecation warning if old parsers are provided</span>
        <span class="k">if</span> <span class="n">non_streaming_chat_completion_parser</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;non_streaming_chat_completion_parser is deprecated and will be ignored. &quot;</span>
                <span class="s2">&quot;The OpenAI client now uses the Response API exclusively.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">streaming_chat_completion_parser</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;streaming_chat_completion_parser is deprecated and will be ignored. &quot;</span>
                <span class="s2">&quot;The OpenAI client now uses the Response API exclusively.&quot;</span>
            <span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_api_key</span> <span class="o">=</span> <span class="n">api_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_url</span> <span class="o">=</span> <span class="n">base_url</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_env_api_key_name</span> <span class="o">=</span> <span class="n">env_api_key_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">organization</span> <span class="o">=</span> <span class="n">organization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">headers</span> <span class="o">=</span> <span class="n">headers</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sync_client</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_sync_client</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">async_client</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># only initialize if the async call is called</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_type</span> <span class="o">=</span> <span class="n">input_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_api_kwargs</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># add api kwargs when the OpenAI Client is called</span>

        <span class="c1"># Response API parsers (RESPONSE API ONLY NOW)</span>
        <span class="c1"># (used for both synchronous and asynchronous (stream + non-streaming) calls via Response API)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">non_streaming_response_parser</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">non_streaming_response_parser</span> <span class="ow">or</span> <span class="n">get_response_output_text</span>
        <span class="p">)</span>
        <span class="c1"># Separate sync and async streaming parsers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">streaming_response_parser_sync</span> <span class="o">=</span> <span class="n">handle_streaming_response_sync</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">streaming_response_parser_async</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">streaming_response_parser</span> <span class="ow">or</span> <span class="n">handle_streaming_response</span>
        <span class="p">)</span>

        <span class="c1"># Default parsers (will be set dynamically based on sync/async context)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">response_parser</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">non_streaming_response_parser</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">streaming_response_parser</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">streaming_response_parser_async</span>
        <span class="p">)</span>  <span class="c1"># Default to async</span>
        <span class="c1"># self.chat_completion_parser = self.non_streaming_chat_completion_parser  # COMMENTED OUT</span>

<div class="viewcode-block" id="OpenAIClient.init_sync_client">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.OpenAIClient.init_sync_client">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">init_sync_client</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">api_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_api_key</span> <span class="ow">or</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_env_api_key_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">api_key</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Environment variable </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_env_api_key_name</span><span class="si">}</span><span class="s2"> must be set&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">OpenAI</span><span class="p">(</span>
            <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">,</span>
            <span class="n">base_url</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">base_url</span><span class="p">,</span>
            <span class="n">organization</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">organization</span><span class="p">,</span>
            <span class="n">default_headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">headers</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="OpenAIClient.init_async_client">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.OpenAIClient.init_async_client">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">init_async_client</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">api_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_api_key</span> <span class="ow">or</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_env_api_key_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">api_key</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Environment variable </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_env_api_key_name</span><span class="si">}</span><span class="s2"> must be set&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">AsyncOpenAI</span><span class="p">(</span>
            <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">,</span>
            <span class="n">base_url</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">base_url</span><span class="p">,</span>
            <span class="n">organization</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">organization</span><span class="p">,</span>
            <span class="n">default_headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">headers</span><span class="p">,</span>
        <span class="p">)</span></div>


    <span class="c1"># NEW RESPONSE API ONLY FUNCTION</span>
<div class="viewcode-block" id="OpenAIClient.parse_chat_completion">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.OpenAIClient.parse_chat_completion">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">parse_chat_completion</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">completion</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Response</span><span class="p">,</span> <span class="n">AsyncIterable</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;GeneratorOutput&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Parse the Response API completion and put it into the raw_response.</span>
<span class="sd">        Fully migrated to Response API only.&quot;&quot;&quot;</span>

        <span class="n">parser</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">response_parser</span>
        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;completion/response: </span><span class="si">{</span><span class="n">completion</span><span class="si">}</span><span class="s2">, parser: </span><span class="si">{</span><span class="n">parser</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Check if this is a Response with complex output (tools, images, etc.)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">completion</span><span class="p">,</span> <span class="n">Response</span><span class="p">):</span>
            <span class="n">parsed_content</span> <span class="o">=</span> <span class="n">parse_response_output</span><span class="p">(</span><span class="n">completion</span><span class="p">)</span>
            <span class="n">usage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_completion_usage</span><span class="p">(</span><span class="n">completion</span><span class="p">)</span>

            <span class="n">data</span> <span class="o">=</span> <span class="n">parsed_content</span><span class="o">.</span><span class="n">text</span>

            <span class="n">thinking</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">parsed_content</span><span class="o">.</span><span class="n">reasoning</span><span class="p">:</span>
                <span class="n">thinking</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">parsed_content</span><span class="o">.</span><span class="n">reasoning</span><span class="p">)</span>


            <span class="k">return</span> <span class="n">GeneratorOutput</span><span class="p">(</span>
                <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>  <span class="c1"># only text</span>
                <span class="n">thinking</span><span class="o">=</span><span class="n">thinking</span><span class="p">,</span>
                <span class="n">images</span><span class="o">=</span><span class="n">parsed_content</span><span class="o">.</span><span class="n">images</span><span class="p">,</span>  <span class="c1"># List of image data (base64 or URLs)</span>
                <span class="n">tool_use</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># Will be populated when we handle function tool calls</span>
                <span class="n">error</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">raw_response</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                <span class="n">usage</span><span class="o">=</span><span class="n">usage</span>
            <span class="p">)</span>
        <span class="c1"># Regular response handling (streaming or other)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">parser</span><span class="p">(</span><span class="n">completion</span><span class="p">)</span>
        <span class="n">usage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_completion_usage</span><span class="p">(</span><span class="n">completion</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">GeneratorOutput</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">raw_response</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">usage</span><span class="o">=</span><span class="n">usage</span><span class="p">)</span></div>



    <span class="c1"># NEW RESPONSE API ONLY FUNCTION</span>
<div class="viewcode-block" id="OpenAIClient.track_completion_usage">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.OpenAIClient.track_completion_usage">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">track_completion_usage</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">completion</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Response</span><span class="p">,</span> <span class="n">AsyncIterable</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ResponseUsage</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Track usage for Response API only.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">completion</span><span class="p">,</span> <span class="n">Response</span><span class="p">):</span>
            <span class="c1"># Handle Response object with ResponseUsage structure</span>
            <span class="n">input_tokens_details</span> <span class="o">=</span> <span class="n">InputTokensDetails</span><span class="p">(</span>
                <span class="n">cached_tokens</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">completion</span><span class="o">.</span><span class="n">usage</span><span class="p">,</span> <span class="s2">&quot;cached_tokens&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="n">output_tokens_details</span> <span class="o">=</span> <span class="n">OutputTokensDetails</span><span class="p">(</span>
                <span class="n">reasoning_tokens</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">completion</span><span class="o">.</span><span class="n">usage</span><span class="p">,</span> <span class="s2">&quot;reasoning_tokens&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="k">return</span> <span class="n">AdalFlowResponseUsage</span><span class="p">(</span>
                <span class="n">input_tokens</span><span class="o">=</span><span class="n">completion</span><span class="o">.</span><span class="n">usage</span><span class="o">.</span><span class="n">input_tokens</span><span class="p">,</span>
                <span class="n">input_tokens_details</span><span class="o">=</span><span class="n">input_tokens_details</span><span class="p">,</span>
                <span class="n">output_tokens</span><span class="o">=</span><span class="n">completion</span><span class="o">.</span><span class="n">usage</span><span class="o">.</span><span class="n">output_tokens</span><span class="p">,</span>
                <span class="n">output_tokens_details</span><span class="o">=</span><span class="n">output_tokens_details</span><span class="p">,</span>
                <span class="n">total_tokens</span><span class="o">=</span><span class="n">completion</span><span class="o">.</span><span class="n">usage</span><span class="o">.</span><span class="n">total_tokens</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># otherwise return the AdalFlowResponseUsage with None values with log warnings</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">completion</span><span class="p">,</span> <span class="s2">&quot;__aiter__&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">completion</span><span class="p">,</span> <span class="s2">&quot;__iter__&quot;</span><span class="p">):</span>
            <span class="n">log</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Cannot track usage for generator/iterator. Usage tracking should be handled when consuming the stream.&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown completion type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">completion</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">AdalFlowResponseUsage</span><span class="p">(</span>
            <span class="n">input_tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">input_tokens_details</span><span class="o">=</span><span class="n">InputTokensDetails</span><span class="p">(</span><span class="n">cached_tokens</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
            <span class="n">output_tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">output_tokens_details</span><span class="o">=</span><span class="n">OutputTokensDetails</span><span class="p">(</span><span class="n">reasoning_tokens</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
            <span class="n">total_tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="OpenAIClient.parse_embedding_response">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.OpenAIClient.parse_embedding_response">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">parse_embedding_response</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">:</span> <span class="n">CreateEmbeddingResponse</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EmbedderOutput</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Parse the embedding response to a structure Adalflow components can understand.</span>

<span class="sd">        Should be called in ``Embedder``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">parse_embedding_response</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error parsing the embedding response: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">EmbedderOutput</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">[],</span> <span class="n">error</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">),</span> <span class="n">raw_response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_convert_llm_inputs_to_messages</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">images</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">detail</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
        <span class="c1"># convert input to messages</span>
        <span class="n">messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_type</span> <span class="o">==</span> <span class="s2">&quot;messages&quot;</span><span class="p">:</span>
            <span class="n">system_start_tag</span> <span class="o">=</span> <span class="s2">&quot;&lt;START_OF_SYSTEM_PROMPT&gt;&quot;</span>
            <span class="n">system_end_tag</span> <span class="o">=</span> <span class="s2">&quot;&lt;END_OF_SYSTEM_PROMPT&gt;&quot;</span>
            <span class="n">user_start_tag</span> <span class="o">=</span> <span class="s2">&quot;&lt;START_OF_USER_PROMPT&gt;&quot;</span>
            <span class="n">user_end_tag</span> <span class="o">=</span> <span class="s2">&quot;&lt;END_OF_USER_PROMPT&gt;&quot;</span>

            <span class="c1"># new regex pattern to ignore special characters such as \n</span>
            <span class="n">pattern</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">rf</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">system_start_tag</span><span class="si">}</span><span class="s2">\s*(.*?)\s*</span><span class="si">{</span><span class="n">system_end_tag</span><span class="si">}</span><span class="s2">\s*&quot;</span>
                <span class="sa">rf</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user_start_tag</span><span class="si">}</span><span class="s2">\s*(.*?)\s*</span><span class="si">{</span><span class="n">user_end_tag</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

            <span class="c1"># Compile the regular expression</span>
            <span class="n">regex</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>

            <span class="c1"># re.DOTALL is to allow . to match newline so that (.*?) does not match in a single line</span>
            <span class="n">regex</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>
            <span class="c1"># Match the pattern</span>
            <span class="n">match</span> <span class="o">=</span> <span class="n">regex</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
            <span class="n">system_prompt</span><span class="p">,</span> <span class="n">input_str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="n">match</span><span class="p">:</span>
                <span class="n">system_prompt</span> <span class="o">=</span> <span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">input_str</span> <span class="o">=</span> <span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No match found.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">system_prompt</span> <span class="ow">and</span> <span class="n">input_str</span><span class="p">:</span>
                <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">system_prompt</span><span class="p">})</span>
                <span class="k">if</span> <span class="n">images</span><span class="p">:</span>
                    <span class="n">content</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">input_str</span><span class="p">}]</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)):</span>
                        <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">images</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
                        <span class="n">content</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_prepare_image_content</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">detail</span><span class="p">))</span>
                    <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">content</span><span class="p">})</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">input_str</span><span class="p">})</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">images</span><span class="p">:</span>
                <span class="n">content</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="nb">input</span><span class="p">}]</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)):</span>
                    <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">images</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
                    <span class="n">content</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_prepare_image_content</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">detail</span><span class="p">))</span>
                <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">content</span><span class="p">})</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="nb">input</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">messages</span>

    <span class="c1"># adapted for the response api</span>
<div class="viewcode-block" id="OpenAIClient.convert_inputs_to_api_kwargs">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.OpenAIClient.convert_inputs_to_api_kwargs">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">convert_inputs_to_api_kwargs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">model_kwargs</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="p">{},</span>
        <span class="n">model_type</span><span class="p">:</span> <span class="n">ModelType</span> <span class="o">=</span> <span class="n">ModelType</span><span class="o">.</span><span class="n">UNDEFINED</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Specify the API input type and output api_kwargs that will be used in _call and _acall methods.</span>
<span class="sd">        Convert the Component&#39;s standard input, and system_input(chat model) and model_kwargs into API-specific format.</span>
<span class="sd">        For multimodal inputs, images can be provided in model_kwargs[&quot;images&quot;] as a string path, URL, or list of them.</span>
<span class="sd">        The model specified in model_kwargs[&quot;model&quot;] must support multimodal capabilities when using images.</span>

<span class="sd">        Args:</span>
<span class="sd">            input: The input text or messages to process</span>
<span class="sd">            model_kwargs: Additional parameters including:</span>
<span class="sd">                - images: Optional image source(s) as path, URL, or list of them</span>
<span class="sd">                - detail: Image detail level (&#39;auto&#39;, &#39;low&#39;, or &#39;high&#39;), defaults to &#39;auto&#39;</span>
<span class="sd">                - model: The model to use (must support multimodal inputs if images are provided)</span>
<span class="sd">            model_type: The type of model (EMBEDDER or LLM)</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dict: API-specific kwargs for the model call</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">final_model_kwargs</span> <span class="o">=</span> <span class="n">model_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="n">ModelType</span><span class="o">.</span><span class="n">EMBEDDER</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="nb">input</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
            <span class="c1"># convert input to input</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;input must be a sequence of text&quot;</span><span class="p">)</span>
            <span class="n">final_model_kwargs</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">input</span>
        <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="n">ModelType</span><span class="o">.</span><span class="n">LLM</span> <span class="ow">or</span> <span class="n">model_type</span> <span class="o">==</span> <span class="n">ModelType</span><span class="o">.</span><span class="n">LLM_REASONING</span><span class="p">:</span>
            <span class="c1"># Check if images are provided for multimodal input</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">final_model_kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;images&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">images</span><span class="p">:</span>
                <span class="c1"># Use helper function to format content with images</span>
                <span class="n">content</span> <span class="o">=</span> <span class="n">format_content_for_response_api</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">images</span><span class="p">)</span>

                <span class="c1"># For responses.create API, wrap in user message format</span>
                <span class="n">final_model_kwargs</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">content</span>
                    <span class="p">}</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Text-only input</span>
                <span class="n">final_model_kwargs</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">input</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;model_type </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2"> is not supported&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">final_model_kwargs</span></div>


<div class="viewcode-block" id="OpenAIClient.parse_image_generation_response">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.OpenAIClient.parse_image_generation_response">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">parse_image_generation_response</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Image</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">GeneratorOutput</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Parse the image generation response into a GeneratorOutput.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Extract URLs or base64 data from the response</span>
            <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">img</span><span class="o">.</span><span class="n">url</span> <span class="ow">or</span> <span class="n">img</span><span class="o">.</span><span class="n">b64_json</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">response</span><span class="p">]</span>
            <span class="c1"># For single image responses, unwrap from list</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">GeneratorOutput</span><span class="p">(</span>
                <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                <span class="n">raw_response</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">response</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error parsing image generation response: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">GeneratorOutput</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">),</span> <span class="n">raw_response</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">response</span><span class="p">))</span></div>


<div class="viewcode-block" id="OpenAIClient.call">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.OpenAIClient.call">[docs]</a>
    <span class="nd">@backoff</span><span class="o">.</span><span class="n">on_exception</span><span class="p">(</span>
        <span class="n">backoff</span><span class="o">.</span><span class="n">expo</span><span class="p">,</span>
        <span class="p">(</span>
            <span class="n">APITimeoutError</span><span class="p">,</span>
            <span class="n">InternalServerError</span><span class="p">,</span>
            <span class="n">RateLimitError</span><span class="p">,</span>
            <span class="n">UnprocessableEntityError</span><span class="p">,</span>
            <span class="n">BadRequestError</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">max_time</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">api_kwargs</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="p">{},</span> <span class="n">model_type</span><span class="p">:</span> <span class="n">ModelType</span> <span class="o">=</span> <span class="n">ModelType</span><span class="o">.</span><span class="n">UNDEFINED</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        kwargs is the combined input and model_kwargs.  Support streaming call.</span>
<span class="sd">        For reasoning model, users can add &quot;reasoning&quot; key to the api_kwargs to pass the reasoning config.</span>
<span class="sd">        eg:</span>
<span class="sd">        model_kwargs = {</span>
<span class="sd">            &quot;model&quot;: &quot;gpt-4o-reasoning&quot;,</span>
<span class="sd">            &quot;reasoning&quot;: {</span>
<span class="sd">                &quot;effort&quot;: &quot;medium&quot;, # low, medium, highc</span>
<span class="sd">                &quot;summary&quot;: &quot;auto&quot;, #detailed, auto, none</span>
<span class="sd">            }</span>
<span class="sd">        }</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_api_kwargs</span> <span class="o">=</span> <span class="n">api_kwargs</span>
        <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="n">ModelType</span><span class="o">.</span><span class="n">EMBEDDER</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sync_client</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="o">**</span><span class="n">api_kwargs</span><span class="p">)</span>
        <span class="c1"># OLD CHAT COMPLETION CALLS (COMMENTED OUT)</span>
        <span class="c1"># elif model_type == ModelType.LLM:</span>
        <span class="c1">#     if &quot;stream&quot; in api_kwargs and api_kwargs.get(&quot;stream&quot;, False):</span>
        <span class="c1">#         log.debug(&quot;streaming call&quot;)</span>
        <span class="c1">#         self.chat_completion_parser = self.streaming_chat_completion_parser</span>
        <span class="c1">#         return self.sync_client.chat.completions.create(**api_kwargs)</span>
        <span class="c1">#     else:</span>
        <span class="c1">#         log.debug(&quot;non-streaming call&quot;)</span>
        <span class="c1">#         self.chat_completion_parser = self.non_streaming_chat_completion_parser</span>
        <span class="c1">#         return self.sync_client.chat.completions.create(**api_kwargs)</span>
        <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="n">ModelType</span><span class="o">.</span><span class="n">LLM_REASONING</span> <span class="ow">or</span> <span class="n">model_type</span> <span class="o">==</span> <span class="n">ModelType</span><span class="o">.</span><span class="n">LLM</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;stream&quot;</span> <span class="ow">in</span> <span class="n">api_kwargs</span> <span class="ow">and</span> <span class="n">api_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;stream&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;streaming call&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">response_parser</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">streaming_response_parser_sync</span>
                <span class="p">)</span>  <span class="c1"># Use sync streaming parser</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sync_client</span><span class="o">.</span><span class="n">responses</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="o">**</span><span class="n">api_kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;non-streaming call&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">response_parser</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">non_streaming_response_parser</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sync_client</span><span class="o">.</span><span class="n">responses</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="o">**</span><span class="n">api_kwargs</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;model_type </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2"> is not supported&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="OpenAIClient.acall">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.OpenAIClient.acall">[docs]</a>
    <span class="nd">@backoff</span><span class="o">.</span><span class="n">on_exception</span><span class="p">(</span>
        <span class="n">backoff</span><span class="o">.</span><span class="n">expo</span><span class="p">,</span>
        <span class="p">(</span>
            <span class="n">APITimeoutError</span><span class="p">,</span>
            <span class="n">InternalServerError</span><span class="p">,</span>
            <span class="n">RateLimitError</span><span class="p">,</span>
            <span class="n">UnprocessableEntityError</span><span class="p">,</span>
            <span class="n">BadRequestError</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">max_time</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">acall</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">api_kwargs</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="p">{},</span> <span class="n">model_type</span><span class="p">:</span> <span class="n">ModelType</span> <span class="o">=</span> <span class="n">ModelType</span><span class="o">.</span><span class="n">UNDEFINED</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        kwargs is the combined input and model_kwargs. Support async streaming call.</span>

<span class="sd">        This method now relies on the OpenAI Responses API to handle streaming and non-streaming calls</span>
<span class="sd">        with the asynchronous client</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># store the api kwargs in the client</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_api_kwargs</span> <span class="o">=</span> <span class="n">api_kwargs</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">async_client</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">async_client</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_async_client</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="n">ModelType</span><span class="o">.</span><span class="n">EMBEDDER</span><span class="p">:</span>
            <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">async_client</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="o">**</span><span class="n">api_kwargs</span><span class="p">)</span>
        <span class="c1"># old chat completions api calls (commented out)</span>
        <span class="c1"># elif model_type == ModelType.LLM:</span>
        <span class="c1">#     return await self.async_client.chat.completions.create(**api_kwargs)</span>
        <span class="c1"># elif model_type == ModelType.LLM_REASONING:</span>
        <span class="c1">#     if &quot;stream&quot; in api_kwargs and api_kwargs.get(&quot;stream&quot;, False):</span>
        <span class="c1">#         log.debug(&quot;async streaming call&quot;)</span>
        <span class="c1">#         self.response_parser = self.streaming_response_parser</span>
        <span class="c1">#         # setting response parser as async streaming parser for Response API</span>
        <span class="c1">#         return await self.async_client.responses.create(**api_kwargs)</span>
        <span class="c1">#     else:</span>
        <span class="c1">#         log.debug(&quot;async non-streaming call&quot;)</span>
        <span class="c1">#         self.response_parser = self.non_streaming_response_parser</span>
        <span class="c1">#         # setting response parser as async non-streaming parser for Response API</span>
        <span class="c1">#         return await self.async_client.responses.create(**api_kwargs)</span>
        <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="n">ModelType</span><span class="o">.</span><span class="n">LLM</span> <span class="ow">or</span> <span class="n">model_type</span> <span class="o">==</span> <span class="n">ModelType</span><span class="o">.</span><span class="n">LLM_REASONING</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;stream&quot;</span> <span class="ow">in</span> <span class="n">api_kwargs</span> <span class="ow">and</span> <span class="n">api_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;stream&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;async streaming call&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">response_parser</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">streaming_response_parser_async</span>
                <span class="p">)</span>  <span class="c1"># Use async streaming parser</span>
                <span class="c1"># setting response parser as async streaming parser for Response API</span>
                <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">async_client</span><span class="o">.</span><span class="n">responses</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="o">**</span><span class="n">api_kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;async non-streaming call&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">response_parser</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">non_streaming_response_parser</span>
                <span class="c1"># setting response parser as async non-streaming parser for Response API</span>
                <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">async_client</span><span class="o">.</span><span class="n">responses</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="o">**</span><span class="n">api_kwargs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="n">ModelType</span><span class="o">.</span><span class="n">IMAGE_GENERATION</span><span class="p">:</span>
            <span class="c1"># Determine which image API to call based on the presence of image/mask</span>
            <span class="k">if</span> <span class="s2">&quot;image&quot;</span> <span class="ow">in</span> <span class="n">api_kwargs</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">&quot;mask&quot;</span> <span class="ow">in</span> <span class="n">api_kwargs</span><span class="p">:</span>
                    <span class="c1"># Image edit</span>
                    <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">async_client</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">edit</span><span class="p">(</span><span class="o">**</span><span class="n">api_kwargs</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Image variation</span>
                    <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">async_client</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">create_variation</span><span class="p">(</span>
                        <span class="o">**</span><span class="n">api_kwargs</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Image generation</span>
                <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">async_client</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">api_kwargs</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;model_type </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2"> is not supported&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="OpenAIClient.from_dict">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.OpenAIClient.from_dict">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_dict</span><span class="p">(</span><span class="bp">cls</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">T</span><span class="p">],</span> <span class="n">data</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="c1"># recreate the existing clients</span>
        <span class="n">obj</span><span class="o">.</span><span class="n">sync_client</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">init_sync_client</span><span class="p">()</span>
        <span class="n">obj</span><span class="o">.</span><span class="n">async_client</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">init_async_client</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">obj</span></div>


<div class="viewcode-block" id="OpenAIClient.to_dict">
<a class="viewcode-back" href="../../../apis/components/components.model_client.openai_client.html#components.model_client.openai_client.OpenAIClient.to_dict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Convert the component to a dictionary.&quot;&quot;&quot;</span>
        <span class="c1"># TODO: not exclude but save yes or no for recreating the clients</span>
        <span class="n">exclude</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;sync_client&quot;</span><span class="p">,</span>
            <span class="s2">&quot;async_client&quot;</span><span class="p">,</span>
        <span class="p">]</span>  <span class="c1"># unserializable object</span>
        <span class="n">output</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="n">exclude</span><span class="o">=</span><span class="n">exclude</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_encode_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Encode image to base64 string.</span>

<span class="sd">        Args:</span>
<span class="sd">            image_path: Path to image file.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Base64 encoded image string.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the file cannot be read or doesn&#39;t exist.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">image_file</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">image_file</span><span class="o">.</span><span class="n">read</span><span class="p">())</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">FileNotFoundError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Image file not found: </span><span class="si">{</span><span class="n">image_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">PermissionError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Permission denied when reading image file: </span><span class="si">{</span><span class="n">image_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error encoding image </span><span class="si">{</span><span class="n">image_path</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_prepare_image_content</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">image_source</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">detail</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Prepare image content for API request.</span>

<span class="sd">        Args:</span>
<span class="sd">            image_source: Either a path to local image or a URL.</span>
<span class="sd">            detail: Image detail level (&#39;auto&#39;, &#39;low&#39;, or &#39;high&#39;).</span>

<span class="sd">        Returns:</span>
<span class="sd">            Formatted image content for API request.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image_source</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">image_source</span><span class="o">.</span><span class="n">startswith</span><span class="p">((</span><span class="s2">&quot;http://&quot;</span><span class="p">,</span> <span class="s2">&quot;https://&quot;</span><span class="p">)):</span>
                <span class="k">return</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;image_url&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;image_url&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;url&quot;</span><span class="p">:</span> <span class="n">image_source</span><span class="p">,</span> <span class="s2">&quot;detail&quot;</span><span class="p">:</span> <span class="n">detail</span><span class="p">},</span>
                <span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">base64_image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_image</span><span class="p">(</span><span class="n">image_source</span><span class="p">)</span>
                <span class="k">return</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;image_url&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;image_url&quot;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;url&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;data:image/jpeg;base64,</span><span class="si">{</span><span class="n">base64_image</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;detail&quot;</span><span class="p">:</span> <span class="n">detail</span><span class="p">,</span>
                    <span class="p">},</span>
                <span class="p">}</span>
        <span class="k">return</span> <span class="n">image_source</span></div>



<span class="c1"># Example usage:</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">adalflow.core</span><span class="w"> </span><span class="kn">import</span> <span class="n">Generator</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">adalflow.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">setup_env</span>

    <span class="c1"># log = get_logger(level=&quot;DEBUG&quot;)</span>

    <span class="n">setup_env</span><span class="p">()</span>
    <span class="n">prompt_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;input_str&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the meaning of life?&quot;</span><span class="p">}</span>

    <span class="n">gen</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span>
        <span class="n">model_client</span><span class="o">=</span><span class="n">OpenAIClient</span><span class="p">(),</span>
        <span class="n">model_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span> <span class="s2">&quot;stream&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">},</span>
    <span class="p">)</span>
    <span class="n">gen_response</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">prompt_kwargs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;gen_response: </span><span class="si">{</span><span class="n">gen_response</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># for genout in gen_response.data:</span>
    <span class="c1">#     print(f&quot;genout: {genout}&quot;)</span>

    <span class="c1"># test that to_dict and from_dict works</span>
    <span class="c1"># model_client = OpenAIClient()</span>
    <span class="c1"># model_client_dict = model_client.to_dict()</span>
    <span class="c1"># from_dict_model_client = OpenAIClient.from_dict(model_client_dict)</span>
    <span class="c1"># assert model_client_dict == from_dict_model_client.to_dict()</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">test_openai_llm</span><span class="p">():</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">adalflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">adal</span>

        <span class="c1"># setup env or pass the api_key</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">adalflow.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">setup_env</span>

        <span class="n">setup_env</span><span class="p">()</span>

        <span class="n">openai_llm</span> <span class="o">=</span> <span class="n">adal</span><span class="o">.</span><span class="n">Generator</span><span class="p">(</span>
            <span class="n">model_client</span><span class="o">=</span><span class="n">adal</span><span class="o">.</span><span class="n">OpenAIClient</span><span class="p">(),</span> <span class="n">model_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">}</span>
        <span class="p">)</span>
        <span class="n">resopnse</span> <span class="o">=</span> <span class="n">openai_llm</span><span class="p">(</span><span class="n">prompt_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;input_str&quot;</span><span class="p">:</span> <span class="s2">&quot;What is LLM?&quot;</span><span class="p">})</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">resopnse</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">test_openai_reasoning</span><span class="p">():</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">adalflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">adal</span>

        <span class="c1"># setup env or pass the api_key</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">adalflow.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">setup_env</span>

        <span class="n">setup_env</span><span class="p">()</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">adalflow.core.types</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelType</span>

        <span class="n">openai_llm</span> <span class="o">=</span> <span class="n">adal</span><span class="o">.</span><span class="n">Generator</span><span class="p">(</span>
            <span class="n">model_client</span><span class="o">=</span><span class="n">adal</span><span class="o">.</span><span class="n">OpenAIClient</span><span class="p">(),</span>
            <span class="n">model_type</span><span class="o">=</span><span class="n">ModelType</span><span class="o">.</span><span class="n">LLM_REASONING</span><span class="p">,</span>
            <span class="n">model_kwargs</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;o3&quot;</span><span class="p">,</span>
                <span class="s2">&quot;reasoning&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;effort&quot;</span><span class="p">:</span> <span class="s2">&quot;medium&quot;</span><span class="p">,</span> <span class="s2">&quot;summary&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">},</span>
            <span class="p">},</span>
        <span class="p">)</span>

        <span class="n">resopnse</span> <span class="o">=</span> <span class="n">openai_llm</span><span class="p">(</span><span class="n">prompt_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;input_str&quot;</span><span class="p">:</span> <span class="s2">&quot;What is LLM?&quot;</span><span class="p">})</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">resopnse</span><span class="p">)</span>

    <span class="n">test_openai_reasoning</span><span class="p">()</span>
</pre></div>
        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, SylphAI, Inc
            </div>
            Made with 
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../../_static/js/rtd_search_config.js"></script>
    <script src="../../../_static/js/rtd_sphinx_search.min.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs"></script>
    <script type="module">mermaid.initialize({startOnLoad:true});</script>
    <script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script>
    <script type="module">
import mermaid from "https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs";
window.addEventListener("load", () => mermaid.run());
</script>
    </body>
</html>